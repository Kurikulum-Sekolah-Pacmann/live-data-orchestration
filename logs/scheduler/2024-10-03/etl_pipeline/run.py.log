[2024-10-03T00:00:04.808+0000] {processor.py:186} INFO - Started process (PID=261505) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:00:04.809+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:00:04.810+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:00:04.810+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:00:14.869+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:00:14.863+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:00:14.872+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:00:14.906+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 10.107 seconds
[2024-10-03T00:00:45.855+0000] {processor.py:186} INFO - Started process (PID=262163) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:00:45.856+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:00:45.858+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:00:45.857+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:00:50.987+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:00:50.984+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:00:50.989+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:00:51.001+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.154 seconds
[2024-10-03T00:01:21.634+0000] {processor.py:186} INFO - Started process (PID=262518) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:01:21.636+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:01:21.638+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:01:21.638+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:01:26.528+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:01:26.524+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:01:26.530+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:01:26.554+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.927 seconds
[2024-10-03T00:01:57.042+0000] {processor.py:186} INFO - Started process (PID=262865) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:01:57.053+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:01:57.055+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:01:57.055+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:02:02.242+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:02:02.236+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:02:02.244+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:02:02.261+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.226 seconds
[2024-10-03T00:02:32.812+0000] {processor.py:186} INFO - Started process (PID=263214) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:02:32.813+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:02:32.815+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:02:32.814+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:02:37.882+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:02:37.878+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:02:37.884+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:02:37.896+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.091 seconds
[2024-10-03T00:03:08.044+0000] {processor.py:186} INFO - Started process (PID=263572) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:03:08.047+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:03:08.049+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:03:08.049+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:03:13.136+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:03:13.132+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:03:13.137+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:03:13.149+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.112 seconds
[2024-10-03T00:03:43.936+0000] {processor.py:186} INFO - Started process (PID=263934) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:03:43.949+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:03:43.950+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:03:43.950+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:03:49.604+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:03:49.600+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:03:49.605+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:03:49.631+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.702 seconds
[2024-10-03T00:04:19.947+0000] {processor.py:186} INFO - Started process (PID=264301) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:04:19.949+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:04:19.950+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:04:19.950+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:04:24.775+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:04:24.770+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:04:24.786+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:04:24.802+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.861 seconds
[2024-10-03T00:04:55.051+0000] {processor.py:186} INFO - Started process (PID=264657) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:04:55.052+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:04:55.054+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:04:55.053+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:04:59.913+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:04:59.910+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:04:59.915+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:04:59.927+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.883 seconds
[2024-10-03T00:05:30.432+0000] {processor.py:186} INFO - Started process (PID=265007) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:05:30.434+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:05:30.436+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:05:30.435+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:05:34.991+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:05:34.987+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:05:34.992+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:05:35.014+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.589 seconds
[2024-10-03T00:06:05.107+0000] {processor.py:186} INFO - Started process (PID=265353) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:06:05.119+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:06:05.120+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:06:05.120+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:06:09.408+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:06:09.405+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:06:09.409+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:06:09.420+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.320 seconds
[2024-10-03T00:06:39.540+0000] {processor.py:186} INFO - Started process (PID=265702) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:06:39.551+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:06:39.553+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:06:39.553+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:06:44.128+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:06:44.124+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:06:44.129+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:06:44.152+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.619 seconds
[2024-10-03T00:07:14.204+0000] {processor.py:186} INFO - Started process (PID=266061) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:07:14.205+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:07:14.207+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:07:14.206+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:07:18.772+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:07:18.768+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:07:18.774+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:07:18.786+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.589 seconds
[2024-10-03T00:07:48.859+0000] {processor.py:186} INFO - Started process (PID=266415) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:07:48.861+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:07:48.862+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:07:48.862+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:07:53.405+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:07:53.402+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:07:53.407+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:07:53.418+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.566 seconds
[2024-10-03T00:08:24.182+0000] {processor.py:186} INFO - Started process (PID=266767) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:08:24.194+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:08:24.196+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:08:24.196+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:08:29.015+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:08:29.011+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:08:29.017+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:08:29.029+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.854 seconds
[2024-10-03T00:08:59.362+0000] {processor.py:186} INFO - Started process (PID=267128) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:08:59.373+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:08:59.375+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:08:59.374+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:09:03.855+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:09:03.851+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:09:03.856+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:09:03.869+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.514 seconds
[2024-10-03T00:09:34.534+0000] {processor.py:186} INFO - Started process (PID=267486) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:09:34.546+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:09:34.548+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:09:34.548+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:09:38.991+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:09:38.988+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:09:38.993+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:09:39.005+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.478 seconds
[2024-10-03T00:10:09.297+0000] {processor.py:186} INFO - Started process (PID=267833) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:10:09.299+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:10:09.300+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:10:09.300+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:10:13.695+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:10:13.691+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:10:13.696+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:10:13.707+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.417 seconds
[2024-10-03T00:10:44.391+0000] {processor.py:186} INFO - Started process (PID=268181) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:10:44.403+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:10:44.405+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:10:44.405+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:10:48.712+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:10:48.708+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:10:48.713+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:10:48.734+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.351 seconds
[2024-10-03T00:11:19.039+0000] {processor.py:186} INFO - Started process (PID=268535) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:11:19.040+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:11:19.042+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:11:19.041+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:11:23.681+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:11:23.678+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:11:23.683+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:11:23.697+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.665 seconds
[2024-10-03T00:11:53.914+0000] {processor.py:186} INFO - Started process (PID=268896) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:11:53.916+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:11:53.917+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:11:53.917+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:11:58.884+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:11:58.877+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:11:58.887+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:11:58.907+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.000 seconds
[2024-10-03T00:12:29.323+0000] {processor.py:186} INFO - Started process (PID=269247) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:12:29.324+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:12:29.325+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:12:29.325+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:12:33.877+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:12:33.873+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:12:33.878+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:12:33.890+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.575 seconds
[2024-10-03T00:13:03.943+0000] {processor.py:186} INFO - Started process (PID=269601) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:13:03.955+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:13:03.957+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:13:03.956+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:13:08.541+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:13:08.536+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:13:08.543+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:13:08.567+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.632 seconds
[2024-10-03T00:13:38.663+0000] {processor.py:186} INFO - Started process (PID=269960) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:13:38.665+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:13:38.666+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:13:38.666+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:13:43.129+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:13:43.126+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:13:43.131+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:13:43.154+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.497 seconds
[2024-10-03T00:14:13.355+0000] {processor.py:186} INFO - Started process (PID=270306) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:14:13.367+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:14:13.368+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:14:13.368+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:14:17.626+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:14:17.622+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:14:17.628+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:14:17.650+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.302 seconds
[2024-10-03T00:14:48.039+0000] {processor.py:186} INFO - Started process (PID=270656) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:14:48.040+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:14:48.042+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:14:48.042+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:14:52.408+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:14:52.404+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:14:52.409+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:14:52.432+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.399 seconds
[2024-10-03T00:15:22.600+0000] {processor.py:186} INFO - Started process (PID=271009) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:15:22.601+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:15:22.602+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:15:22.602+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:15:26.851+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:15:26.849+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:15:26.853+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:15:26.863+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.271 seconds
[2024-10-03T00:15:57.358+0000] {processor.py:186} INFO - Started process (PID=271360) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:15:57.360+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:15:57.361+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:15:57.361+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:16:02.168+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:16:02.164+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:16:02.170+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:16:02.183+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.831 seconds
[2024-10-03T00:16:32.603+0000] {processor.py:186} INFO - Started process (PID=271713) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:16:32.606+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:16:32.607+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:16:32.607+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:16:37.232+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:16:37.227+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:16:37.235+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:16:37.247+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.650 seconds
[2024-10-03T00:17:07.691+0000] {processor.py:186} INFO - Started process (PID=272067) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:17:07.692+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:17:07.693+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:17:07.693+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:17:12.342+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:17:12.338+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:17:12.343+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:17:12.361+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.676 seconds
[2024-10-03T00:17:42.864+0000] {processor.py:186} INFO - Started process (PID=272420) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:17:42.865+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:17:42.867+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:17:42.866+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:17:47.582+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:17:47.578+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:17:47.583+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:17:47.605+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.749 seconds
[2024-10-03T00:18:17.829+0000] {processor.py:186} INFO - Started process (PID=272781) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:18:17.831+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:18:17.832+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:18:17.832+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:18:22.244+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:18:22.241+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:18:22.246+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:18:22.268+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.445 seconds
[2024-10-03T00:18:52.519+0000] {processor.py:186} INFO - Started process (PID=273129) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:18:52.532+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:18:52.533+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:18:52.533+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:18:56.963+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:18:56.958+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:18:56.964+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:18:56.988+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.476 seconds
[2024-10-03T00:19:27.223+0000] {processor.py:186} INFO - Started process (PID=273483) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:19:27.235+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:19:27.237+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:19:27.236+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:19:31.641+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:19:31.637+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:19:31.642+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:19:31.668+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.452 seconds
[2024-10-03T00:20:02.028+0000] {processor.py:186} INFO - Started process (PID=273835) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:20:02.040+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:20:02.041+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:20:02.041+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:20:06.434+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:20:06.431+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:20:06.435+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:20:06.446+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.427 seconds
[2024-10-03T00:20:36.515+0000] {processor.py:186} INFO - Started process (PID=274191) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:20:36.527+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:20:36.529+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:20:36.528+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:20:40.997+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:20:40.993+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:20:40.999+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:20:41.012+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.503 seconds
[2024-10-03T00:21:11.688+0000] {processor.py:186} INFO - Started process (PID=274539) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:21:11.690+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:21:11.692+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:21:11.691+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:21:16.328+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:21:16.325+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:21:16.330+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:21:16.341+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.660 seconds
[2024-10-03T00:21:46.612+0000] {processor.py:186} INFO - Started process (PID=274901) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:21:46.624+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:21:46.626+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:21:46.625+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:21:51.879+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:21:51.876+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:21:51.881+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:21:51.894+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.288 seconds
[2024-10-03T00:22:22.136+0000] {processor.py:186} INFO - Started process (PID=275255) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:22:22.147+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:22:22.149+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:22:22.149+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:22:26.787+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:22:26.784+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:22:26.788+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:22:26.814+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.685 seconds
[2024-10-03T00:22:57.070+0000] {processor.py:186} INFO - Started process (PID=275610) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:22:57.081+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:22:57.083+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:22:57.083+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:23:01.727+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:23:01.723+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:23:01.728+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:23:01.751+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.687 seconds
[2024-10-03T00:23:31.951+0000] {processor.py:186} INFO - Started process (PID=275966) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:23:31.963+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:23:31.965+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:23:31.964+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:23:36.363+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:23:36.358+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:23:36.365+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:23:36.378+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.434 seconds
[2024-10-03T00:24:06.640+0000] {processor.py:186} INFO - Started process (PID=276318) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:24:06.652+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:24:06.655+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:24:06.654+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:24:10.978+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:24:10.975+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:24:10.980+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:24:10.992+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.360 seconds
[2024-10-03T00:24:41.300+0000] {processor.py:186} INFO - Started process (PID=276669) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:24:41.302+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:24:41.303+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:24:41.303+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:24:45.717+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:24:45.713+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:24:45.718+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:24:45.741+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.449 seconds
[2024-10-03T00:25:15.904+0000] {processor.py:186} INFO - Started process (PID=277017) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:25:15.915+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:25:15.917+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:25:15.916+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:25:20.242+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:25:20.239+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:25:20.243+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:25:20.265+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.368 seconds
[2024-10-03T00:25:50.470+0000] {processor.py:186} INFO - Started process (PID=277366) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:25:50.472+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:25:50.474+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:25:50.474+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:25:55.459+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:25:55.455+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:25:55.461+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:25:55.476+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.012 seconds
[2024-10-03T00:26:26.067+0000] {processor.py:186} INFO - Started process (PID=277724) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:26:26.069+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:26:26.070+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:26:26.070+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:26:30.477+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:26:30.474+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:26:30.478+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:26:30.501+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.441 seconds
[2024-10-03T00:27:00.963+0000] {processor.py:186} INFO - Started process (PID=278079) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:27:00.964+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:27:00.966+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:27:00.966+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:27:05.942+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:27:05.939+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:27:05.944+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:27:05.958+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.001 seconds
[2024-10-03T00:27:36.155+0000] {processor.py:186} INFO - Started process (PID=278441) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:27:36.156+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:27:36.158+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:27:36.157+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:27:40.774+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:27:40.770+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:27:40.776+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:27:40.790+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.642 seconds
[2024-10-03T00:28:10.932+0000] {processor.py:186} INFO - Started process (PID=278792) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:28:10.933+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:28:10.934+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:28:10.934+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:28:15.747+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:28:15.743+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:28:15.748+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:28:15.771+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.847 seconds
[2024-10-03T00:28:46.458+0000] {processor.py:186} INFO - Started process (PID=279145) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:28:46.464+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:28:46.465+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:28:46.465+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:28:50.740+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:28:50.736+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:28:50.742+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:28:50.752+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.301 seconds
[2024-10-03T00:29:21.204+0000] {processor.py:186} INFO - Started process (PID=279491) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:29:21.205+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:29:21.207+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:29:21.206+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:29:25.599+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:29:25.595+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:29:25.601+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:29:25.623+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.427 seconds
[2024-10-03T00:29:55.783+0000] {processor.py:186} INFO - Started process (PID=279838) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:29:55.785+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:29:55.786+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:29:55.786+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:30:00.357+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:30:00.350+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:30:00.359+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:30:00.371+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.594 seconds
[2024-10-03T00:30:30.890+0000] {processor.py:186} INFO - Started process (PID=280198) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:30:30.902+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:30:30.903+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:30:30.903+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:30:35.309+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:30:35.306+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:30:35.311+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:30:35.323+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.440 seconds
[2024-10-03T00:31:05.824+0000] {processor.py:186} INFO - Started process (PID=280547) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:31:05.836+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:31:05.838+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:31:05.837+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:31:10.858+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:31:10.855+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:31:10.860+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:31:10.872+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.055 seconds
[2024-10-03T00:31:40.938+0000] {processor.py:186} INFO - Started process (PID=280912) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:31:40.942+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:31:40.943+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:31:40.943+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:31:45.781+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:31:45.777+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:31:45.783+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:31:45.797+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.866 seconds
[2024-10-03T00:32:16.132+0000] {processor.py:186} INFO - Started process (PID=281263) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:32:16.134+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:32:16.135+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:32:16.135+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:32:20.510+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:32:20.506+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:32:20.511+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:32:20.533+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.409 seconds
[2024-10-03T00:32:50.891+0000] {processor.py:186} INFO - Started process (PID=281624) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:32:50.894+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:32:50.895+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:32:50.895+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:32:55.558+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:32:55.553+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:32:55.560+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:32:55.591+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.706 seconds
[2024-10-03T00:33:25.721+0000] {processor.py:186} INFO - Started process (PID=281974) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:33:25.733+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:33:25.734+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:33:25.734+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:33:30.033+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:33:30.030+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:33:30.035+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:33:30.059+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.344 seconds
[2024-10-03T00:34:00.306+0000] {processor.py:186} INFO - Started process (PID=282320) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:34:00.319+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:34:00.320+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:34:00.320+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:34:04.963+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:34:04.958+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:34:04.964+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:34:04.978+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.678 seconds
[2024-10-03T00:34:35.709+0000] {processor.py:186} INFO - Started process (PID=282675) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:34:35.721+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:34:35.723+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:34:35.722+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:34:39.836+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:34:39.834+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:34:39.837+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:34:39.849+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.148 seconds
[2024-10-03T00:35:10.366+0000] {processor.py:186} INFO - Started process (PID=283030) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:35:10.368+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:35:10.369+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:35:10.369+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:35:14.705+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:35:14.701+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:35:14.707+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:35:14.721+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.361 seconds
[2024-10-03T00:35:45.267+0000] {processor.py:186} INFO - Started process (PID=283391) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:35:45.280+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:35:45.282+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:35:45.282+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:35:49.515+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:35:49.511+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:35:49.516+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:35:49.529+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.268 seconds
[2024-10-03T00:36:20.242+0000] {processor.py:186} INFO - Started process (PID=283749) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:36:20.242+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:36:20.244+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:36:20.243+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:36:25.217+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:36:25.213+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:36:25.218+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:36:25.234+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.000 seconds
[2024-10-03T00:36:55.422+0000] {processor.py:186} INFO - Started process (PID=284097) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:36:55.423+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:36:55.424+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:36:55.424+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:36:59.687+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:36:59.683+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:36:59.688+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:36:59.701+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.285 seconds
[2024-10-03T00:37:29.799+0000] {processor.py:186} INFO - Started process (PID=284454) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:37:29.801+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:37:29.802+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:37:29.802+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:37:34.042+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:37:34.038+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:37:34.043+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:37:34.065+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.272 seconds
[2024-10-03T00:38:04.854+0000] {processor.py:186} INFO - Started process (PID=284803) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:38:04.855+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:38:04.857+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:38:04.856+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:38:08.992+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:38:08.989+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:38:08.994+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:38:09.016+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.169 seconds
[2024-10-03T00:38:39.114+0000] {processor.py:186} INFO - Started process (PID=285157) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:38:39.115+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:38:39.117+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:38:39.116+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:38:43.440+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:38:43.437+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:38:43.442+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:38:43.454+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.348 seconds
[2024-10-03T00:39:13.635+0000] {processor.py:186} INFO - Started process (PID=285513) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:39:13.636+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:39:13.637+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:39:13.637+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:39:18.548+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:39:18.543+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:39:18.550+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:39:18.574+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.948 seconds
[2024-10-03T00:39:49.248+0000] {processor.py:186} INFO - Started process (PID=285873) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:39:49.260+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:39:49.262+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:39:49.261+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:39:53.380+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:39:53.377+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:39:53.381+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:39:53.395+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.154 seconds
[2024-10-03T00:40:23.658+0000] {processor.py:186} INFO - Started process (PID=286228) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:40:23.659+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:40:23.661+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:40:23.660+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:40:28.184+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:40:28.180+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:40:28.185+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:40:28.209+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.557 seconds
[2024-10-03T00:40:58.713+0000] {processor.py:186} INFO - Started process (PID=286583) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:40:58.714+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:40:58.715+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:40:58.715+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:41:03.194+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:41:03.190+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:41:03.195+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:41:03.220+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.514 seconds
[2024-10-03T00:41:33.439+0000] {processor.py:186} INFO - Started process (PID=286931) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:41:33.441+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:41:33.443+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:41:33.442+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:41:37.773+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:41:37.770+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:41:37.775+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:41:37.798+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.366 seconds
[2024-10-03T00:42:08.204+0000] {processor.py:186} INFO - Started process (PID=287286) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:42:08.206+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:42:08.207+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:42:08.207+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:42:12.430+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:42:12.425+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:42:12.432+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:42:12.455+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.258 seconds
[2024-10-03T00:42:42.969+0000] {processor.py:186} INFO - Started process (PID=287634) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:42:42.981+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:42:42.983+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:42:42.982+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:42:47.412+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:42:47.408+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:42:47.414+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:42:47.427+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.464 seconds
[2024-10-03T00:43:18.091+0000] {processor.py:186} INFO - Started process (PID=287993) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:43:18.103+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:43:18.105+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:43:18.104+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:43:22.318+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:43:22.315+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:43:22.320+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:43:22.343+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.259 seconds
[2024-10-03T00:43:52.721+0000] {processor.py:186} INFO - Started process (PID=288350) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:43:52.732+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:43:52.734+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:43:52.734+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:43:56.927+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:43:56.923+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:43:56.928+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:43:56.941+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.227 seconds
[2024-10-03T00:44:27.240+0000] {processor.py:186} INFO - Started process (PID=288703) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:44:27.243+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:44:27.245+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:44:27.244+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:44:31.526+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:44:31.522+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:44:31.527+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:44:31.549+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.315 seconds
[2024-10-03T00:45:02.132+0000] {processor.py:186} INFO - Started process (PID=289050) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:45:02.144+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:45:02.145+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:45:02.145+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:45:06.420+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:45:06.417+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:45:06.422+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:45:06.435+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.309 seconds
[2024-10-03T00:45:36.909+0000] {processor.py:186} INFO - Started process (PID=289403) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:45:36.910+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:45:36.912+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:45:36.911+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:45:41.133+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:45:41.130+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:45:41.135+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:45:41.147+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.245 seconds
[2024-10-03T00:46:11.339+0000] {processor.py:186} INFO - Started process (PID=289753) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:46:11.340+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:46:11.341+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:46:11.341+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:46:15.497+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:46:15.493+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:46:15.499+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:46:15.521+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.189 seconds
[2024-10-03T00:46:45.677+0000] {processor.py:186} INFO - Started process (PID=290108) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:46:45.690+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:46:45.691+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:46:45.691+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:46:49.896+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:46:49.893+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:46:49.897+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:46:49.922+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.251 seconds
[2024-10-03T00:47:20.363+0000] {processor.py:186} INFO - Started process (PID=290455) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:47:20.375+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:47:20.377+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:47:20.376+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:47:24.722+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:47:24.718+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:47:24.723+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:47:24.735+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.379 seconds
[2024-10-03T00:47:54.853+0000] {processor.py:186} INFO - Started process (PID=290814) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:47:54.854+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:47:54.856+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:47:54.855+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:47:59.432+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:47:59.428+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:47:59.433+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:47:59.458+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.612 seconds
[2024-10-03T00:48:30.272+0000] {processor.py:186} INFO - Started process (PID=291176) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:48:30.284+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:48:30.286+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:48:30.285+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:48:34.506+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:48:34.503+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:48:34.508+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:48:34.532+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.267 seconds
[2024-10-03T00:49:04.790+0000] {processor.py:186} INFO - Started process (PID=291525) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:49:04.803+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:49:04.804+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:49:04.804+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:49:08.998+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:49:08.996+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:49:08.999+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:49:09.010+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.227 seconds
[2024-10-03T00:49:39.066+0000] {processor.py:186} INFO - Started process (PID=291872) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:49:39.069+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:49:39.070+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:49:39.070+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:49:43.207+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:49:43.203+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:49:43.209+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:49:43.222+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.163 seconds
[2024-10-03T00:50:13.540+0000] {processor.py:186} INFO - Started process (PID=292220) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:50:13.542+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:50:13.544+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:50:13.543+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:50:17.969+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:50:17.966+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:50:17.971+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:50:17.996+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.464 seconds
[2024-10-03T00:50:48.132+0000] {processor.py:186} INFO - Started process (PID=292574) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:50:48.134+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:50:48.135+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:50:48.135+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:50:52.496+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:50:52.493+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:50:52.498+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:50:52.510+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.384 seconds
[2024-10-03T00:51:22.684+0000] {processor.py:186} INFO - Started process (PID=292927) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:51:22.685+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:51:22.686+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:51:22.686+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:51:27.092+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:51:27.089+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:51:27.094+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:51:27.118+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.440 seconds
[2024-10-03T00:51:57.812+0000] {processor.py:186} INFO - Started process (PID=293285) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:51:57.813+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:51:57.815+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:51:57.814+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:52:02.314+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:52:02.309+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:52:02.316+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:52:02.332+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.527 seconds
[2024-10-03T00:52:32.679+0000] {processor.py:186} INFO - Started process (PID=293646) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:52:32.691+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:52:32.693+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:52:32.693+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:52:37.249+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:52:37.245+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:52:37.251+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:52:37.264+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.593 seconds
[2024-10-03T00:53:07.922+0000] {processor.py:186} INFO - Started process (PID=293999) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:53:07.932+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:53:07.933+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:53:07.933+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:53:12.093+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:53:12.089+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:53:12.095+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:53:12.119+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.205 seconds
[2024-10-03T00:53:42.821+0000] {processor.py:186} INFO - Started process (PID=294347) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:53:42.823+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:53:42.824+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:53:42.824+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:53:47.457+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:53:47.453+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:53:47.459+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:53:47.487+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.673 seconds
[2024-10-03T00:54:18.254+0000] {processor.py:186} INFO - Started process (PID=294693) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:54:18.256+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:54:18.258+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:54:18.257+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:54:22.420+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:54:22.417+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:54:22.422+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:54:22.443+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.196 seconds
[2024-10-03T00:54:52.641+0000] {processor.py:186} INFO - Started process (PID=295045) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:54:52.643+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:54:52.644+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:54:52.644+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:54:56.937+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:54:56.934+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:54:56.939+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:54:56.960+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.326 seconds
[2024-10-03T00:55:27.608+0000] {processor.py:186} INFO - Started process (PID=295400) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:55:27.620+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:55:27.622+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:55:27.621+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:55:32.042+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:55:32.038+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:55:32.043+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:55:32.057+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.456 seconds
[2024-10-03T00:56:02.622+0000] {processor.py:186} INFO - Started process (PID=295769) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:56:02.634+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:56:02.636+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:56:02.636+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:56:07.283+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:56:07.280+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:56:07.284+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:56:07.297+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.682 seconds
[2024-10-03T00:56:38.033+0000] {processor.py:186} INFO - Started process (PID=296128) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:56:38.045+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:56:38.046+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:56:38.046+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:56:42.628+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:56:42.623+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:56:42.630+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:56:42.657+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.631 seconds
[2024-10-03T00:57:13.342+0000] {processor.py:186} INFO - Started process (PID=296478) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:57:13.343+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:57:13.344+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:57:13.344+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:57:17.586+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:57:17.582+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:57:17.588+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:57:17.611+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.276 seconds
[2024-10-03T00:57:48.103+0000] {processor.py:186} INFO - Started process (PID=296827) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:57:48.116+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:57:48.118+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:57:48.117+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:57:52.275+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:57:52.271+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:57:52.276+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:57:52.297+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.200 seconds
[2024-10-03T00:58:23.071+0000] {processor.py:186} INFO - Started process (PID=297175) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:58:23.083+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:58:23.085+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:58:23.084+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:58:27.310+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:58:27.307+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:58:27.311+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:58:27.323+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.259 seconds
[2024-10-03T00:58:57.880+0000] {processor.py:186} INFO - Started process (PID=297522) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:58:57.892+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:58:57.893+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:58:57.893+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:59:02.048+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:59:02.045+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:59:02.049+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:59:02.060+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.187 seconds
[2024-10-03T00:59:32.800+0000] {processor.py:186} INFO - Started process (PID=297870) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:59:32.801+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T00:59:32.803+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:59:32.802+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:59:37.326+0000] {logging_mixin.py:190} INFO - [2024-10-03T00:59:37.322+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T00:59:37.328+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T00:59:37.352+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.560 seconds
[2024-10-03T01:00:07.894+0000] {processor.py:186} INFO - Started process (PID=298244) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:00:07.896+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:00:07.897+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:00:07.897+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:00:12.456+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:00:12.452+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:00:12.457+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:00:12.481+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.594 seconds
[2024-10-03T01:00:42.658+0000] {processor.py:186} INFO - Started process (PID=298608) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:00:42.670+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:00:42.671+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:00:42.671+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:00:47.436+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:00:47.433+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:00:47.438+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:00:47.462+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.811 seconds
[2024-10-03T01:01:18.041+0000] {processor.py:186} INFO - Started process (PID=298955) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:01:18.043+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:01:18.045+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:01:18.045+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:01:22.337+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:01:22.333+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:01:22.339+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:01:22.353+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.318 seconds
[2024-10-03T01:01:52.420+0000] {processor.py:186} INFO - Started process (PID=299302) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:01:52.421+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:01:52.423+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:01:52.422+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:01:56.724+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:01:56.720+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:01:56.725+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:01:56.739+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.326 seconds
[2024-10-03T01:02:27.020+0000] {processor.py:186} INFO - Started process (PID=299651) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:02:27.033+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:02:27.034+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:02:27.034+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:02:31.236+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:02:31.233+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:02:31.237+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:02:31.259+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.245 seconds
[2024-10-03T01:03:01.525+0000] {processor.py:186} INFO - Started process (PID=299998) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:03:01.526+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:03:01.528+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:03:01.527+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:03:05.813+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:03:05.810+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:03:05.814+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:03:05.838+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.320 seconds
[2024-10-03T01:03:36.242+0000] {processor.py:186} INFO - Started process (PID=300346) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:03:36.254+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:03:36.255+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:03:36.255+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:03:40.589+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:03:40.586+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:03:40.590+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:03:40.614+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.378 seconds
[2024-10-03T01:04:10.983+0000] {processor.py:186} INFO - Started process (PID=300710) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:04:10.994+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:04:10.996+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:04:10.995+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:04:16.171+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:04:16.165+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:04:16.174+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:04:16.192+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.217 seconds
[2024-10-03T01:04:46.391+0000] {processor.py:186} INFO - Started process (PID=301075) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:04:46.403+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:04:46.405+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:04:46.404+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:04:50.685+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:04:50.682+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:04:50.687+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:04:50.700+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.316 seconds
[2024-10-03T01:05:20.890+0000] {processor.py:186} INFO - Started process (PID=301428) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:05:20.891+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:05:20.893+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:05:20.892+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:05:25.331+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:05:25.327+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:05:25.332+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:05:25.345+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.461 seconds
[2024-10-03T01:05:55.687+0000] {processor.py:186} INFO - Started process (PID=301775) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:05:55.688+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:05:55.690+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:05:55.689+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:05:59.888+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:05:59.885+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:05:59.889+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:05:59.912+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.232 seconds
[2024-10-03T01:06:29.999+0000] {processor.py:186} INFO - Started process (PID=302121) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:06:30.001+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:06:30.002+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:06:30.002+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:06:34.383+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:06:34.378+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:06:34.385+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:06:34.409+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.417 seconds
[2024-10-03T01:07:04.571+0000] {processor.py:186} INFO - Started process (PID=302468) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:07:04.583+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:07:04.584+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:07:04.584+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:07:08.726+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:07:08.723+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:07:08.728+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:07:08.739+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.175 seconds
[2024-10-03T01:07:39.203+0000] {processor.py:186} INFO - Started process (PID=302816) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:07:39.206+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:07:39.207+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:07:39.207+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:07:43.559+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:07:43.554+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:07:43.560+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:07:43.573+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.380 seconds
[2024-10-03T01:08:13.944+0000] {processor.py:186} INFO - Started process (PID=303172) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:08:13.949+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:08:13.950+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:08:13.950+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:08:18.209+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:08:18.205+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:08:18.210+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:08:18.224+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.287 seconds
[2024-10-03T01:08:48.377+0000] {processor.py:186} INFO - Started process (PID=303529) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:08:48.379+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:08:48.381+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:08:48.380+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:08:53.630+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:08:53.625+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:08:53.632+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:08:53.652+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.281 seconds
[2024-10-03T01:09:23.722+0000] {processor.py:186} INFO - Started process (PID=303883) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:09:23.723+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:09:23.724+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:09:23.724+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:09:28.341+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:09:28.335+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:09:28.343+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:09:28.358+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.643 seconds
[2024-10-03T01:09:58.484+0000] {processor.py:186} INFO - Started process (PID=304250) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:09:58.496+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:09:58.498+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:09:58.497+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:10:02.840+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:10:02.835+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:10:02.842+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:10:02.855+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.377 seconds
[2024-10-03T01:10:33.718+0000] {processor.py:186} INFO - Started process (PID=304600) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:10:33.720+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:10:33.721+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:10:33.721+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:10:37.958+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:10:37.954+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:10:37.959+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:10:37.971+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.260 seconds
[2024-10-03T01:11:08.386+0000] {processor.py:186} INFO - Started process (PID=304948) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:11:08.387+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:11:08.389+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:11:08.388+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:11:12.737+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:11:12.734+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:11:12.738+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:11:12.751+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.371 seconds
[2024-10-03T01:11:42.790+0000] {processor.py:186} INFO - Started process (PID=305295) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:11:42.791+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:11:42.792+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:11:42.792+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:11:47.265+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:11:47.262+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:11:47.267+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:11:47.291+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.508 seconds
[2024-10-03T01:12:17.357+0000] {processor.py:186} INFO - Started process (PID=305659) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:12:17.359+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:12:17.360+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:12:17.360+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:12:21.810+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:12:21.806+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:12:21.811+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:12:21.823+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.473 seconds
[2024-10-03T01:12:52.571+0000] {processor.py:186} INFO - Started process (PID=306007) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:12:52.583+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:12:52.584+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:12:52.584+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:12:56.906+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:12:56.903+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:12:56.908+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:12:56.931+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.368 seconds
[2024-10-03T01:13:26.969+0000] {processor.py:186} INFO - Started process (PID=306361) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:13:26.980+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:13:26.982+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:13:26.982+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:13:31.245+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:13:31.241+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:13:31.247+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:13:31.269+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.307 seconds
[2024-10-03T01:14:01.703+0000] {processor.py:186} INFO - Started process (PID=306709) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:14:01.714+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:14:01.716+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:14:01.715+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:14:06.201+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:14:06.197+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:14:06.202+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:14:06.443+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.746 seconds
[2024-10-03T01:14:36.625+0000] {processor.py:186} INFO - Started process (PID=307069) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:14:36.637+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:14:36.639+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:14:36.638+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:14:41.127+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:14:41.122+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:14:41.128+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:14:41.152+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.534 seconds
[2024-10-03T01:15:11.205+0000] {processor.py:186} INFO - Started process (PID=307423) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:15:11.217+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:15:11.218+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:15:11.218+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:15:15.482+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:15:15.478+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:15:15.484+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:15:15.509+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.311 seconds
[2024-10-03T01:15:46.069+0000] {processor.py:186} INFO - Started process (PID=307772) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:15:46.070+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:15:46.071+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:15:46.071+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:15:50.833+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:15:50.830+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:15:50.835+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:15:50.847+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.785 seconds
[2024-10-03T01:16:21.490+0000] {processor.py:186} INFO - Started process (PID=308133) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:16:21.491+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:16:21.493+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:16:21.492+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:16:25.776+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:16:25.773+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:16:25.778+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:16:25.791+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.309 seconds
[2024-10-03T01:16:55.858+0000] {processor.py:186} INFO - Started process (PID=308485) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:16:55.860+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:16:55.861+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:16:55.861+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:16:59.965+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:16:59.962+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:16:59.966+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:16:59.988+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.137 seconds
[2024-10-03T01:17:30.411+0000] {processor.py:186} INFO - Started process (PID=308833) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:17:30.412+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:17:30.413+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:17:30.413+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:17:34.820+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:17:34.816+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:17:34.821+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:17:34.843+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.439 seconds
[2024-10-03T01:18:05.026+0000] {processor.py:186} INFO - Started process (PID=309182) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:18:05.038+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:18:05.040+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:18:05.039+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:18:09.238+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:18:09.232+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:18:09.240+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:18:09.255+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.235 seconds
[2024-10-03T01:18:40.030+0000] {processor.py:186} INFO - Started process (PID=309529) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:18:40.031+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:18:40.033+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:18:40.032+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:18:44.331+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:18:44.327+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:18:44.332+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:18:44.346+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.323 seconds
[2024-10-03T01:19:14.541+0000] {processor.py:186} INFO - Started process (PID=309888) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:19:14.553+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:19:14.554+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:19:14.554+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:19:19.141+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:19:19.138+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:19:19.142+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:19:19.154+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.620 seconds
[2024-10-03T01:19:49.503+0000] {processor.py:186} INFO - Started process (PID=310246) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:19:49.515+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:19:49.517+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:19:49.517+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:19:54.034+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:19:54.031+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:19:54.036+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:19:54.058+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.561 seconds
[2024-10-03T01:20:24.854+0000] {processor.py:186} INFO - Started process (PID=310598) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:20:24.866+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:20:24.867+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:20:24.867+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:20:29.447+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:20:29.442+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:20:29.449+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:20:29.472+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.626 seconds
[2024-10-03T01:21:00.327+0000] {processor.py:186} INFO - Started process (PID=310955) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:21:00.328+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:21:00.330+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:21:00.329+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:21:05.133+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:21:05.130+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:21:05.135+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:21:05.146+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.827 seconds
[2024-10-03T01:21:35.682+0000] {processor.py:186} INFO - Started process (PID=311310) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:21:35.687+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:21:35.688+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:21:35.688+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:21:40.236+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:21:40.232+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:21:40.237+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:21:40.261+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.586 seconds
[2024-10-03T01:22:11.109+0000] {processor.py:186} INFO - Started process (PID=311658) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:22:11.122+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:22:11.123+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:22:11.123+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:22:15.425+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:22:15.422+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:22:15.427+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:22:15.450+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.347 seconds
[2024-10-03T01:22:45.676+0000] {processor.py:186} INFO - Started process (PID=312005) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:22:45.677+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:22:45.678+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:22:45.678+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:22:49.985+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:22:49.982+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:22:49.987+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:22:50.180+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.510 seconds
[2024-10-03T01:23:20.327+0000] {processor.py:186} INFO - Started process (PID=312367) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:23:20.328+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:23:20.330+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:23:20.329+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:23:24.814+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:23:24.809+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:23:24.816+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:23:24.839+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.518 seconds
[2024-10-03T01:23:54.943+0000] {processor.py:186} INFO - Started process (PID=312714) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:23:54.955+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:23:54.957+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:23:54.956+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:23:59.626+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:23:59.621+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:23:59.627+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:23:59.644+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.708 seconds
[2024-10-03T01:24:29.957+0000] {processor.py:186} INFO - Started process (PID=313079) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:24:29.959+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:24:29.960+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:24:29.960+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:24:34.284+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:24:34.280+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:24:34.285+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:24:34.299+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.349 seconds
[2024-10-03T01:25:04.614+0000] {processor.py:186} INFO - Started process (PID=313432) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:25:04.626+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:25:04.628+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:25:04.627+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:25:09.086+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:25:09.083+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:25:09.087+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:25:09.108+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.501 seconds
[2024-10-03T01:25:39.276+0000] {processor.py:186} INFO - Started process (PID=313787) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:25:39.288+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:25:39.289+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:25:39.289+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:25:43.797+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:25:43.793+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:25:43.799+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:25:43.811+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.542 seconds
[2024-10-03T01:26:13.950+0000] {processor.py:186} INFO - Started process (PID=314134) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:26:13.952+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:26:13.954+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:26:13.953+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:26:18.064+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:26:18.061+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:26:18.066+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:26:18.087+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.144 seconds
[2024-10-03T01:26:48.252+0000] {processor.py:186} INFO - Started process (PID=314481) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:26:48.254+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:26:48.256+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:26:48.256+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:26:52.676+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:26:52.672+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:26:52.678+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:26:52.701+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.456 seconds
[2024-10-03T01:27:22.788+0000] {processor.py:186} INFO - Started process (PID=314827) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:27:22.800+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:27:22.801+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:27:22.801+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:27:27.143+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:27:27.139+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:27:27.145+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:27:27.165+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.385 seconds
[2024-10-03T01:27:57.342+0000] {processor.py:186} INFO - Started process (PID=315188) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:27:57.353+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:27:57.355+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:27:57.355+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:28:01.701+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:28:01.695+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:28:01.703+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:28:01.733+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.398 seconds
[2024-10-03T01:28:31.939+0000] {processor.py:186} INFO - Started process (PID=315549) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:28:31.951+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:28:31.953+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:28:31.952+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:28:36.548+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:28:36.545+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:28:36.550+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:28:36.562+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.629 seconds
[2024-10-03T01:29:07.428+0000] {processor.py:186} INFO - Started process (PID=315904) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:29:07.435+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:29:07.437+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:29:07.436+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:29:11.671+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:29:11.667+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:29:11.673+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:29:11.695+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.275 seconds
[2024-10-03T01:29:41.821+0000] {processor.py:186} INFO - Started process (PID=316262) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:29:41.823+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:29:41.824+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:29:41.824+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:29:46.287+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:29:46.283+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:29:46.288+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:29:46.301+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.487 seconds
[2024-10-03T01:30:16.649+0000] {processor.py:186} INFO - Started process (PID=316609) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:30:16.661+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:30:16.663+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:30:16.662+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:30:21.441+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:30:21.437+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:30:21.442+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:30:21.454+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.812 seconds
[2024-10-03T01:30:51.919+0000] {processor.py:186} INFO - Started process (PID=316958) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:30:51.931+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:30:51.933+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:30:51.932+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:30:56.285+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:30:56.282+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:30:56.287+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:30:56.308+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.396 seconds
[2024-10-03T01:31:26.354+0000] {processor.py:186} INFO - Started process (PID=317307) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:31:26.367+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:31:26.369+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:31:26.368+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:31:30.897+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:31:30.893+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:31:30.898+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:31:30.913+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.565 seconds
[2024-10-03T01:32:01.760+0000] {processor.py:186} INFO - Started process (PID=317663) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:32:01.780+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:32:01.781+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:32:01.781+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:32:06.464+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:32:06.461+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:32:06.466+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:32:06.675+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.922 seconds
[2024-10-03T01:32:37.332+0000] {processor.py:186} INFO - Started process (PID=318028) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:32:37.344+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:32:37.345+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:32:37.345+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:32:41.959+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:32:41.954+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:32:41.961+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:32:41.986+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.661 seconds
[2024-10-03T01:33:12.108+0000] {processor.py:186} INFO - Started process (PID=318388) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:33:12.120+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:33:12.122+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:33:12.121+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:33:16.650+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:33:16.647+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:33:16.651+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:33:16.675+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.575 seconds
[2024-10-03T01:33:47.283+0000] {processor.py:186} INFO - Started process (PID=318735) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:33:47.296+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:33:47.297+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:33:47.297+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:33:51.949+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:33:51.945+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:33:51.950+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:33:51.973+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.697 seconds
[2024-10-03T01:34:22.224+0000] {processor.py:186} INFO - Started process (PID=319092) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:34:22.226+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:34:22.228+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:34:22.227+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:34:26.617+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:34:26.613+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:34:26.618+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:34:26.640+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.423 seconds
[2024-10-03T01:34:57.061+0000] {processor.py:186} INFO - Started process (PID=319440) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:34:57.074+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:34:57.075+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:34:57.075+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:35:01.457+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:35:01.453+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:35:01.458+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:35:01.472+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.417 seconds
[2024-10-03T01:35:31.746+0000] {processor.py:186} INFO - Started process (PID=319787) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:35:31.758+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:35:31.760+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:35:31.760+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:35:36.469+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:35:36.466+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:35:36.471+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:35:36.483+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.747 seconds
[2024-10-03T01:36:06.698+0000] {processor.py:186} INFO - Started process (PID=320146) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:36:06.703+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:36:06.705+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:36:06.705+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:36:10.967+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:36:10.964+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:36:10.968+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:36:10.982+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.290 seconds
[2024-10-03T01:36:41.601+0000] {processor.py:186} INFO - Started process (PID=320504) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:36:41.602+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:36:41.603+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:36:41.603+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:36:46.297+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:36:46.293+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:36:46.298+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:36:46.311+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.718 seconds
[2024-10-03T01:37:16.688+0000] {processor.py:186} INFO - Started process (PID=320870) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:37:16.700+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:37:16.702+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:37:16.701+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:37:20.952+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:37:20.949+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:37:20.954+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:37:20.965+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.283 seconds
[2024-10-03T01:37:51.254+0000] {processor.py:186} INFO - Started process (PID=321217) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:37:51.266+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:37:51.267+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:37:51.267+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:37:55.785+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:37:55.781+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:37:55.786+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:37:55.806+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.559 seconds
[2024-10-03T01:38:25.971+0000] {processor.py:186} INFO - Started process (PID=321568) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:38:25.973+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:38:25.974+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:38:25.974+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:38:30.287+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:38:30.284+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:38:30.289+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:38:30.302+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.338 seconds
[2024-10-03T01:39:00.610+0000] {processor.py:186} INFO - Started process (PID=321925) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:39:00.611+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:39:00.613+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:39:00.612+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:39:05.097+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:39:05.093+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:39:05.098+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:39:05.110+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.507 seconds
[2024-10-03T01:39:36.053+0000] {processor.py:186} INFO - Started process (PID=322273) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:39:36.056+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:39:36.057+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:39:36.057+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:39:40.350+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:39:40.347+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:39:40.351+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:39:40.374+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.327 seconds
[2024-10-03T01:40:10.814+0000] {processor.py:186} INFO - Started process (PID=322630) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:40:10.815+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:40:10.817+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:40:10.816+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:40:15.259+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:40:15.255+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:40:15.260+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:40:15.273+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.465 seconds
[2024-10-03T01:40:45.478+0000] {processor.py:186} INFO - Started process (PID=322984) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:40:45.489+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:40:45.491+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:40:45.490+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:40:50.050+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:40:50.046+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:40:50.052+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:40:50.065+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.595 seconds
[2024-10-03T01:41:20.484+0000] {processor.py:186} INFO - Started process (PID=323342) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:41:20.485+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:41:20.486+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:41:20.486+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:41:25.052+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:41:25.048+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:41:25.053+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:41:25.065+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.589 seconds
[2024-10-03T01:41:55.316+0000] {processor.py:186} INFO - Started process (PID=323694) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:41:55.318+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:41:55.320+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:41:55.320+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:41:59.666+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:41:59.661+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:41:59.667+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:41:59.691+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.381 seconds
[2024-10-03T01:42:29.860+0000] {processor.py:186} INFO - Started process (PID=324043) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:42:29.861+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:42:29.863+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:42:29.862+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:42:34.281+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:42:34.278+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:42:34.283+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:42:34.294+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.441 seconds
[2024-10-03T01:43:04.854+0000] {processor.py:186} INFO - Started process (PID=324392) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:43:04.866+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:43:04.868+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:43:04.867+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:43:09.328+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:43:09.325+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:43:09.329+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:43:09.350+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.503 seconds
[2024-10-03T01:43:39.730+0000] {processor.py:186} INFO - Started process (PID=324748) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:43:39.742+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:43:39.743+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:43:39.743+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:43:44.113+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:43:44.108+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:43:44.115+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:43:44.130+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.406 seconds
[2024-10-03T01:44:15.041+0000] {processor.py:186} INFO - Started process (PID=325103) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:44:15.042+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:44:15.044+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:44:15.043+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:44:19.331+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:44:19.328+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:44:19.332+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:44:19.352+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.318 seconds
[2024-10-03T01:44:49.656+0000] {processor.py:186} INFO - Started process (PID=325461) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:44:49.668+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:44:49.670+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:44:49.670+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:44:54.137+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:44:54.133+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:44:54.138+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:44:54.161+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.511 seconds
[2024-10-03T01:45:24.270+0000] {processor.py:186} INFO - Started process (PID=325818) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:45:24.283+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:45:24.284+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:45:24.284+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:45:28.542+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:45:28.538+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:45:28.544+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:45:28.555+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.293 seconds
[2024-10-03T01:45:58.754+0000] {processor.py:186} INFO - Started process (PID=326167) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:45:58.756+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:45:58.758+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:45:58.758+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:46:03.695+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:46:03.692+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:46:03.696+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:46:03.708+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.961 seconds
[2024-10-03T01:46:34.146+0000] {processor.py:186} INFO - Started process (PID=326522) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:46:34.148+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:46:34.150+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:46:34.149+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:46:38.605+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:46:38.601+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:46:38.606+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:46:38.628+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.489 seconds
[2024-10-03T01:47:08.849+0000] {processor.py:186} INFO - Started process (PID=326869) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:47:08.861+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:47:08.863+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:47:08.863+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:47:13.693+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:47:13.690+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:47:13.695+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:47:13.718+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.876 seconds
[2024-10-03T01:47:44.239+0000] {processor.py:186} INFO - Started process (PID=327221) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:47:44.240+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:47:44.241+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:47:44.241+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:47:48.657+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:47:48.653+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:47:48.658+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:47:48.681+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.449 seconds
[2024-10-03T01:48:18.821+0000] {processor.py:186} INFO - Started process (PID=327574) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:48:18.822+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:48:18.824+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:48:18.823+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:48:23.778+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:48:23.774+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:48:23.781+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:48:23.805+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.993 seconds
[2024-10-03T01:48:54.431+0000] {processor.py:186} INFO - Started process (PID=327934) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:48:54.433+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:48:54.434+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:48:54.434+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:48:58.969+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:48:58.965+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:48:58.970+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:48:58.983+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.559 seconds
[2024-10-03T01:49:29.190+0000] {processor.py:186} INFO - Started process (PID=328290) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:49:29.193+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:49:29.194+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:49:29.194+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:49:33.788+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:49:33.783+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:49:33.790+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:49:33.803+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.619 seconds
[2024-10-03T01:50:03.927+0000] {processor.py:186} INFO - Started process (PID=328639) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:50:03.939+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:50:03.941+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:50:03.941+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:50:08.236+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:50:08.232+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:50:08.238+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:50:08.262+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.341 seconds
[2024-10-03T01:50:38.909+0000] {processor.py:186} INFO - Started process (PID=328989) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:50:38.921+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:50:38.923+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:50:38.923+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:50:43.324+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:50:43.321+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:50:43.326+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:50:43.338+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.436 seconds
[2024-10-03T01:51:13.767+0000] {processor.py:186} INFO - Started process (PID=329345) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:51:13.779+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:51:13.781+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:51:13.780+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:51:18.061+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:51:18.057+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:51:18.062+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:51:18.073+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.312 seconds
[2024-10-03T01:51:48.286+0000] {processor.py:186} INFO - Started process (PID=329693) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:51:48.288+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:51:48.290+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:51:48.290+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:51:52.872+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:51:52.868+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:51:52.874+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:51:52.888+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.608 seconds
[2024-10-03T01:52:23.046+0000] {processor.py:186} INFO - Started process (PID=330052) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:52:23.047+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:52:23.048+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:52:23.048+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:52:27.417+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:52:27.414+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:52:27.418+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:52:27.431+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.392 seconds
[2024-10-03T01:52:57.712+0000] {processor.py:186} INFO - Started process (PID=330405) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:52:57.725+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:52:57.726+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:52:57.726+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:53:02.744+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:53:02.740+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:53:02.745+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:53:02.769+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.065 seconds
[2024-10-03T01:53:33.278+0000] {processor.py:186} INFO - Started process (PID=330770) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:53:33.280+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:53:33.282+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:53:33.281+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:53:37.658+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:53:37.655+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:53:37.660+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:53:37.683+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.412 seconds
[2024-10-03T01:54:07.954+0000] {processor.py:186} INFO - Started process (PID=331117) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:54:07.967+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:54:07.968+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:54:07.968+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:54:12.550+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:54:12.547+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:54:12.552+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:54:12.563+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.615 seconds
[2024-10-03T01:54:43.214+0000] {processor.py:186} INFO - Started process (PID=331464) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:54:43.218+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:54:43.219+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:54:43.219+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:54:47.768+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:54:47.764+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:54:47.769+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:54:47.794+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.589 seconds
[2024-10-03T01:55:18.558+0000] {processor.py:186} INFO - Started process (PID=331818) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:55:18.570+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:55:18.571+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:55:18.571+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:55:23.021+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:55:23.018+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:55:23.023+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:55:23.046+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.494 seconds
[2024-10-03T01:55:53.267+0000] {processor.py:186} INFO - Started process (PID=332165) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:55:53.280+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:55:53.281+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:55:53.281+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:55:57.562+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:55:57.560+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:55:57.564+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:55:57.584+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.323 seconds
[2024-10-03T01:56:27.655+0000] {processor.py:186} INFO - Started process (PID=332521) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:56:27.667+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:56:27.669+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:56:27.668+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:56:32.111+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:56:32.107+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:56:32.112+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:56:32.126+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.479 seconds
[2024-10-03T01:57:02.634+0000] {processor.py:186} INFO - Started process (PID=332881) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:57:02.636+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:57:02.637+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:57:02.637+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:57:07.152+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:57:07.149+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:57:07.154+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:57:07.165+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.537 seconds
[2024-10-03T01:57:37.680+0000] {processor.py:186} INFO - Started process (PID=333241) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:57:37.692+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:57:37.694+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:57:37.693+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:57:41.912+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:57:41.908+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:57:41.913+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:57:41.925+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.251 seconds
[2024-10-03T01:58:12.359+0000] {processor.py:186} INFO - Started process (PID=333587) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:58:12.371+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:58:12.373+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:58:12.372+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:58:16.545+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:58:16.541+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:58:16.546+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:58:16.567+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.216 seconds
[2024-10-03T01:58:46.899+0000] {processor.py:186} INFO - Started process (PID=333934) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:58:46.912+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:58:46.913+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:58:46.913+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:58:51.288+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:58:51.285+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:58:51.289+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:58:51.305+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.412 seconds
[2024-10-03T01:59:21.775+0000] {processor.py:186} INFO - Started process (PID=334283) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:59:21.776+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:59:21.777+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:59:21.777+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:59:26.163+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:59:26.160+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T01:59:26.165+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:59:26.176+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.408 seconds
[2024-10-03T01:59:56.291+0000] {processor.py:186} INFO - Started process (PID=334638) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T01:59:56.294+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T01:59:56.295+0000] {logging_mixin.py:190} INFO - [2024-10-03T01:59:56.295+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:00:00.547+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:00:00.544+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T02:00:00.549+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:00:00.560+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.275 seconds
[2024-10-03T02:00:30.658+0000] {processor.py:186} INFO - Started process (PID=334996) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:00:30.659+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T02:00:30.661+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:00:30.660+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:00:35.385+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:00:35.379+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T02:00:35.387+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:00:35.405+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.754 seconds
[2024-10-03T02:01:06.359+0000] {processor.py:186} INFO - Started process (PID=335350) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:01:06.360+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T02:01:06.361+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:01:06.361+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:01:10.763+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:01:10.759+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T02:01:10.764+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:01:10.788+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.436 seconds
[2024-10-03T02:01:41.593+0000] {processor.py:186} INFO - Started process (PID=335704) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:01:41.606+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T02:01:41.607+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:01:41.607+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:01:46.334+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:01:46.331+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T02:01:46.336+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:01:46.358+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.772 seconds
[2024-10-03T02:02:16.487+0000] {processor.py:186} INFO - Started process (PID=336065) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:02:16.489+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T02:02:16.490+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:02:16.490+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:02:20.942+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:02:20.938+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T02:02:20.944+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:02:20.967+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.487 seconds
[2024-10-03T02:02:51.680+0000] {processor.py:186} INFO - Started process (PID=336414) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:02:51.682+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T02:02:51.684+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:02:51.683+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:02:56.053+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:02:56.050+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T02:02:56.054+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:02:56.064+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.390 seconds
[2024-10-03T02:03:26.466+0000] {processor.py:186} INFO - Started process (PID=336761) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:03:26.477+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T02:03:26.479+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:03:26.479+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:03:30.779+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:03:30.773+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T02:03:30.781+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:03:30.792+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.333 seconds
[2024-10-03T02:04:01.097+0000] {processor.py:186} INFO - Started process (PID=337110) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:04:01.109+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T02:04:01.111+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:04:01.110+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:04:05.537+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:04:05.534+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T02:04:05.539+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:04:05.551+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.461 seconds
[2024-10-03T02:04:35.604+0000] {processor.py:186} INFO - Started process (PID=337476) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:04:35.616+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T02:04:35.617+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:04:35.617+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:04:40.209+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:04:40.205+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T02:04:40.210+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:04:40.224+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.627 seconds
[2024-10-03T02:05:11.109+0000] {processor.py:186} INFO - Started process (PID=337831) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:05:11.110+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T02:05:11.112+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:05:11.111+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:05:15.876+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:05:15.872+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T02:05:15.878+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:05:15.890+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.789 seconds
[2024-10-03T02:05:46.492+0000] {processor.py:186} INFO - Started process (PID=338186) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:05:46.493+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T02:05:46.495+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:05:46.494+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:05:51.071+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:05:51.066+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T02:05:51.073+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:05:51.097+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.614 seconds
[2024-10-03T02:06:21.148+0000] {processor.py:186} INFO - Started process (PID=338540) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:06:21.149+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T02:06:21.151+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:06:21.151+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:06:25.830+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:06:25.827+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T02:06:25.832+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:06:25.845+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.703 seconds
[2024-10-03T02:06:56.112+0000] {processor.py:186} INFO - Started process (PID=338895) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:06:56.113+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T02:06:56.115+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:06:56.115+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:07:00.535+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:07:00.531+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T02:07:00.536+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:07:00.563+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.457 seconds
[2024-10-03T02:07:30.911+0000] {processor.py:186} INFO - Started process (PID=339244) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:07:30.923+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T02:07:30.925+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:07:30.924+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:07:35.786+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:07:35.782+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T02:07:35.788+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:07:35.810+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.905 seconds
[2024-10-03T02:08:06.488+0000] {processor.py:186} INFO - Started process (PID=339596) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:08:06.500+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T02:08:06.501+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:08:06.501+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:08:10.935+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:08:10.931+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T02:08:10.937+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:08:10.959+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.479 seconds
[2024-10-03T02:08:41.018+0000] {processor.py:186} INFO - Started process (PID=339948) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:08:41.020+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T02:08:41.021+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:08:41.021+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:08:45.562+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:08:45.559+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T02:08:45.564+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:08:45.575+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.564 seconds
[2024-10-03T02:09:16.011+0000] {processor.py:186} INFO - Started process (PID=340306) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:09:16.023+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T02:09:16.024+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:09:16.024+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:09:20.569+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:09:20.564+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T02:09:20.571+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:09:20.596+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.592 seconds
[2024-10-03T02:09:51.344+0000] {processor.py:186} INFO - Started process (PID=340659) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:09:51.356+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T02:09:51.357+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:09:51.357+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:09:55.820+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:09:55.817+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T02:09:55.821+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:09:55.834+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.498 seconds
[2024-10-03T02:10:26.512+0000] {processor.py:186} INFO - Started process (PID=341022) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:10:26.516+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T02:10:26.518+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:10:26.517+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:10:32.360+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:10:32.354+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T02:10:32.363+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:10:32.388+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.885 seconds
[2024-10-03T02:11:02.467+0000] {processor.py:186} INFO - Started process (PID=341372) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:11:02.468+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T02:11:02.470+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:11:02.469+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:11:07.687+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:11:07.683+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T02:11:07.689+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:11:07.712+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.252 seconds
[2024-10-03T02:11:37.927+0000] {processor.py:186} INFO - Started process (PID=341732) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:11:37.929+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T02:11:37.930+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:11:37.930+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:11:42.922+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:11:42.917+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T02:11:42.924+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:11:42.938+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.018 seconds
[2024-10-03T02:12:13.529+0000] {processor.py:186} INFO - Started process (PID=342087) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:12:13.541+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T02:12:13.542+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:12:13.542+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:12:18.136+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:12:18.133+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T02:12:18.138+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:12:18.149+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.627 seconds
[2024-10-03T02:12:48.913+0000] {processor.py:186} INFO - Started process (PID=342438) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:12:48.926+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T02:12:48.927+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:12:48.927+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:12:53.623+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:12:53.619+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T02:12:53.625+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:12:53.639+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.732 seconds
[2024-10-03T02:13:24.165+0000] {processor.py:186} INFO - Started process (PID=342786) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:13:24.177+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T02:13:24.179+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:13:24.178+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:13:28.944+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:13:28.939+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T02:13:28.946+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:13:28.959+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.801 seconds
[2024-10-03T02:13:59.170+0000] {processor.py:186} INFO - Started process (PID=343152) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:13:59.172+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T02:13:59.173+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:13:59.173+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:14:03.750+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:14:03.744+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T02:14:03.753+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:14:03.779+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.616 seconds
[2024-10-03T02:14:34.252+0000] {processor.py:186} INFO - Started process (PID=343499) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:14:34.264+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T02:14:34.266+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:14:34.265+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:14:38.949+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:14:38.946+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T02:14:38.951+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:14:38.974+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.729 seconds
[2024-10-03T02:15:09.277+0000] {processor.py:186} INFO - Started process (PID=343848) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:15:09.289+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T02:15:09.291+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:15:09.290+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:15:13.807+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:15:13.801+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T02:15:13.809+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:15:13.823+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.554 seconds
[2024-10-03T02:15:44.715+0000] {processor.py:186} INFO - Started process (PID=344206) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:15:44.727+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T02:15:44.728+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:15:44.728+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:15:49.466+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:15:49.462+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T02:15:49.467+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:15:49.490+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.783 seconds
[2024-10-03T02:16:19.684+0000] {processor.py:186} INFO - Started process (PID=344558) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:16:19.686+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T02:16:19.687+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:16:19.687+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:16:24.341+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:16:24.337+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T02:16:24.343+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:16:24.356+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.679 seconds
[2024-10-03T02:16:54.995+0000] {processor.py:186} INFO - Started process (PID=344911) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:16:55.007+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T02:16:55.009+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:16:55.008+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:16:59.255+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:16:59.251+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T02:16:59.257+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:16:59.269+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.281 seconds
[2024-10-03T02:17:29.331+0000] {processor.py:186} INFO - Started process (PID=345259) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:17:29.333+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T02:17:29.335+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:17:29.334+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:17:34.072+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:17:34.068+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T02:17:34.074+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:17:34.100+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.775 seconds
[2024-10-03T02:18:04.809+0000] {processor.py:186} INFO - Started process (PID=345615) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:18:04.810+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T02:18:04.811+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:18:04.811+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:18:09.440+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:18:09.437+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T02:18:09.442+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:18:09.465+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.663 seconds
[2024-10-03T02:18:39.524+0000] {processor.py:186} INFO - Started process (PID=345977) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:18:39.537+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T02:18:39.538+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:18:39.538+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:18:44.657+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:18:44.653+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T02:18:44.658+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:18:44.671+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.153 seconds
[2024-10-03T02:19:14.886+0000] {processor.py:186} INFO - Started process (PID=346332) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:19:14.887+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T02:19:14.889+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:19:14.889+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:19:19.484+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:19:19.481+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T02:19:19.486+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:19:19.508+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.630 seconds
[2024-10-03T02:19:50.253+0000] {processor.py:186} INFO - Started process (PID=346687) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:19:50.255+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T02:19:50.257+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:19:50.257+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:19:54.910+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:19:54.905+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T02:19:54.913+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:19:54.929+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.683 seconds
[2024-10-03T02:20:25.670+0000] {processor.py:186} INFO - Started process (PID=347040) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:20:25.682+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T02:20:25.685+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:20:25.685+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:20:30.425+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:20:30.420+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T02:20:30.426+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:20:30.439+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.779 seconds
[2024-10-03T02:21:00.601+0000] {processor.py:186} INFO - Started process (PID=347394) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:21:00.603+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T02:21:00.604+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:21:00.604+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:21:05.391+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:21:05.388+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T02:21:05.392+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:21:05.416+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.821 seconds
[2024-10-03T02:21:35.811+0000] {processor.py:186} INFO - Started process (PID=347746) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:21:35.817+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T02:21:35.818+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:21:35.818+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:21:40.468+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:21:40.461+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T02:21:40.471+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:21:40.497+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.692 seconds
[2024-10-03T02:22:10.923+0000] {processor.py:186} INFO - Started process (PID=348094) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:22:10.924+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T02:22:10.926+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:22:10.925+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:22:15.663+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:22:15.659+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T02:22:15.664+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:22:15.687+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.772 seconds
[2024-10-03T02:22:45.773+0000] {processor.py:186} INFO - Started process (PID=348454) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:22:45.775+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T02:22:45.776+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:22:45.776+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:22:50.331+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:22:50.328+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T02:22:50.333+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:22:50.356+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.589 seconds
[2024-10-03T02:23:20.797+0000] {processor.py:186} INFO - Started process (PID=348813) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:23:20.798+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T02:23:20.800+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:23:20.800+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:23:25.234+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:23:25.230+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T02:23:25.235+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:23:25.248+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.458 seconds
[2024-10-03T02:23:56.130+0000] {processor.py:186} INFO - Started process (PID=349166) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:23:56.141+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T02:23:56.143+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:23:56.142+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:24:00.642+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:24:00.638+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T02:24:00.644+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:24:00.667+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.546 seconds
[2024-10-03T02:24:31.174+0000] {processor.py:186} INFO - Started process (PID=349519) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:24:31.186+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T02:24:31.188+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:24:31.187+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:24:35.769+0000] {logging_mixin.py:190} INFO - [2024-10-03T02:24:35.764+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-03T02:24:35.772+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T02:24:35.786+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.618 seconds
[2024-10-03T04:10:23.426+0000] {processor.py:186} INFO - Started process (PID=349778) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T04:10:23.428+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T04:10:23.430+0000] {logging_mixin.py:190} INFO - [2024-10-03T04:10:23.429+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T04:10:53.447+0000] {logging_mixin.py:190} INFO - [2024-10-03T04:10:53.436+0000] {timeout.py:68} ERROR - Process timed out, PID: 349778
[2024-10-03T04:10:53.512+0000] {logging_mixin.py:190} INFO - [2024-10-03T04:10:53.461+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 5, in <module>
    from etl_pipeline.tasks.warehouse.main import warehouse
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 4, in <module>
    from etl_pipeline.tasks.warehouse.components.extract_transform import ExtractTransform
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/components/extract_transform.py", line 5, in <module>
    from etl_pipeline.tasks.warehouse.components.validations import Validation, ValidationType
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/components/validations.py", line 11, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 500, in getOrCreate
    session = SparkSession(sc, options=self._options)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 581, in __init__
    self._jvm.SparkSession.getDefaultSession().isDefined()
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py", line 1535, in __getattr__
    answer = self._gateway_client.send_command(command)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
                          ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/socket.py", line 720, in readinto
    return self._sock.recv_into(b)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/etl_pipeline/run.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.10.2/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.10.2/best-practices.html#reducing-dag-complexity, PID: 349778
[2024-10-03T04:10:53.556+0000] {logging_mixin.py:190} INFO - [2024-10-03T04:10:53.541+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2024-10-03T04:10:53.576+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T04:10:53.970+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 30.556 seconds
[2024-10-03T05:55:58.550+0000] {processor.py:186} INFO - Started process (PID=192) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T05:55:58.552+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T05:55:58.555+0000] {logging_mixin.py:190} INFO - [2024-10-03T05:55:58.554+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T05:56:10.971+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T05:56:11.117+0000] {logging_mixin.py:190} INFO - [2024-10-03T05:56:11.116+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T05:56:11.142+0000] {logging_mixin.py:190} INFO - [2024-10-03T05:56:11.142+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-03T05:56:11.264+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 12.723 seconds
[2024-10-03T05:56:43.499+0000] {processor.py:186} INFO - Started process (PID=1439) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T05:56:43.512+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T05:56:43.615+0000] {logging_mixin.py:190} INFO - [2024-10-03T05:56:43.607+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T05:56:59.766+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T05:56:59.898+0000] {logging_mixin.py:190} INFO - [2024-10-03T05:56:59.897+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T05:57:00.856+0000] {logging_mixin.py:190} INFO - [2024-10-03T05:57:00.856+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T05:57:00.894+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 17.633 seconds
[2024-10-03T05:57:31.542+0000] {processor.py:186} INFO - Started process (PID=2477) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T05:57:31.543+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T05:57:31.547+0000] {logging_mixin.py:190} INFO - [2024-10-03T05:57:31.546+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T05:57:43.095+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T05:57:44.234+0000] {logging_mixin.py:190} INFO - [2024-10-03T05:57:44.223+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T05:57:44.324+0000] {logging_mixin.py:190} INFO - [2024-10-03T05:57:44.324+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T05:57:44.396+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 12.866 seconds
[2024-10-03T05:58:16.970+0000] {processor.py:186} INFO - Started process (PID=3284) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T05:58:16.974+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T05:58:16.980+0000] {logging_mixin.py:190} INFO - [2024-10-03T05:58:16.979+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T05:58:30.762+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T05:58:30.813+0000] {logging_mixin.py:190} INFO - [2024-10-03T05:58:30.812+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T05:58:30.855+0000] {logging_mixin.py:190} INFO - [2024-10-03T05:58:30.855+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T05:58:30.884+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 13.931 seconds
[2024-10-03T05:59:01.000+0000] {processor.py:186} INFO - Started process (PID=4091) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T05:59:01.002+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T05:59:01.005+0000] {logging_mixin.py:190} INFO - [2024-10-03T05:59:01.004+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T05:59:09.385+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T05:59:09.462+0000] {logging_mixin.py:190} INFO - [2024-10-03T05:59:09.460+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T05:59:09.968+0000] {logging_mixin.py:190} INFO - [2024-10-03T05:59:09.966+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T05:59:10.016+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 9.024 seconds
[2024-10-03T05:59:40.718+0000] {processor.py:186} INFO - Started process (PID=4874) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T05:59:40.721+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T05:59:40.735+0000] {logging_mixin.py:190} INFO - [2024-10-03T05:59:40.727+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T05:59:54.180+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T05:59:54.233+0000] {logging_mixin.py:190} INFO - [2024-10-03T05:59:54.233+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T05:59:54.473+0000] {logging_mixin.py:190} INFO - [2024-10-03T05:59:54.473+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T05:59:54.503+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 13.845 seconds
[2024-10-03T06:00:24.955+0000] {processor.py:186} INFO - Started process (PID=5484) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:00:24.956+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:00:24.961+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:00:24.961+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:00:32.052+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:00:32.090+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:00:32.089+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:00:32.122+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:00:32.121+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:00:32.145+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 7.202 seconds
[2024-10-03T06:01:02.795+0000] {processor.py:186} INFO - Started process (PID=5838) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:01:02.809+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:01:02.822+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:01:02.821+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:01:12.373+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:01:12.412+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:01:12.412+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:01:12.743+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:01:12.742+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:01:12.767+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 10.032 seconds
[2024-10-03T06:01:43.511+0000] {processor.py:186} INFO - Started process (PID=6247) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:01:43.512+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:01:43.516+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:01:43.515+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:01:49.349+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:01:49.442+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:01:49.441+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:01:49.680+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:01:49.680+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:01:49.705+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.202 seconds
[2024-10-03T06:02:19.744+0000] {processor.py:186} INFO - Started process (PID=6598) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:02:19.756+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:02:19.759+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:02:19.759+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:02:26.023+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:02:26.271+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:02:26.270+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:02:26.305+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:02:26.305+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:02:26.328+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.591 seconds
[2024-10-03T06:02:56.386+0000] {processor.py:186} INFO - Started process (PID=6973) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:02:56.388+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:02:56.392+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:02:56.391+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:03:02.557+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:03:02.603+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:03:02.602+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:03:02.636+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:03:02.635+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:03:02.662+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.287 seconds
[2024-10-03T06:03:33.376+0000] {processor.py:186} INFO - Started process (PID=7341) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:03:33.377+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:03:33.380+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:03:33.380+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:03:39.827+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:03:39.878+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:03:39.878+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:03:40.124+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:03:40.124+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:03:40.158+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.789 seconds
[2024-10-03T06:04:10.906+0000] {processor.py:186} INFO - Started process (PID=7702) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:04:10.908+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:04:10.911+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:04:10.911+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:04:18.747+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:04:19.021+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:04:19.020+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:04:19.052+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:04:19.051+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:04:19.084+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 8.190 seconds
[2024-10-03T06:04:49.445+0000] {processor.py:186} INFO - Started process (PID=8054) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:04:49.447+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:04:49.450+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:04:49.449+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:04:55.213+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:04:55.246+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:04:55.245+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:04:55.270+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:04:55.270+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:04:55.304+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.865 seconds
[2024-10-03T06:05:26.019+0000] {processor.py:186} INFO - Started process (PID=8409) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:05:26.031+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:05:26.033+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:05:26.033+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:05:30.722+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:05:30.775+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:05:30.774+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:05:30.811+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:05:30.810+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:05:30.841+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.830 seconds
[2024-10-03T06:06:01.659+0000] {processor.py:186} INFO - Started process (PID=8768) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:06:01.660+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:06:01.663+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:06:01.663+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:06:06.242+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:06:06.282+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:06:06.282+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:06:06.478+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:06:06.477+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:06:06.507+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.855 seconds
[2024-10-03T06:06:37.436+0000] {processor.py:186} INFO - Started process (PID=9132) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:06:37.437+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:06:37.440+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:06:37.440+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:06:42.095+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:06:42.310+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:06:42.309+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:06:42.335+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:06:42.335+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:06:42.356+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.927 seconds
[2024-10-03T06:07:12.567+0000] {processor.py:186} INFO - Started process (PID=9481) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:07:12.568+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:07:12.571+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:07:12.571+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:07:17.840+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:07:17.872+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:07:17.872+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:07:17.898+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:07:17.897+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:07:17.919+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.358 seconds
[2024-10-03T06:07:48.123+0000] {processor.py:186} INFO - Started process (PID=9837) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:07:48.126+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:07:48.129+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:07:48.129+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:07:55.506+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:07:55.546+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:07:55.546+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:07:55.777+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:07:55.777+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:07:55.798+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 7.684 seconds
[2024-10-03T06:08:26.216+0000] {processor.py:186} INFO - Started process (PID=10191) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:08:26.217+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:08:26.220+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:08:26.220+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:08:30.914+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:08:31.148+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:08:31.147+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:08:31.172+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:08:31.171+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:08:31.201+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.990 seconds
[2024-10-03T06:09:01.270+0000] {processor.py:186} INFO - Started process (PID=10557) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:09:01.282+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:09:01.284+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:09:01.284+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:09:06.519+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:09:06.732+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:09:06.732+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:09:06.757+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:09:06.756+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:09:06.777+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.515 seconds
[2024-10-03T06:09:36.924+0000] {processor.py:186} INFO - Started process (PID=10912) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:09:36.936+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:09:36.939+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:09:36.938+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:09:42.470+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:09:42.519+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:09:42.518+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:09:42.553+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:09:42.552+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:09:42.581+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.663 seconds
[2024-10-03T06:10:12.857+0000] {processor.py:186} INFO - Started process (PID=11278) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:10:12.869+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:10:12.872+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:10:12.871+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:10:19.892+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:10:19.938+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:10:19.937+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:10:20.196+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:10:20.196+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:10:20.219+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 7.368 seconds
[2024-10-03T06:10:50.769+0000] {processor.py:186} INFO - Started process (PID=11634) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:10:50.772+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:10:50.774+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:10:50.774+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:10:56.943+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:10:57.229+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:10:57.228+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:10:57.256+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:10:57.256+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:10:57.291+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.529 seconds
[2024-10-03T06:11:27.395+0000] {processor.py:186} INFO - Started process (PID=11995) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:11:27.398+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:11:27.403+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:11:27.402+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:11:35.735+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:11:35.775+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:11:35.774+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:11:35.809+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:11:35.809+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:11:35.851+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 8.471 seconds
[2024-10-03T06:12:06.038+0000] {processor.py:186} INFO - Started process (PID=12364) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:12:06.050+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:12:06.053+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:12:06.053+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:12:11.364+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:12:11.410+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:12:11.410+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:12:11.696+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:12:11.696+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:12:11.718+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.686 seconds
[2024-10-03T06:12:42.688+0000] {processor.py:186} INFO - Started process (PID=12720) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:12:42.700+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:12:42.702+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:12:42.701+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:12:47.408+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:12:47.693+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:12:47.692+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:12:47.726+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:12:47.725+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:12:47.762+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.082 seconds
[2024-10-03T06:13:18.352+0000] {processor.py:186} INFO - Started process (PID=13080) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:13:18.364+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:13:18.366+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:13:18.366+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:13:23.018+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:13:23.049+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:13:23.049+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:13:23.075+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:13:23.074+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:13:23.107+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.761 seconds
[2024-10-03T06:13:53.474+0000] {processor.py:186} INFO - Started process (PID=13428) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:13:53.476+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:13:53.479+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:13:53.479+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:13:58.289+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:13:58.342+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:13:58.341+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:13:58.595+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:13:58.594+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:13:58.619+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.151 seconds
[2024-10-03T06:14:29.274+0000] {processor.py:186} INFO - Started process (PID=13779) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:14:29.286+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:14:29.289+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:14:29.288+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:14:33.563+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:14:33.593+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:14:33.593+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:14:33.783+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:14:33.783+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:14:33.801+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.534 seconds
[2024-10-03T06:15:03.867+0000] {processor.py:186} INFO - Started process (PID=14133) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:15:03.869+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:15:03.872+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:15:03.872+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:15:08.311+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:15:08.551+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:15:08.551+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:15:08.578+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:15:08.578+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:15:08.610+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.749 seconds
[2024-10-03T06:15:39.195+0000] {processor.py:186} INFO - Started process (PID=14493) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:15:39.197+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:15:39.201+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:15:39.201+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:15:45.997+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:15:46.042+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:15:46.041+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:15:46.074+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:15:46.073+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:15:46.105+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.919 seconds
[2024-10-03T06:16:16.698+0000] {processor.py:186} INFO - Started process (PID=14857) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:16:16.709+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:16:16.716+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:16:16.715+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:16:31.684+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:16:31.746+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:16:31.745+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:16:32.169+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:16:32.168+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:16:32.208+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 15.530 seconds
[2024-10-03T06:17:02.701+0000] {processor.py:186} INFO - Started process (PID=15230) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:17:02.703+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:17:02.706+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:17:02.706+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:17:08.119+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:17:08.355+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:17:08.355+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:17:08.385+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:17:08.384+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:17:08.408+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.715 seconds
[2024-10-03T06:17:49.847+0000] {processor.py:186} INFO - Started process (PID=193) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:17:49.849+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:17:49.854+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:17:49.853+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:18:06.508+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:18:06.757+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:18:06.756+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:18:06.789+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:18:06.789+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:18:06.830+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 16.996 seconds
[2024-10-03T06:18:37.545+0000] {processor.py:186} INFO - Started process (PID=579) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:18:37.551+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:18:37.558+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:18:37.557+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:18:58.664+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:18:58.720+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:18:58.719+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:18:59.221+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:18:59.220+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:18:59.261+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 21.758 seconds
[2024-10-03T06:19:30.055+0000] {processor.py:186} INFO - Started process (PID=1277) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:19:30.057+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:19:30.059+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:19:30.058+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:19:36.621+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:19:36.619+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 5, in <module>
    from etl_pipeline.tasks.warehouse.main import warehouse
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 29, in <module>
    warehouse()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 96, in _create_task_group
    with tg_factory(add_suffix_on_collision=True, **self.tg_kwargs) as task_group:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/task_group.py", line 139, in __init__
    raise AirflowException("TaskGroup can only be used inside a dag")
airflow.exceptions.AirflowException: TaskGroup can only be used inside a dag
[2024-10-03T06:19:36.623+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:19:36.661+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.612 seconds
[2024-10-03T06:20:06.721+0000] {processor.py:186} INFO - Started process (PID=1662) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:20:06.722+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:20:06.725+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:20:06.725+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:20:20.100+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:20:20.488+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:20:20.488+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:20:20.515+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:20:20.514+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:20:20.544+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 13.829 seconds
[2024-10-03T06:20:50.647+0000] {processor.py:186} INFO - Started process (PID=2024) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:20:50.649+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:20:50.652+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:20:50.651+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:21:01.874+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:21:01.984+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:21:01.982+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:21:02.372+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:21:02.372+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:21:02.426+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 11.788 seconds
[2024-10-03T06:21:32.624+0000] {processor.py:186} INFO - Started process (PID=2602) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:21:32.629+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:21:32.635+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:21:32.634+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:21:42.036+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:21:42.305+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:21:42.304+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:21:42.338+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:21:42.338+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:21:42.366+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 9.765 seconds
[2024-10-03T06:22:12.828+0000] {processor.py:186} INFO - Started process (PID=2992) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:22:12.841+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:22:12.845+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:22:12.844+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:22:20.531+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:22:20.586+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:22:20.585+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:22:20.624+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:22:20.624+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:22:20.654+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 7.836 seconds
[2024-10-03T06:22:50.714+0000] {processor.py:186} INFO - Started process (PID=3403) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:22:50.716+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:22:50.720+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:22:50.719+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:22:57.752+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:22:57.803+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:22:57.802+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:22:58.029+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:22:58.029+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:22:58.051+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 7.350 seconds
[2024-10-03T06:23:28.725+0000] {processor.py:186} INFO - Started process (PID=3838) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:23:28.728+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:23:28.736+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:23:28.735+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:23:46.272+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:23:46.811+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:23:46.810+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:23:46.855+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:23:46.855+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:23:46.890+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 18.194 seconds
[2024-10-03T06:24:17.527+0000] {processor.py:186} INFO - Started process (PID=4555) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:24:17.539+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:24:17.542+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:24:17.542+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:24:24.301+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:24:24.381+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:24:24.380+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:24:24.436+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:24:24.435+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:24:24.484+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.966 seconds
[2024-10-03T06:24:54.638+0000] {processor.py:186} INFO - Started process (PID=4924) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:24:54.640+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:24:54.643+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:24:54.642+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:25:02.830+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:25:02.897+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:25:02.895+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:25:02.943+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:25:02.942+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:25:02.997+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 8.366 seconds
[2024-10-03T06:25:33.709+0000] {processor.py:186} INFO - Started process (PID=5448) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:25:33.710+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:25:33.713+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:25:33.712+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:25:44.870+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:25:45.685+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:25:45.684+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:25:45.770+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:25:45.769+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:25:45.819+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 12.117 seconds
[2024-10-03T06:26:16.021+0000] {processor.py:186} INFO - Started process (PID=5968) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:26:16.042+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:26:16.045+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:26:16.044+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:26:24.923+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:26:25.428+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:26:25.425+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:26:25.492+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:26:25.491+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:26:25.538+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 9.524 seconds
[2024-10-03T06:26:55.759+0000] {processor.py:186} INFO - Started process (PID=6807) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:26:55.761+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:26:55.763+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:26:55.763+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:27:01.303+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:27:01.524+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:27:01.523+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:27:01.556+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:27:01.555+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:27:01.587+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.835 seconds
[2024-10-03T06:27:31.708+0000] {processor.py:186} INFO - Started process (PID=7174) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:27:31.720+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:27:31.722+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:27:31.722+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:27:36.040+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:27:36.078+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:27:36.077+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:27:36.284+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:27:36.284+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:27:36.304+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.602 seconds
[2024-10-03T06:28:06.481+0000] {processor.py:186} INFO - Started process (PID=7529) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:28:06.493+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:28:06.496+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:28:06.496+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:28:10.998+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:28:11.199+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:28:11.198+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:28:11.220+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:28:11.219+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:28:11.247+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.773 seconds
[2024-10-03T06:28:41.704+0000] {processor.py:186} INFO - Started process (PID=7879) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:28:41.716+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:28:41.719+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:28:41.718+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:28:46.065+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:28:46.093+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:28:46.092+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:28:46.113+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:28:46.113+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:28:46.141+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.443 seconds
[2024-10-03T06:29:16.267+0000] {processor.py:186} INFO - Started process (PID=8229) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:29:16.270+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:29:16.273+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:29:16.272+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:29:20.522+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:29:20.551+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:29:20.551+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:29:20.725+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:29:20.725+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:29:20.754+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.493 seconds
[2024-10-03T06:29:51.064+0000] {processor.py:186} INFO - Started process (PID=8583) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:29:51.065+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:29:51.067+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:29:51.067+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:29:55.282+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:29:55.311+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:29:55.311+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:29:55.486+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:29:55.486+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:29:55.514+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.457 seconds
[2024-10-03T06:30:26.332+0000] {processor.py:186} INFO - Started process (PID=8933) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:30:26.334+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:30:26.337+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:30:26.336+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:30:30.705+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:30:30.901+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:30:30.901+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:30:30.923+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:30:30.922+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:30:30.950+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.624 seconds
[2024-10-03T06:31:01.900+0000] {processor.py:186} INFO - Started process (PID=9297) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:31:01.912+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:31:01.915+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:31:01.914+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:31:07.160+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:31:07.193+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:31:07.192+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:31:07.216+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:31:07.215+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:31:07.248+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.354 seconds
[2024-10-03T06:31:37.402+0000] {processor.py:186} INFO - Started process (PID=9661) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:31:37.404+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:31:37.406+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:31:37.406+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:31:41.917+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:31:41.953+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:31:41.952+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:31:42.179+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:31:42.179+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:31:42.199+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.804 seconds
[2024-10-03T06:32:12.265+0000] {processor.py:186} INFO - Started process (PID=10017) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:32:12.266+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:32:12.269+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:32:12.269+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:32:16.469+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:32:16.688+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:32:16.688+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:32:16.715+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:32:16.715+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:32:16.745+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.487 seconds
[2024-10-03T06:32:47.202+0000] {processor.py:186} INFO - Started process (PID=10366) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:32:47.214+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:32:47.217+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:32:47.216+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:32:52.133+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:32:52.168+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:32:52.167+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:32:52.192+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:32:52.192+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:32:52.224+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.028 seconds
[2024-10-03T06:33:22.799+0000] {processor.py:186} INFO - Started process (PID=10717) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:33:22.812+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:33:22.814+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:33:22.814+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:33:27.788+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:33:27.840+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:33:27.839+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:33:27.874+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:33:27.873+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:33:27.912+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.120 seconds
[2024-10-03T06:33:58.240+0000] {processor.py:186} INFO - Started process (PID=11074) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:33:58.252+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:33:58.255+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:33:58.254+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:34:02.606+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:34:02.644+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:34:02.644+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:34:02.851+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:34:02.851+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:34:02.877+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.643 seconds
[2024-10-03T06:34:33.025+0000] {processor.py:186} INFO - Started process (PID=11433) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:34:33.026+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:34:33.028+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:34:33.028+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:34:37.740+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:34:37.977+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:34:37.976+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:34:38.005+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:34:38.004+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:34:38.025+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.008 seconds
[2024-10-03T06:35:08.371+0000] {processor.py:186} INFO - Started process (PID=11789) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:35:08.373+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:35:08.376+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:35:08.375+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:35:14.725+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:35:14.774+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:35:14.773+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:35:14.806+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:35:14.806+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:35:14.836+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.475 seconds
[2024-10-03T06:35:45.267+0000] {processor.py:186} INFO - Started process (PID=12155) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:35:45.268+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:35:45.270+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:35:45.270+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:35:50.796+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:35:50.836+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:35:50.835+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:35:50.866+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:35:50.866+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:35:50.896+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.638 seconds
[2024-10-03T06:36:21.568+0000] {processor.py:186} INFO - Started process (PID=12512) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:36:21.569+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:36:21.572+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:36:21.571+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:36:25.765+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:36:25.962+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:36:25.962+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:36:25.983+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:36:25.983+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:36:26.011+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.450 seconds
[2024-10-03T06:36:56.180+0000] {processor.py:186} INFO - Started process (PID=12861) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:36:56.192+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:36:56.194+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:36:56.194+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:37:00.632+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:37:00.660+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:37:00.660+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:37:00.680+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:37:00.680+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:37:00.698+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.525 seconds
[2024-10-03T06:37:30.794+0000] {processor.py:186} INFO - Started process (PID=13215) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:37:30.798+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:37:30.800+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:37:30.800+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:37:38.815+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:37:38.881+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:37:38.880+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:37:38.940+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:37:38.940+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:37:38.986+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 8.200 seconds
[2024-10-03T06:38:09.440+0000] {processor.py:186} INFO - Started process (PID=14051) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:38:09.442+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:38:09.445+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:38:09.445+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:38:15.719+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:38:15.872+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:38:15.871+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:38:15.899+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:38:15.898+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:38:15.934+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.503 seconds
[2024-10-03T06:38:46.444+0000] {processor.py:186} INFO - Started process (PID=14424) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:38:46.456+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:38:46.458+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:38:46.458+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:38:51.792+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:38:51.829+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:38:51.829+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:38:51.858+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:38:51.857+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:38:51.897+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.459 seconds
[2024-10-03T06:39:22.225+0000] {processor.py:186} INFO - Started process (PID=14897) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:39:22.227+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:39:22.231+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:39:22.230+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:39:35.573+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:39:35.667+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:39:35.666+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:39:35.812+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:39:35.811+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:39:35.886+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 13.671 seconds
[2024-10-03T06:40:06.675+0000] {processor.py:186} INFO - Started process (PID=15421) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:40:06.678+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:40:06.704+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:40:06.694+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:40:22.650+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:40:22.695+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:40:22.695+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:40:22.724+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:40:22.724+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:40:22.759+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 16.134 seconds
[2024-10-03T06:40:53.312+0000] {processor.py:186} INFO - Started process (PID=15881) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:40:53.323+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:40:53.326+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:40:53.326+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:40:57.649+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:40:57.676+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:40:57.676+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:40:57.697+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:40:57.697+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:40:57.724+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.419 seconds
[2024-10-03T06:41:28.064+0000] {processor.py:186} INFO - Started process (PID=16228) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:41:28.076+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:41:28.079+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:41:28.079+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:41:32.471+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:41:32.501+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:41:32.501+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:41:32.524+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:41:32.523+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:41:32.548+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.490 seconds
[2024-10-03T06:42:02.973+0000] {processor.py:186} INFO - Started process (PID=16580) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:42:02.985+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:42:02.987+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:42:02.987+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:42:07.323+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:42:07.351+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:42:07.351+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:42:07.376+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:42:07.375+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:42:07.395+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.428 seconds
[2024-10-03T06:42:37.446+0000] {processor.py:186} INFO - Started process (PID=16930) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:42:37.447+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:42:37.450+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:42:37.450+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:42:41.549+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:42:41.752+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:42:41.752+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:42:41.775+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:42:41.775+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:42:41.792+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.352 seconds
[2024-10-03T06:43:11.842+0000] {processor.py:186} INFO - Started process (PID=17286) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:43:11.854+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:43:11.856+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:43:11.856+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:43:16.111+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:43:16.140+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:43:16.139+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:43:16.167+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:43:16.167+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:43:16.199+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.364 seconds
[2024-10-03T06:43:46.851+0000] {processor.py:186} INFO - Started process (PID=17645) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:43:46.854+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:43:46.857+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:43:46.857+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:43:51.752+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:43:51.789+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:43:51.788+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:43:51.819+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:43:51.819+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:43:51.843+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.999 seconds
[2024-10-03T06:44:22.148+0000] {processor.py:186} INFO - Started process (PID=18001) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:44:22.160+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:44:22.163+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:44:22.162+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:44:26.362+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:44:26.395+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:44:26.394+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:44:26.417+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:44:26.416+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:44:26.436+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.295 seconds
[2024-10-03T06:44:57.078+0000] {processor.py:186} INFO - Started process (PID=18354) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:44:57.079+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:44:57.081+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:44:57.081+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:45:01.288+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:45:01.320+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:45:01.320+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:45:01.346+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:45:01.346+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:45:01.377+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.305 seconds
[2024-10-03T06:45:31.685+0000] {processor.py:186} INFO - Started process (PID=18706) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:45:31.697+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:45:31.700+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:45:31.699+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:45:36.011+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:45:36.041+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:45:36.041+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:45:36.065+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:45:36.064+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:45:36.087+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.408 seconds
[2024-10-03T06:46:06.382+0000] {processor.py:186} INFO - Started process (PID=19053) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:46:06.384+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:46:06.387+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:46:06.386+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:46:12.431+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:46:12.479+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:46:12.478+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:46:12.514+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:46:12.513+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:46:12.549+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.173 seconds
[2024-10-03T06:46:42.760+0000] {processor.py:186} INFO - Started process (PID=19414) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:46:42.762+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:46:42.764+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:46:42.764+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:46:49.911+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:46:49.965+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:46:49.964+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:46:50.020+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:46:50.020+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:46:50.059+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 7.307 seconds
[2024-10-03T06:47:20.924+0000] {processor.py:186} INFO - Started process (PID=19781) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:47:20.936+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:47:20.938+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:47:20.938+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:47:25.169+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:47:25.201+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:47:25.200+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:47:25.224+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:47:25.224+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:47:25.244+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.327 seconds
[2024-10-03T06:47:55.447+0000] {processor.py:186} INFO - Started process (PID=20130) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:47:55.449+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:47:55.451+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:47:55.451+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:48:01.638+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:48:01.680+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:48:01.679+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:48:01.712+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:48:01.711+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:48:01.737+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.298 seconds
[2024-10-03T06:48:31.816+0000] {processor.py:186} INFO - Started process (PID=20495) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:48:31.817+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:48:31.820+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:48:31.820+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:48:38.212+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:48:38.268+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:48:38.267+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:48:38.310+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:48:38.309+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:48:38.347+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.538 seconds
[2024-10-03T06:49:08.824+0000] {processor.py:186} INFO - Started process (PID=20849) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:49:08.826+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:49:08.830+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:49:08.829+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:49:18.305+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:49:18.358+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:49:18.357+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:49:18.397+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:49:18.396+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:49:18.427+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 9.615 seconds
[2024-10-03T06:49:48.599+0000] {processor.py:186} INFO - Started process (PID=21218) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:49:48.600+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:49:48.603+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:49:48.603+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:49:57.599+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:49:57.666+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:49:57.665+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:49:57.722+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:49:57.721+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:49:57.760+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 9.169 seconds
[2024-10-03T06:50:28.249+0000] {processor.py:186} INFO - Started process (PID=21835) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:50:28.254+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:50:28.262+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:50:28.261+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:50:42.178+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:50:42.227+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:50:42.226+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:50:42.276+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:50:42.275+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:50:42.305+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 14.097 seconds
[2024-10-03T06:51:12.453+0000] {processor.py:186} INFO - Started process (PID=22300) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:51:12.454+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:51:12.458+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:51:12.457+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:51:18.652+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:51:18.696+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:51:18.695+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:51:18.729+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:51:18.729+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:51:18.752+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.308 seconds
[2024-10-03T06:51:48.975+0000] {processor.py:186} INFO - Started process (PID=22710) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:51:48.987+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:51:48.991+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:51:48.990+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:51:59.483+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:51:59.573+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:51:59.572+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:51:59.651+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:51:59.650+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:51:59.712+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 10.750 seconds
[2024-10-03T06:52:29.826+0000] {processor.py:186} INFO - Started process (PID=23376) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:52:29.838+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:52:29.844+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:52:29.844+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:52:36.920+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:52:36.968+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:52:36.968+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:52:37.006+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:52:37.006+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:52:37.047+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 7.230 seconds
[2024-10-03T06:53:07.366+0000] {processor.py:186} INFO - Started process (PID=23667) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:53:07.367+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:53:07.371+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:53:07.370+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:53:08.419+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:53:08.508+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:53:08.507+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:53:08.576+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:53:08.575+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:53:08.642+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.291 seconds
[2024-10-03T06:53:39.327+0000] {processor.py:186} INFO - Started process (PID=23827) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:53:39.339+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:53:39.343+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:53:39.343+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:53:40.187+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:53:40.245+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:53:40.244+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:53:40.291+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:53:40.291+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:53:40.326+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.008 seconds
[2024-10-03T06:54:10.822+0000] {processor.py:186} INFO - Started process (PID=23876) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:54:10.823+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:54:10.826+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:54:10.826+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:54:11.571+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:54:11.622+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:54:11.622+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:54:11.891+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:54:11.891+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:54:11.914+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.101 seconds
[2024-10-03T06:54:42.310+0000] {processor.py:186} INFO - Started process (PID=23925) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:54:42.313+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:54:42.317+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:54:42.317+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:54:43.207+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:54:43.275+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:54:43.274+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:54:43.336+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:54:43.335+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:54:43.407+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.107 seconds
[2024-10-03T06:55:13.666+0000] {processor.py:186} INFO - Started process (PID=23980) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:55:13.668+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:55:13.671+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:55:13.671+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:55:14.410+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:55:14.459+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:55:14.459+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:55:14.490+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:55:14.490+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:55:14.518+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.861 seconds
[2024-10-03T06:55:44.595+0000] {processor.py:186} INFO - Started process (PID=24029) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:55:44.608+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:55:44.611+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:55:44.610+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:55:45.302+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:55:45.338+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:55:45.337+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:55:45.367+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:55:45.367+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:55:45.591+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.004 seconds
[2024-10-03T06:56:15.859+0000] {processor.py:186} INFO - Started process (PID=24093) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:56:15.871+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:56:15.874+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:56:15.874+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:56:16.524+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:56:16.969+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:56:16.968+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:56:17.002+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:56:17.002+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:56:17.044+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.192 seconds
[2024-10-03T06:56:47.233+0000] {processor.py:186} INFO - Started process (PID=24223) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:56:47.236+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:56:47.239+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:56:47.239+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:56:48.171+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:56:48.550+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:56:48.549+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:56:48.575+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:56:48.575+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:56:48.601+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.379 seconds
[2024-10-03T06:57:18.791+0000] {processor.py:186} INFO - Started process (PID=24272) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:57:18.803+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:57:18.806+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:57:18.805+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:57:19.496+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:57:19.538+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:57:19.537+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:57:19.576+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:57:19.576+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:57:19.612+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.828 seconds
[2024-10-03T06:57:49.891+0000] {processor.py:186} INFO - Started process (PID=24321) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:57:49.893+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:57:49.896+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:57:49.895+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:57:50.540+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:57:50.578+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:57:50.578+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:57:50.611+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:57:50.610+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:57:50.810+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.927 seconds
[2024-10-03T06:58:21.012+0000] {processor.py:186} INFO - Started process (PID=24370) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:58:21.014+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:58:21.017+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:58:21.016+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:58:21.720+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:58:21.762+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:58:21.761+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:58:22.033+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:58:22.033+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:58:22.136+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.132 seconds
[2024-10-03T06:58:52.869+0000] {processor.py:186} INFO - Started process (PID=24478) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:58:52.872+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:58:52.876+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:58:52.875+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:58:54.107+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:58:54.176+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:58:54.175+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:58:54.226+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:58:54.225+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:58:54.279+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.424 seconds
[2024-10-03T06:59:24.374+0000] {processor.py:186} INFO - Started process (PID=24553) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:59:24.386+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:59:24.388+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:59:24.388+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:59:25.047+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:59:25.165+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:59:25.164+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:59:25.227+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:59:25.227+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:59:25.275+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.909 seconds
[2024-10-03T06:59:55.802+0000] {processor.py:186} INFO - Started process (PID=24602) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:59:55.803+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T06:59:55.806+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:59:55.806+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:59:56.541+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T06:59:56.582+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:59:56.581+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T06:59:56.614+0000] {logging_mixin.py:190} INFO - [2024-10-03T06:59:56.613+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T06:59:56.845+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.052 seconds
[2024-10-03T07:00:26.915+0000] {processor.py:186} INFO - Started process (PID=24651) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:00:26.917+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:00:26.920+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:00:26.919+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:00:27.733+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:00:27.786+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:00:27.785+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:00:28.041+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:00:28.041+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:00:28.079+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.171 seconds
[2024-10-03T07:00:58.615+0000] {processor.py:186} INFO - Started process (PID=24819) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:00:58.628+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:00:58.634+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:00:58.633+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:01:00.290+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:01:00.386+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:01:00.385+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:01:00.479+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:01:00.478+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:01:00.549+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.950 seconds
[2024-10-03T07:01:31.102+0000] {processor.py:186} INFO - Started process (PID=25105) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:01:31.104+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:01:31.109+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:01:31.108+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:01:32.000+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:01:32.056+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:01:32.055+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:01:32.092+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:01:32.092+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:01:32.127+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.035 seconds
[2024-10-03T07:02:02.434+0000] {processor.py:186} INFO - Started process (PID=25162) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:02:02.436+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:02:02.440+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:02:02.439+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:02:03.395+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:02:03.452+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:02:03.451+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:02:03.503+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:02:03.503+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:02:03.820+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.394 seconds
[2024-10-03T07:02:34.560+0000] {processor.py:186} INFO - Started process (PID=25211) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:02:34.572+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:02:34.576+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:02:34.576+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:02:35.578+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:02:35.622+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:02:35.621+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:02:35.873+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:02:35.873+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:02:35.897+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.348 seconds
[2024-10-03T07:03:06.789+0000] {processor.py:186} INFO - Started process (PID=25260) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:03:06.790+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:03:06.794+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:03:06.794+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:03:07.475+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:03:07.699+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:03:07.699+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:03:07.726+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:03:07.725+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:03:07.747+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.967 seconds
[2024-10-03T07:03:38.486+0000] {processor.py:186} INFO - Started process (PID=25339) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:03:38.488+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:03:38.492+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:03:38.491+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:03:39.266+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:03:39.633+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:03:39.633+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:03:39.663+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:03:39.662+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:03:39.701+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.224 seconds
[2024-10-03T07:04:09.785+0000] {processor.py:186} INFO - Started process (PID=25467) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:04:09.787+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:04:09.791+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:04:09.790+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:04:10.408+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:04:10.457+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:04:10.456+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:04:10.487+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:04:10.486+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:04:10.686+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.909 seconds
[2024-10-03T07:04:41.062+0000] {processor.py:186} INFO - Started process (PID=25516) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:04:41.074+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:04:41.076+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:04:41.076+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:04:41.762+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:04:41.801+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:04:41.801+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:04:42.027+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:04:42.027+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:04:42.063+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.009 seconds
[2024-10-03T07:05:12.209+0000] {processor.py:186} INFO - Started process (PID=25638) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:05:12.210+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:05:12.213+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:05:12.213+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:05:12.871+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:05:13.098+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:05:13.097+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:05:13.130+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:05:13.130+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:05:13.166+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.967 seconds
[2024-10-03T07:05:43.408+0000] {processor.py:186} INFO - Started process (PID=25687) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:05:43.420+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:05:43.425+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:05:43.424+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:05:44.304+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:05:44.344+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:05:44.344+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:05:44.377+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:05:44.377+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:05:44.415+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.020 seconds
[2024-10-03T07:06:14.943+0000] {processor.py:186} INFO - Started process (PID=25805) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:06:14.945+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:06:14.951+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:06:14.950+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:06:16.462+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:06:16.536+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:06:16.535+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:06:16.618+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:06:16.617+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:06:17.051+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 2.121 seconds
[2024-10-03T07:06:47.432+0000] {processor.py:186} INFO - Started process (PID=25958) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:06:47.434+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:06:47.440+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:06:47.439+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:06:48.689+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:06:48.767+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:06:48.765+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:06:49.172+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:06:49.172+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:06:49.223+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.806 seconds
[2024-10-03T07:07:19.514+0000] {processor.py:186} INFO - Started process (PID=26175) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:07:19.515+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:07:19.518+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:07:19.518+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:07:20.403+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:07:20.652+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:07:20.651+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:07:20.680+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:07:20.680+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:07:20.705+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.199 seconds
[2024-10-03T07:07:50.937+0000] {processor.py:186} INFO - Started process (PID=26224) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:07:50.939+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:07:50.942+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:07:50.941+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:07:51.838+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:07:51.885+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:07:51.884+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:07:51.917+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:07:51.917+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:07:51.948+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.018 seconds
[2024-10-03T07:08:22.468+0000] {processor.py:186} INFO - Started process (PID=26443) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:08:22.480+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:08:22.483+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:08:22.483+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:08:23.121+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:08:23.159+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:08:23.159+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:08:23.419+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:08:23.419+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:08:23.445+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.984 seconds
[2024-10-03T07:08:53.999+0000] {processor.py:186} INFO - Started process (PID=26492) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:08:53.999+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:08:54.002+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:08:54.001+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:08:54.868+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:08:54.925+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:08:54.924+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:08:55.192+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:08:55.191+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:08:55.232+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.241 seconds
[2024-10-03T07:09:25.651+0000] {processor.py:186} INFO - Started process (PID=26710) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:09:25.664+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:09:25.667+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:09:25.667+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:09:26.545+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:09:26.840+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:09:26.839+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:09:26.869+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:09:26.869+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:09:26.900+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.258 seconds
[2024-10-03T07:09:56.971+0000] {processor.py:186} INFO - Started process (PID=26759) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:09:56.983+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:09:56.986+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:09:56.985+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:09:57.785+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:09:57.822+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:09:57.821+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:09:57.850+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:09:57.850+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:09:57.885+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.922 seconds
[2024-10-03T07:10:28.016+0000] {processor.py:186} INFO - Started process (PID=26808) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:10:28.028+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:10:28.030+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:10:28.030+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:10:28.665+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:10:28.706+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:10:28.706+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:10:28.941+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:10:28.940+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:10:28.967+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.959 seconds
[2024-10-03T07:10:59.260+0000] {processor.py:186} INFO - Started process (PID=26919) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:10:59.262+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:10:59.268+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:10:59.267+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:11:00.318+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:11:00.763+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:11:00.763+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:11:00.804+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:11:00.803+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:11:00.838+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.590 seconds
[2024-10-03T07:11:31.332+0000] {processor.py:186} INFO - Started process (PID=27073) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:11:31.334+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:11:31.339+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:11:31.339+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:11:32.466+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:11:32.715+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:11:32.715+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:11:32.745+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:11:32.744+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:11:32.780+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.463 seconds
[2024-10-03T07:12:03.315+0000] {processor.py:186} INFO - Started process (PID=27122) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:12:03.316+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:12:03.319+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:12:03.319+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:12:04.163+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:12:04.198+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:12:04.198+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:12:04.227+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:12:04.227+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:12:04.250+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.943 seconds
[2024-10-03T07:12:34.924+0000] {processor.py:186} INFO - Started process (PID=27176) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:12:34.930+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:12:34.934+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:12:34.934+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:12:35.589+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:12:35.626+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:12:35.626+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:12:35.661+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:12:35.660+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:12:35.865+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.951 seconds
[2024-10-03T07:13:05.956+0000] {processor.py:186} INFO - Started process (PID=27225) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:13:05.967+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:13:05.970+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:13:05.970+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:13:06.691+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:13:06.733+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:13:06.732+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:13:06.973+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:13:06.973+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:13:07.006+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.059 seconds
[2024-10-03T07:13:37.744+0000] {processor.py:186} INFO - Started process (PID=27279) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:13:37.746+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:13:37.749+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:13:37.749+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:13:38.430+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:13:38.709+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:13:38.708+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:13:38.741+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:13:38.741+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:13:38.780+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.045 seconds
[2024-10-03T07:14:09.654+0000] {processor.py:186} INFO - Started process (PID=27498) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:14:09.656+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:14:09.660+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:14:09.660+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:14:10.918+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:14:10.961+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:14:10.961+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:14:10.993+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:14:10.992+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:14:11.018+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.378 seconds
[2024-10-03T07:14:41.902+0000] {processor.py:186} INFO - Started process (PID=27555) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:14:41.903+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:14:41.906+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:14:41.905+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:14:42.671+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:14:42.732+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:14:42.731+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:14:42.774+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:14:42.773+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:14:43.003+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.110 seconds
[2024-10-03T07:15:13.668+0000] {processor.py:186} INFO - Started process (PID=27606) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:15:13.670+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:15:13.672+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:15:13.672+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:15:14.413+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:15:14.456+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:15:14.455+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:15:14.682+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:15:14.681+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:15:14.714+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.055 seconds
[2024-10-03T07:15:44.774+0000] {processor.py:186} INFO - Started process (PID=27655) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:15:44.786+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:15:44.789+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:15:44.788+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:15:45.437+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:15:45.666+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:15:45.666+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:15:45.691+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:15:45.691+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:15:45.723+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.957 seconds
[2024-10-03T07:16:16.381+0000] {processor.py:186} INFO - Started process (PID=27704) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:16:16.382+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:16:16.388+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:16:16.387+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:16:17.925+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:16:17.982+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:16:17.981+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:16:18.023+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:16:18.023+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:16:18.050+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.678 seconds
[2024-10-03T07:16:48.885+0000] {processor.py:186} INFO - Started process (PID=27926) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:16:48.887+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:16:48.890+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:16:48.889+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:16:49.550+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:16:49.593+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:16:49.592+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:16:49.812+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:16:49.812+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:16:49.834+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.956 seconds
[2024-10-03T07:17:20.577+0000] {processor.py:186} INFO - Started process (PID=27975) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:17:20.579+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:17:20.582+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:17:20.581+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:17:21.290+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:17:21.328+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:17:21.328+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:17:21.542+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:17:21.541+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:17:21.581+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.012 seconds
[2024-10-03T07:17:52.100+0000] {processor.py:186} INFO - Started process (PID=28192) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:17:52.107+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:17:52.112+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:17:52.111+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:17:53.129+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:17:53.354+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:17:53.353+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:17:53.383+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:17:53.382+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:17:53.406+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.322 seconds
[2024-10-03T07:18:23.583+0000] {processor.py:186} INFO - Started process (PID=28246) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:18:23.585+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:18:23.588+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:18:23.587+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:18:24.539+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:18:24.579+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:18:24.578+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:18:24.607+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:18:24.607+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:18:24.634+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.059 seconds
[2024-10-03T07:18:54.704+0000] {processor.py:186} INFO - Started process (PID=28424) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:18:54.711+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:18:54.716+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:18:54.716+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:18:56.312+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:18:56.388+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:18:56.387+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:18:56.652+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:18:56.652+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:18:56.679+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.993 seconds
[2024-10-03T07:19:27.170+0000] {processor.py:186} INFO - Started process (PID=28512) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:19:27.173+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:19:27.178+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:19:27.177+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:19:27.953+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:19:28.016+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:19:28.015+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:19:28.287+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:19:28.287+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:19:28.311+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.161 seconds
[2024-10-03T07:19:58.462+0000] {processor.py:186} INFO - Started process (PID=28561) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:19:58.464+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:19:58.467+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:19:58.466+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:19:59.225+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:19:59.453+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:19:59.452+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:19:59.478+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:19:59.478+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:19:59.512+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.058 seconds
[2024-10-03T07:20:29.639+0000] {processor.py:186} INFO - Started process (PID=28610) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:20:29.642+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:20:29.649+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:20:29.648+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:20:31.422+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:20:31.483+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:20:31.482+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:20:31.528+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:20:31.528+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:20:31.586+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.968 seconds
[2024-10-03T07:21:01.780+0000] {processor.py:186} INFO - Started process (PID=28826) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:21:01.782+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:21:01.787+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:21:01.786+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:21:02.633+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:21:02.676+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:21:02.676+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:21:03.172+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:21:03.161+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:21:03.314+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.546 seconds
[2024-10-03T07:21:33.599+0000] {processor.py:186} INFO - Started process (PID=28875) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:21:33.612+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:21:33.614+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:21:33.614+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:21:34.263+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:21:34.301+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:21:34.301+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:21:34.519+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:21:34.519+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:21:34.551+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.962 seconds
[2024-10-03T07:22:04.634+0000] {processor.py:186} INFO - Started process (PID=29052) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:22:04.649+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:22:04.655+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:22:04.654+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:22:06.338+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:22:06.834+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:22:06.833+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:22:06.888+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:22:06.888+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:22:06.930+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 2.315 seconds
[2024-10-03T07:22:36.989+0000] {processor.py:186} INFO - Started process (PID=29143) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:22:36.991+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:22:36.994+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:22:36.993+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:22:38.000+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:22:38.043+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:22:38.042+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:22:38.083+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:22:38.082+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:22:38.108+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.126 seconds
[2024-10-03T07:23:08.261+0000] {processor.py:186} INFO - Started process (PID=29360) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:23:08.262+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:23:08.266+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:23:08.265+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:23:08.940+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:23:08.978+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:23:08.978+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:23:09.182+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:23:09.182+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:23:09.206+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.955 seconds
[2024-10-03T07:23:39.708+0000] {processor.py:186} INFO - Started process (PID=29409) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:23:39.710+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:23:39.713+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:23:39.712+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:23:40.392+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:23:40.437+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:23:40.436+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:23:40.725+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:23:40.725+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:23:40.754+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.054 seconds
[2024-10-03T07:24:11.013+0000] {processor.py:186} INFO - Started process (PID=29625) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:24:11.017+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:24:11.022+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:24:11.021+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:24:11.883+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:24:12.189+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:24:12.189+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:24:12.230+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:24:12.229+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:24:12.260+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.262 seconds
[2024-10-03T07:24:42.609+0000] {processor.py:186} INFO - Started process (PID=29674) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:24:42.621+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:24:42.624+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:24:42.624+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:24:43.699+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:24:43.748+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:24:43.747+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:24:43.781+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:24:43.780+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:24:43.807+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.206 seconds
[2024-10-03T07:25:13.960+0000] {processor.py:186} INFO - Started process (PID=29723) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:25:13.972+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:25:13.975+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:25:13.974+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:25:14.795+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:25:14.847+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:25:14.846+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:25:15.090+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:25:15.090+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:25:15.117+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.167 seconds
[2024-10-03T07:25:45.571+0000] {processor.py:186} INFO - Started process (PID=29776) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:25:45.572+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:25:45.575+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:25:45.574+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:25:46.501+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:25:46.744+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:25:46.743+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:25:46.774+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:25:46.773+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:25:46.806+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.243 seconds
[2024-10-03T07:26:16.935+0000] {processor.py:186} INFO - Started process (PID=29878) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:26:16.942+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:26:16.951+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:26:16.949+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:26:18.902+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:26:18.980+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:26:18.979+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:26:19.037+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:26:19.036+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:26:19.082+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 2.182 seconds
[2024-10-03T07:26:49.617+0000] {processor.py:186} INFO - Started process (PID=30046) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:26:49.620+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:26:49.624+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:26:49.623+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:26:50.700+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:26:50.738+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:26:50.738+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:26:50.772+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:26:50.771+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:26:50.810+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.202 seconds
[2024-10-03T07:27:20.971+0000] {processor.py:186} INFO - Started process (PID=30158) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:27:20.974+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:27:20.986+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:27:20.984+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:27:22.490+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:27:22.561+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:27:22.560+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:27:22.865+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:27:22.864+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:27:22.892+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.944 seconds
[2024-10-03T07:27:53.439+0000] {processor.py:186} INFO - Started process (PID=30323) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:27:53.440+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:27:53.443+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:27:53.443+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:27:54.148+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:27:54.394+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:27:54.394+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:27:54.421+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:27:54.421+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:27:54.446+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.017 seconds
[2024-10-03T07:28:24.720+0000] {processor.py:186} INFO - Started process (PID=30380) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:28:24.721+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:28:24.725+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:28:24.724+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:28:25.575+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:28:25.614+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:28:25.613+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:28:25.641+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:28:25.640+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:28:25.672+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.960 seconds
[2024-10-03T07:28:56.125+0000] {processor.py:186} INFO - Started process (PID=30484) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:28:56.127+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:28:56.132+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:28:56.131+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:28:57.505+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:28:57.576+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:28:57.575+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:28:57.621+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:28:57.621+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:28:57.668+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.557 seconds
[2024-10-03T07:29:27.743+0000] {processor.py:186} INFO - Started process (PID=30652) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:29:27.755+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:29:27.758+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:29:27.758+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:29:28.392+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:29:28.429+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:29:28.429+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:29:28.658+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:29:28.658+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:29:28.681+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.945 seconds
[2024-10-03T07:29:58.851+0000] {processor.py:186} INFO - Started process (PID=30763) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:29:58.853+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:29:58.858+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:29:58.857+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:29:59.886+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:30:00.216+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:30:00.215+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:30:00.256+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:30:00.255+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:30:00.298+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.457 seconds
[2024-10-03T07:30:30.441+0000] {processor.py:186} INFO - Started process (PID=30922) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:30:30.453+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:30:30.456+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:30:30.455+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:30:31.238+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:30:31.273+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:30:31.272+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:30:31.299+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:30:31.299+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:30:31.321+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.887 seconds
[2024-10-03T07:31:01.840+0000] {processor.py:186} INFO - Started process (PID=30971) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:31:01.841+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:31:01.844+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:31:01.844+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:31:02.673+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:31:02.711+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:31:02.711+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:31:02.736+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:31:02.736+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:31:02.761+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.930 seconds
[2024-10-03T07:31:33.213+0000] {processor.py:186} INFO - Started process (PID=31020) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:31:33.215+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:31:33.219+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:31:33.218+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:31:34.227+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:31:34.275+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:31:34.275+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:31:34.513+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:31:34.513+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:31:34.536+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.333 seconds
[2024-10-03T07:32:04.993+0000] {processor.py:186} INFO - Started process (PID=31139) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:32:05.006+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:32:05.009+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:32:05.009+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:32:06.081+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:32:06.492+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:32:06.490+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:32:06.557+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:32:06.556+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:32:06.610+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.631 seconds
[2024-10-03T07:32:36.859+0000] {processor.py:186} INFO - Started process (PID=31293) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:32:36.861+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:32:36.864+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:32:36.863+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:32:37.784+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:32:37.831+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:32:37.831+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:32:37.866+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:32:37.866+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:32:37.893+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.044 seconds
[2024-10-03T07:33:08.072+0000] {processor.py:186} INFO - Started process (PID=31344) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:33:08.074+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:33:08.080+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:33:08.079+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:33:09.225+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:33:09.283+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:33:09.281+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:33:09.322+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:33:09.322+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:33:09.348+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.290 seconds
[2024-10-03T07:33:39.482+0000] {processor.py:186} INFO - Started process (PID=31568) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:33:39.484+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:33:39.487+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:33:39.486+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:33:40.121+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:33:40.158+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:33:40.158+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:33:40.358+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:33:40.358+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:33:40.389+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.913 seconds
[2024-10-03T07:34:10.498+0000] {processor.py:186} INFO - Started process (PID=31617) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:34:10.509+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:34:10.512+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:34:10.512+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:34:11.183+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:34:11.404+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:34:11.404+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:34:11.431+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:34:11.430+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:34:11.467+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.977 seconds
[2024-10-03T07:34:41.880+0000] {processor.py:186} INFO - Started process (PID=31833) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:34:41.892+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:34:41.895+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:34:41.895+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:34:42.794+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:34:42.828+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:34:42.827+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:34:42.854+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:34:42.854+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:34:42.886+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.016 seconds
[2024-10-03T07:35:12.959+0000] {processor.py:186} INFO - Started process (PID=31882) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:35:12.971+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:35:12.974+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:35:12.973+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:35:13.879+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:35:13.924+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:35:13.923+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:35:13.956+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:35:13.956+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:35:13.983+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.033 seconds
[2024-10-03T07:35:44.495+0000] {processor.py:186} INFO - Started process (PID=32099) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:35:44.496+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:35:44.499+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:35:44.499+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:35:45.444+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:35:45.499+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:35:45.498+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:35:45.850+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:35:45.850+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:35:45.885+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.398 seconds
[2024-10-03T07:36:16.042+0000] {processor.py:186} INFO - Started process (PID=32148) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:36:16.055+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:36:16.058+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:36:16.058+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:36:16.802+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:36:17.049+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:36:17.048+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:36:17.088+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:36:17.087+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:36:17.126+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.092 seconds
[2024-10-03T07:36:47.224+0000] {processor.py:186} INFO - Started process (PID=32197) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:36:47.236+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:36:47.240+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:36:47.239+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:36:48.316+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:36:48.353+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:36:48.352+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:36:48.381+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:36:48.380+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:36:48.413+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.200 seconds
[2024-10-03T07:37:19.205+0000] {processor.py:186} INFO - Started process (PID=32246) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:37:19.217+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:37:19.221+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:37:19.220+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:37:20.035+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:37:20.069+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:37:20.069+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:37:20.095+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:37:20.095+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:37:20.119+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.922 seconds
[2024-10-03T07:37:50.204+0000] {processor.py:186} INFO - Started process (PID=32295) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:37:50.216+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:37:50.220+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:37:50.219+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:37:50.882+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:37:50.934+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:37:50.933+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:37:51.225+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:37:51.224+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:37:51.258+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.062 seconds
[2024-10-03T07:38:21.622+0000] {processor.py:186} INFO - Started process (PID=32344) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:38:21.623+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:38:21.626+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:38:21.626+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:38:22.321+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:38:22.539+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:38:22.539+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:38:22.565+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:38:22.565+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:38:22.597+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.982 seconds
[2024-10-03T07:38:53.166+0000] {processor.py:186} INFO - Started process (PID=32393) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:38:53.180+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:38:53.185+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:38:53.185+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:38:54.253+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:38:54.298+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:38:54.298+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:38:54.337+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:38:54.336+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:38:54.373+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.215 seconds
[2024-10-03T07:39:25.036+0000] {processor.py:186} INFO - Started process (PID=32442) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:39:25.048+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:39:25.052+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:39:25.051+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:39:25.856+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:39:25.895+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:39:25.895+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:39:25.922+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:39:25.922+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:39:25.948+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.918 seconds
[2024-10-03T07:39:56.359+0000] {processor.py:186} INFO - Started process (PID=32491) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:39:56.361+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:39:56.364+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:39:56.363+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:39:56.979+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:39:57.015+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:39:57.014+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:39:57.221+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:39:57.221+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:39:57.243+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.892 seconds
[2024-10-03T07:40:27.470+0000] {processor.py:186} INFO - Started process (PID=32540) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:40:27.472+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:40:27.476+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:40:27.475+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:40:28.569+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:40:28.903+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:40:28.902+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:40:28.947+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:40:28.946+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:40:28.990+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.530 seconds
[2024-10-03T07:40:59.220+0000] {processor.py:186} INFO - Started process (PID=32589) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:40:59.232+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:40:59.235+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:40:59.235+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:41:00.069+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:41:00.117+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:41:00.116+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:41:00.150+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:41:00.149+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:41:00.174+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.961 seconds
[2024-10-03T07:41:30.300+0000] {processor.py:186} INFO - Started process (PID=32648) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:41:30.303+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:41:30.309+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:41:30.308+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:41:31.343+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:41:31.335+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 31, in warehouse
    step_1()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 30, in step_1
    extract_transform()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 17, in extract_transform
    SparkSubmitOperator(
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 124, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: categories). Invalid arguments were:
**kwargs: {'on_exit_code': {99: 'skip'}}
[2024-10-03T07:41:31.344+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:41:31.359+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.069 seconds
[2024-10-03T07:41:37.158+0000] {processor.py:186} INFO - Started process (PID=32666) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:41:37.159+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:41:37.164+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:41:37.163+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:41:38.445+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:41:38.427+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 31, in warehouse
    step_1()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 30, in step_1
    extract_transform()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 17, in extract_transform
    SparkSubmitOperator(
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 124, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: categories). Invalid arguments were:
**kwargs: {'on_exit_code': {99: 'skip'}}
[2024-10-03T07:41:38.457+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:41:38.554+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:41:38.554+0000] {taskinstance.py:3312} ERROR - Executor LocalExecutor(parallelism=32) reported that the task instance <TaskInstance: etl_pipeline.warehouse.step_1.extract_transform.categories scheduled__2024-10-02T00:00:00+00:00 [queued]> finished with state failed, but the task instance's state attribute is queued. Learn more: https://airflow.apache.org/docs/apache-airflow/stable/troubleshooting.html#task-state-changed-externally
[2024-10-03T07:41:38.621+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:41:38.620+0000] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=etl_pipeline, task_id=warehouse.step_1.extract_transform.categories, run_id=scheduled__2024-10-02T00:00:00+00:00, execution_date=20241002T000000, start_date=20241003T073518, end_date=20241003T074138
[2024-10-03T07:41:38.621+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:41:38.621+0000] {taskinstance.py:1563} INFO - Executing callback at index 0: str
[2024-10-03T07:41:38.622+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:41:38.622+0000] {taskinstance.py:1567} ERROR - Error in callback at index 0: str
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 1565, in _run_finished_callback
    callback(context)
TypeError: 'str' object is not callable
[2024-10-03T07:41:38.639+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:41:38.639+0000] {processor.py:876} INFO - Executed callback for <TaskInstance: etl_pipeline.warehouse.step_1.extract_transform.categories scheduled__2024-10-02T00:00:00+00:00 [failed]> in state failed
[2024-10-03T07:41:38.640+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.495 seconds
[2024-10-03T07:42:09.082+0000] {processor.py:186} INFO - Started process (PID=32715) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:42:09.094+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:42:09.097+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:42:09.096+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:42:09.923+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:42:09.919+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 31, in warehouse
    step_1()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 30, in step_1
    extract_transform()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 17, in extract_transform
    SparkSubmitOperator(
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 124, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: categories). Invalid arguments were:
**kwargs: {'on_exit_code': {99: 'skip'}}
[2024-10-03T07:42:09.924+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:42:09.936+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.861 seconds
[2024-10-03T07:42:40.252+0000] {processor.py:186} INFO - Started process (PID=32764) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:42:40.253+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:42:40.254+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:42:40.254+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:42:41.095+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:42:41.090+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 31, in warehouse
    step_1()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 30, in step_1
    extract_transform()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 17, in extract_transform
    SparkSubmitOperator(
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 124, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: categories). Invalid arguments were:
**kwargs: {'on_exit_code': {99: 'skip'}}
[2024-10-03T07:42:41.096+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:42:41.117+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.873 seconds
[2024-10-03T07:43:12.027+0000] {processor.py:186} INFO - Started process (PID=32813) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:43:12.029+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:43:12.030+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:43:12.030+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:43:12.898+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:43:12.894+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 31, in warehouse
    step_1()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 30, in step_1
    extract_transform()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 17, in extract_transform
    SparkSubmitOperator(
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 124, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: categories). Invalid arguments were:
**kwargs: {'on_exit_code': {99: 'skip'}}
[2024-10-03T07:43:12.899+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:43:12.910+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.891 seconds
[2024-10-03T07:43:43.487+0000] {processor.py:186} INFO - Started process (PID=32867) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:43:43.489+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:43:43.491+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:43:43.490+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:43:44.555+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:43:44.739+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:43:44.738+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:43:44.767+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:43:44.767+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:43:44.797+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.319 seconds
[2024-10-03T07:44:15.159+0000] {processor.py:186} INFO - Started process (PID=32916) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:44:15.171+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:44:15.172+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:44:15.172+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:44:16.121+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:44:16.158+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:44:16.158+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:44:16.189+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:44:16.189+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:44:16.225+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.075 seconds
[2024-10-03T07:44:46.665+0000] {processor.py:186} INFO - Started process (PID=32965) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:44:46.677+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:44:46.678+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:44:46.678+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:44:47.532+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:44:47.571+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:44:47.570+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:44:47.599+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:44:47.598+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:44:47.623+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.966 seconds
[2024-10-03T07:45:18.346+0000] {processor.py:186} INFO - Started process (PID=33014) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:45:18.348+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:45:18.350+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:45:18.349+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:45:19.330+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:45:19.381+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:45:19.380+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:45:19.421+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:45:19.421+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:45:19.446+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.109 seconds
[2024-10-03T07:45:49.831+0000] {processor.py:186} INFO - Started process (PID=33063) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:45:49.834+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:45:49.838+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:45:49.837+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:45:51.249+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:45:51.288+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:45:51.288+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:45:51.323+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:45:51.322+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:45:51.362+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.547 seconds
[2024-10-03T07:46:21.717+0000] {processor.py:186} INFO - Started process (PID=33279) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:46:21.718+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:46:21.720+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:46:21.719+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:46:22.572+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:46:22.612+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:46:22.611+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:46:22.643+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:46:22.643+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:46:22.676+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.966 seconds
[2024-10-03T07:46:53.362+0000] {processor.py:186} INFO - Started process (PID=33328) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:46:53.368+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:46:53.370+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:46:53.370+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:46:54.543+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:46:54.607+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:46:54.605+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:46:54.655+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:46:54.655+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:46:54.689+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.353 seconds
[2024-10-03T07:47:25.526+0000] {processor.py:186} INFO - Started process (PID=33382) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:47:25.536+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:47:25.538+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:47:25.537+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:47:26.533+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:47:26.568+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:47:26.567+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:47:26.594+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:47:26.594+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:47:26.627+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.110 seconds
[2024-10-03T07:47:57.435+0000] {processor.py:186} INFO - Started process (PID=33451) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:47:57.436+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:47:57.439+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:47:57.438+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:47:58.470+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:47:58.478+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:47:58.477+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:47:58.521+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:47:58.521+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:47:58.553+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.133 seconds
[2024-10-03T07:48:28.800+0000] {processor.py:186} INFO - Started process (PID=33667) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:48:28.802+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:48:28.805+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:48:28.804+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:48:29.864+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:48:30.008+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:48:30.007+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:48:30.042+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:48:30.041+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:48:30.072+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.280 seconds
[2024-10-03T07:49:00.521+0000] {processor.py:186} INFO - Started process (PID=33726) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:49:00.532+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:49:00.534+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:49:00.534+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:49:01.692+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:49:01.999+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:49:01.998+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:49:02.041+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:49:02.040+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:49:02.107+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.597 seconds
[2024-10-03T07:49:32.721+0000] {processor.py:186} INFO - Started process (PID=33878) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:49:32.725+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:49:32.730+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:49:32.729+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:49:34.694+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:49:34.763+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:49:34.762+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:49:34.815+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:49:34.814+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:49:34.853+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 2.157 seconds
[2024-10-03T07:50:05.023+0000] {processor.py:186} INFO - Started process (PID=34073) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:50:05.035+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:50:05.036+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:50:05.036+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:50:06.274+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:50:06.328+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:50:06.327+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:50:06.381+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:50:06.380+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:50:06.424+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.410 seconds
[2024-10-03T07:50:36.739+0000] {processor.py:186} INFO - Started process (PID=34122) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:50:36.741+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:50:36.743+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:50:36.743+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:50:38.065+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:50:38.161+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:50:38.160+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:50:38.245+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:50:38.244+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:50:38.311+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.585 seconds
[2024-10-03T07:51:09.040+0000] {processor.py:186} INFO - Started process (PID=34171) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:51:09.050+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:51:09.052+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:51:09.052+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:51:10.017+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:51:10.061+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:51:10.060+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:51:10.096+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:51:10.096+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:51:10.122+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.090 seconds
[2024-10-03T07:51:40.176+0000] {processor.py:186} INFO - Started process (PID=34303) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:51:40.177+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:51:40.179+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:51:40.179+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:51:41.259+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:51:41.557+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:51:41.557+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:51:41.590+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:51:41.590+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:51:41.627+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.461 seconds
[2024-10-03T07:52:12.171+0000] {processor.py:186} INFO - Started process (PID=34352) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:52:12.173+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:52:12.174+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:52:12.174+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:52:12.949+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:52:12.982+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:52:12.981+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:52:13.009+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:52:13.009+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:52:13.040+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.876 seconds
[2024-10-03T07:52:43.652+0000] {processor.py:186} INFO - Started process (PID=34401) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:52:43.654+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:52:43.656+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:52:43.656+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:52:44.624+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:52:44.660+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:52:44.660+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:52:44.695+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:52:44.695+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:52:44.719+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.088 seconds
[2024-10-03T07:53:14.802+0000] {processor.py:186} INFO - Started process (PID=34490) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:53:14.814+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:53:14.816+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:53:14.816+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:53:16.007+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:53:16.287+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:53:16.286+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:53:16.333+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:53:16.332+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:53:16.371+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.578 seconds
[2024-10-03T07:53:46.998+0000] {processor.py:186} INFO - Started process (PID=34539) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:53:47.000+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:53:47.001+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:53:47.001+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:53:47.887+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:53:47.933+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:53:47.932+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:53:47.967+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:53:47.967+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:53:48.007+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.017 seconds
[2024-10-03T07:54:18.100+0000] {processor.py:186} INFO - Started process (PID=34588) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:54:18.114+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:54:18.116+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:54:18.116+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:54:19.023+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:54:19.057+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:54:19.056+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:54:19.085+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:54:19.085+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:54:19.117+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.043 seconds
[2024-10-03T07:54:49.641+0000] {processor.py:186} INFO - Started process (PID=34640) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:54:49.642+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:54:49.644+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:54:49.643+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:54:50.772+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:54:50.865+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:54:50.864+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:54:50.903+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:54:50.902+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:54:50.933+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.299 seconds
[2024-10-03T07:55:21.714+0000] {processor.py:186} INFO - Started process (PID=34696) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:55:21.716+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:55:21.720+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:55:21.719+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:55:22.657+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:55:22.708+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:55:22.707+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:55:22.743+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:55:22.743+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:55:22.768+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.064 seconds
[2024-10-03T07:55:53.558+0000] {processor.py:186} INFO - Started process (PID=34893) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:55:53.570+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:55:53.573+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:55:53.572+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:55:54.384+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:55:54.424+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:55:54.423+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:55:54.450+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:55:54.450+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:55:54.490+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.940 seconds
[2024-10-03T07:56:24.891+0000] {processor.py:186} INFO - Started process (PID=34955) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:56:24.892+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:56:24.895+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:56:24.894+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:56:26.038+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:56:26.099+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:56:26.098+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:56:26.135+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:56:26.134+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:56:26.165+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.283 seconds
[2024-10-03T07:56:56.666+0000] {processor.py:186} INFO - Started process (PID=35082) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:56:56.669+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:56:56.672+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:56:56.671+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:56:57.640+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:56:57.679+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:56:57.678+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:56:57.711+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:56:57.710+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:56:57.739+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.085 seconds
[2024-10-03T07:57:27.926+0000] {processor.py:186} INFO - Started process (PID=35304) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:57:27.929+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:57:27.932+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:57:27.931+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:57:29.311+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:57:29.365+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:57:29.365+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:57:29.396+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:57:29.396+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:57:29.434+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.521 seconds
[2024-10-03T07:58:00.084+0000] {processor.py:186} INFO - Started process (PID=35354) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:58:00.109+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:58:00.111+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:58:00.110+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:58:01.841+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:58:02.035+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:58:02.035+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:58:02.076+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:58:02.075+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:58:02.174+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 2.103 seconds
[2024-10-03T07:58:32.676+0000] {processor.py:186} INFO - Started process (PID=35546) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:58:32.679+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:58:32.686+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:58:32.685+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:58:34.926+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:58:35.002+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:58:35.001+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:58:35.059+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:58:35.059+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:58:35.088+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 2.439 seconds
[2024-10-03T07:59:05.853+0000] {processor.py:186} INFO - Started process (PID=35659) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:59:05.866+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:59:05.867+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:59:05.867+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:59:06.961+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:59:07.017+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:59:07.017+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:59:07.049+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:59:07.048+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:59:07.078+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.234 seconds
[2024-10-03T07:59:37.702+0000] {processor.py:186} INFO - Started process (PID=35708) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:59:37.704+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T07:59:37.705+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:59:37.705+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:59:38.726+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T07:59:38.782+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:59:38.781+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T07:59:38.821+0000] {logging_mixin.py:190} INFO - [2024-10-03T07:59:38.821+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T07:59:38.850+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.156 seconds
[2024-10-03T08:00:09.161+0000] {processor.py:186} INFO - Started process (PID=35916) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:00:09.164+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:00:09.169+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:00:09.167+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:00:10.981+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:00:11.062+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:00:11.060+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:00:11.118+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:00:11.118+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:00:11.170+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 2.027 seconds
[2024-10-03T08:00:41.836+0000] {processor.py:186} INFO - Started process (PID=36015) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:00:41.838+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:00:41.843+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:00:41.842+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:00:42.932+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:00:42.977+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:00:42.977+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:00:43.011+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:00:43.011+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:00:43.037+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.213 seconds
[2024-10-03T08:01:13.159+0000] {processor.py:186} INFO - Started process (PID=36067) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:01:13.161+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:01:13.162+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:01:13.162+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:01:14.262+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:01:14.303+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:01:14.303+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:01:14.331+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:01:14.331+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:01:14.354+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.208 seconds
[2024-10-03T08:01:45.155+0000] {processor.py:186} INFO - Started process (PID=36116) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:01:45.173+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:01:45.197+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:01:45.190+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:01:46.428+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:01:46.468+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:01:46.467+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:01:46.498+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:01:46.497+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:01:46.519+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.479 seconds
[2024-10-03T08:02:16.812+0000] {processor.py:186} INFO - Started process (PID=36162) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:02:16.824+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:02:16.826+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:02:16.826+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:02:17.785+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:02:17.824+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:02:17.823+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:02:17.856+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:02:17.856+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:02:17.882+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.083 seconds
[2024-10-03T08:02:48.221+0000] {processor.py:186} INFO - Started process (PID=36211) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:02:48.222+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:02:48.223+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:02:48.223+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:02:49.170+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:02:49.217+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:02:49.216+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:02:49.251+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:02:49.251+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:02:49.278+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.069 seconds
[2024-10-03T08:03:19.654+0000] {processor.py:186} INFO - Started process (PID=36260) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:03:19.666+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:03:19.668+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:03:19.668+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:03:20.666+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:03:20.709+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:03:20.708+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:03:20.736+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:03:20.736+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:03:20.758+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.113 seconds
[2024-10-03T08:03:51.033+0000] {processor.py:186} INFO - Started process (PID=36309) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:03:51.034+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:03:51.037+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:03:51.037+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:03:52.191+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:03:52.234+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:03:52.233+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:03:52.265+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:03:52.264+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:03:52.290+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.272 seconds
[2024-10-03T08:04:22.664+0000] {processor.py:186} INFO - Started process (PID=36358) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:04:22.666+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:04:22.667+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:04:22.667+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:04:23.645+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:04:23.685+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:04:23.684+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:04:23.717+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:04:23.717+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:04:23.748+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.096 seconds
[2024-10-03T08:04:53.826+0000] {processor.py:186} INFO - Started process (PID=36412) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:04:53.827+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:04:53.829+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:04:53.828+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:04:55.111+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:04:55.165+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:04:55.164+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:04:55.208+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:04:55.207+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:04:55.239+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.425 seconds
[2024-10-03T08:05:26.051+0000] {processor.py:186} INFO - Started process (PID=36461) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:05:26.063+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:05:26.065+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:05:26.065+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:05:27.272+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:05:27.321+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:05:27.320+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:05:27.363+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:05:27.363+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:05:27.386+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.345 seconds
[2024-10-03T08:05:58.159+0000] {processor.py:186} INFO - Started process (PID=36510) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:05:58.161+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:05:58.164+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:05:58.163+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:05:59.429+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:05:59.473+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:05:59.472+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:05:59.503+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:05:59.503+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:05:59.534+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.385 seconds
[2024-10-03T08:06:30.399+0000] {processor.py:186} INFO - Started process (PID=36563) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:06:30.401+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:06:30.404+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:06:30.403+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:06:31.403+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:06:31.447+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:06:31.446+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:06:31.475+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:06:31.474+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:06:31.513+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.127 seconds
[2024-10-03T08:07:02.004+0000] {processor.py:186} INFO - Started process (PID=36619) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:07:02.006+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:07:02.008+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:07:02.007+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:07:03.292+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:07:03.332+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:07:03.332+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:07:03.360+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:07:03.359+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:07:03.386+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.394 seconds
[2024-10-03T08:07:34.191+0000] {processor.py:186} INFO - Started process (PID=36668) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:07:34.193+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:07:34.195+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:07:34.195+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:07:35.073+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:07:35.119+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:07:35.118+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:07:35.167+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:07:35.167+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:07:35.200+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.018 seconds
[2024-10-03T08:08:05.707+0000] {processor.py:186} INFO - Started process (PID=36717) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:08:05.716+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:08:05.718+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:08:05.717+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:08:06.988+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:08:07.088+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:08:07.086+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:08:07.166+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:08:07.165+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:08:07.211+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.516 seconds
[2024-10-03T08:08:38.050+0000] {processor.py:186} INFO - Started process (PID=36774) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:08:38.053+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:08:38.055+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:08:38.054+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:08:39.203+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:08:39.242+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:08:39.241+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:08:39.278+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:08:39.278+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:08:39.312+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.274 seconds
[2024-10-03T08:09:09.460+0000] {processor.py:186} INFO - Started process (PID=36825) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:09:09.473+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:09:09.477+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:09:09.475+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:09:10.756+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:09:10.835+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:09:10.834+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:09:10.895+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:09:10.895+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:09:10.933+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.483 seconds
[2024-10-03T08:09:41.230+0000] {processor.py:186} INFO - Started process (PID=36880) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:09:41.235+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:09:41.239+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:09:41.237+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:09:42.635+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:09:42.690+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:09:42.690+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:09:42.719+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:09:42.718+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:09:42.751+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.535 seconds
[2024-10-03T08:10:12.909+0000] {processor.py:186} INFO - Started process (PID=36929) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:10:12.910+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:10:12.912+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:10:12.912+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:10:13.979+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:10:14.033+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:10:14.032+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:10:14.075+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:10:14.074+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:10:14.108+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.208 seconds
[2024-10-03T08:10:44.971+0000] {processor.py:186} INFO - Started process (PID=36978) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:10:44.984+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:10:44.987+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:10:44.986+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:10:46.282+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:10:46.322+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:10:46.321+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:10:46.348+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:10:46.348+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:10:46.382+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.428 seconds
[2024-10-03T08:11:16.783+0000] {processor.py:186} INFO - Started process (PID=37027) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:11:16.798+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:11:16.803+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:11:16.801+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:11:18.012+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:11:18.096+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:11:18.095+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:11:18.139+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:11:18.139+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:11:18.169+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.395 seconds
[2024-10-03T08:11:48.753+0000] {processor.py:186} INFO - Started process (PID=37076) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:11:48.766+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:11:48.768+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:11:48.768+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:11:49.755+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:11:49.826+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:11:49.825+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:11:49.877+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:11:49.876+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:11:49.915+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.172 seconds
[2024-10-03T08:12:20.562+0000] {processor.py:186} INFO - Started process (PID=37125) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:12:20.575+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:12:20.578+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:12:20.577+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:12:22.000+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:12:22.064+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:12:22.063+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:12:22.113+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:12:22.113+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:12:22.147+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.601 seconds
[2024-10-03T08:12:52.632+0000] {processor.py:186} INFO - Started process (PID=37174) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:12:52.635+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:12:52.637+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:12:52.636+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:12:53.586+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:12:53.628+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:12:53.627+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:12:53.662+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:12:53.662+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:12:53.690+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.068 seconds
[2024-10-03T08:13:23.899+0000] {processor.py:186} INFO - Started process (PID=37228) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:13:23.901+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:13:23.903+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:13:23.903+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:13:24.781+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:13:24.823+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:13:24.822+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:13:24.863+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:13:24.863+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:13:24.887+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.998 seconds
[2024-10-03T08:13:55.373+0000] {processor.py:186} INFO - Started process (PID=37277) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:13:55.385+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:13:55.387+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:13:55.387+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:13:56.226+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:13:56.265+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:13:56.264+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:13:56.290+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:13:56.290+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:13:56.322+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.958 seconds
[2024-10-03T08:14:26.686+0000] {processor.py:186} INFO - Started process (PID=37326) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:14:26.699+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:14:26.700+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:14:26.700+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:14:27.602+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:14:27.647+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:14:27.647+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:14:27.693+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:14:27.693+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:14:27.734+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.056 seconds
[2024-10-03T08:14:58.157+0000] {processor.py:186} INFO - Started process (PID=37375) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:14:58.169+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:14:58.171+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:14:58.171+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:14:59.252+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:14:59.307+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:14:59.306+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:14:59.343+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:14:59.342+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:14:59.373+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.224 seconds
[2024-10-03T08:15:29.774+0000] {processor.py:186} INFO - Started process (PID=37424) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:15:29.775+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:15:29.777+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:15:29.777+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:15:30.701+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:15:30.740+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:15:30.739+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:15:30.794+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:15:30.790+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:15:30.840+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.077 seconds
[2024-10-03T08:16:01.329+0000] {processor.py:186} INFO - Started process (PID=37618) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:16:01.343+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:16:01.348+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:16:01.346+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:16:03.229+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:16:03.327+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:16:03.326+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:16:03.428+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:16:03.427+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:16:03.485+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 2.173 seconds
[2024-10-03T08:16:34.261+0000] {processor.py:186} INFO - Started process (PID=37751) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:16:34.263+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:16:34.266+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:16:34.265+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:16:35.261+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:16:35.305+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:16:35.305+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:16:35.332+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:16:35.332+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:16:35.366+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.114 seconds
[2024-10-03T08:17:05.452+0000] {processor.py:186} INFO - Started process (PID=37800) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:17:05.464+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:17:05.466+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:17:05.466+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:17:06.467+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:17:06.517+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:17:06.517+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:17:06.544+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:17:06.544+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:17:06.567+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.125 seconds
[2024-10-03T08:17:36.854+0000] {processor.py:186} INFO - Started process (PID=37858) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:17:36.856+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:17:36.859+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:17:36.858+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:17:37.848+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:17:37.893+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:17:37.892+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:17:37.920+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:17:37.920+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:17:37.953+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.108 seconds
[2024-10-03T08:18:08.015+0000] {processor.py:186} INFO - Started process (PID=37909) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:18:08.017+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:18:08.019+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:18:08.018+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:18:08.931+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:18:08.972+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:18:08.972+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:18:09.003+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:18:09.003+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:18:09.032+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.027 seconds
[2024-10-03T08:18:39.226+0000] {processor.py:186} INFO - Started process (PID=37961) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:18:39.239+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:18:39.241+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:18:39.241+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:18:40.915+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:18:41.001+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:18:41.000+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:18:41.054+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:18:41.053+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:18:41.098+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.885 seconds
[2024-10-03T08:19:11.268+0000] {processor.py:186} INFO - Started process (PID=38007) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:19:11.269+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:19:11.273+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:19:11.272+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:19:12.400+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:19:12.455+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:19:12.454+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:19:12.490+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:19:12.490+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:19:12.517+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.258 seconds
[2024-10-03T08:19:42.663+0000] {processor.py:186} INFO - Started process (PID=38056) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:19:42.676+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:19:42.678+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:19:42.678+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:19:43.847+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:19:43.900+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:19:43.899+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:19:43.944+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:19:43.944+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:19:43.979+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.330 seconds
[2024-10-03T08:20:14.088+0000] {processor.py:186} INFO - Started process (PID=38105) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:20:14.090+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:20:14.092+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:20:14.091+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:20:15.154+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:20:15.197+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:20:15.197+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:20:15.225+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:20:15.225+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:20:15.249+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.171 seconds
[2024-10-03T08:20:45.396+0000] {processor.py:186} INFO - Started process (PID=38163) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:20:45.398+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:20:45.401+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:20:45.400+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:20:46.590+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:20:46.634+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:20:46.633+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:20:46.670+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:20:46.669+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:20:46.706+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.325 seconds
[2024-10-03T08:21:17.708+0000] {processor.py:186} INFO - Started process (PID=38393) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:21:17.710+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:21:17.714+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:21:17.713+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:21:18.636+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:21:18.675+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:21:18.674+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:21:18.706+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:21:18.705+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:21:18.748+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.051 seconds
[2024-10-03T08:21:49.179+0000] {processor.py:186} INFO - Started process (PID=38444) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:21:49.183+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:21:49.185+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:21:49.185+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:21:50.136+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:21:50.183+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:21:50.182+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:21:50.220+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:21:50.219+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:21:50.249+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.079 seconds
[2024-10-03T08:22:20.631+0000] {processor.py:186} INFO - Started process (PID=38493) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:22:20.644+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:22:20.647+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:22:20.646+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:22:21.604+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:22:21.643+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:22:21.642+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:22:21.672+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:22:21.671+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:22:21.710+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.088 seconds
[2024-10-03T08:22:52.195+0000] {processor.py:186} INFO - Started process (PID=38609) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:22:52.196+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:22:52.198+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:22:52.198+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:22:53.686+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:22:53.751+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:22:53.750+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:22:53.796+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:22:53.795+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:22:53.837+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.654 seconds
[2024-10-03T08:23:24.564+0000] {processor.py:186} INFO - Started process (PID=38805) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:23:24.577+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:23:24.579+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:23:24.578+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:23:25.396+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:23:25.430+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:23:25.429+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:23:25.459+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:23:25.459+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:23:25.492+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.938 seconds
[2024-10-03T08:23:56.014+0000] {processor.py:186} INFO - Started process (PID=38854) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:23:56.027+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:23:56.029+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:23:56.028+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:23:57.093+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:23:57.143+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:23:57.143+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:23:57.185+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:23:57.185+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:23:57.211+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.207 seconds
[2024-10-03T08:24:28.003+0000] {processor.py:186} INFO - Started process (PID=39024) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:24:28.006+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:24:28.010+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:24:28.009+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:24:29.679+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:24:29.766+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:24:29.765+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:24:29.832+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:24:29.832+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:24:29.881+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.895 seconds
[2024-10-03T08:25:00.452+0000] {processor.py:186} INFO - Started process (PID=39149) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:25:00.453+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:25:00.455+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:25:00.455+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:25:01.291+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:25:01.339+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:25:01.338+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:25:01.365+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:25:01.365+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:25:01.388+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.945 seconds
[2024-10-03T08:25:31.882+0000] {processor.py:186} INFO - Started process (PID=39199) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:25:31.884+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:25:31.886+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:25:31.886+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:25:32.765+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:25:32.799+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:25:32.798+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:25:32.828+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:25:32.828+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:25:32.859+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.984 seconds
[2024-10-03T08:26:03.409+0000] {processor.py:186} INFO - Started process (PID=39260) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:26:03.410+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:26:03.412+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:26:03.411+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:26:04.227+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:26:04.261+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:26:04.261+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:26:04.290+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:26:04.290+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:26:04.322+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.921 seconds
[2024-10-03T08:26:34.398+0000] {processor.py:186} INFO - Started process (PID=39309) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:26:34.400+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:26:34.402+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:26:34.402+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:26:35.261+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:26:35.303+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:26:35.302+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:26:35.332+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:26:35.332+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:26:35.370+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.983 seconds
[2024-10-03T08:27:05.677+0000] {processor.py:186} INFO - Started process (PID=39519) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:27:05.681+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:27:05.685+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:27:05.684+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:27:07.394+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:27:07.438+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:27:07.437+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:27:07.470+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:27:07.470+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:27:07.510+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.849 seconds
[2024-10-03T08:27:38.042+0000] {processor.py:186} INFO - Started process (PID=39611) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:27:38.045+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:27:38.048+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:27:38.047+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:27:39.418+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:27:39.455+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:27:39.455+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:27:39.482+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:27:39.482+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:27:39.516+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.493 seconds
[2024-10-03T08:28:09.718+0000] {processor.py:186} INFO - Started process (PID=39660) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:28:09.720+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:28:09.722+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:28:09.722+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:28:11.114+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:28:11.169+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:28:11.169+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:28:11.210+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:28:11.210+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:28:11.243+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.537 seconds
[2024-10-03T08:28:42.248+0000] {processor.py:186} INFO - Started process (PID=39714) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:28:42.251+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:28:42.254+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:28:42.253+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:28:43.528+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:28:43.610+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:28:43.609+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:28:43.651+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:28:43.651+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:28:43.675+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.442 seconds
[2024-10-03T08:29:14.384+0000] {processor.py:186} INFO - Started process (PID=39763) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:29:14.398+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:29:14.401+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:29:14.400+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:29:15.291+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:29:15.333+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:29:15.332+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:29:15.366+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:29:15.365+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:29:15.412+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.038 seconds
[2024-10-03T08:29:46.045+0000] {processor.py:186} INFO - Started process (PID=39812) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:29:46.058+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:29:46.061+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:29:46.060+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:29:46.942+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:29:46.997+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:29:46.997+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:29:47.036+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:29:47.035+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:29:47.072+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.039 seconds
[2024-10-03T08:30:17.780+0000] {processor.py:186} INFO - Started process (PID=39861) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:30:17.782+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:30:17.785+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:30:17.784+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:30:18.889+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:30:18.924+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:30:18.924+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:30:18.957+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:30:18.956+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:30:18.987+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.219 seconds
[2024-10-03T08:30:49.052+0000] {processor.py:186} INFO - Started process (PID=39910) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:30:49.065+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:30:49.066+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:30:49.066+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:30:49.901+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:30:49.947+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:30:49.946+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:30:49.983+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:30:49.983+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:30:50.014+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.970 seconds
[2024-10-03T08:31:20.121+0000] {processor.py:186} INFO - Started process (PID=40035) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:31:20.122+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:31:20.128+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:31:20.126+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:31:21.837+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:31:21.930+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:31:21.929+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:31:22.027+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:31:22.026+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:31:22.093+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.988 seconds
[2024-10-03T08:31:52.196+0000] {processor.py:186} INFO - Started process (PID=40207) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:31:52.208+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:31:52.210+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:31:52.209+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:31:53.106+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:31:53.141+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:31:53.140+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:31:53.169+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:31:53.168+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:31:53.204+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.017 seconds
[2024-10-03T08:32:23.874+0000] {processor.py:186} INFO - Started process (PID=40256) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:32:23.887+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:32:23.889+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:32:23.888+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:32:24.741+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:32:24.775+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:32:24.774+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:32:24.802+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:32:24.801+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:32:24.835+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.972 seconds
[2024-10-03T08:32:55.481+0000] {processor.py:186} INFO - Started process (PID=40305) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:32:55.494+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:32:55.495+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:32:55.495+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:32:56.408+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:32:56.457+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:32:56.456+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:32:56.486+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:32:56.485+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:32:56.521+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.050 seconds
[2024-10-03T08:33:26.753+0000] {processor.py:186} INFO - Started process (PID=40362) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:33:26.758+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:33:26.760+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:33:26.759+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:33:28.047+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:33:28.096+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:33:28.095+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:33:28.127+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:33:28.127+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:33:28.163+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.419 seconds
[2024-10-03T08:33:58.963+0000] {processor.py:186} INFO - Started process (PID=40612) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:33:58.966+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:33:58.970+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:33:58.969+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:34:00.542+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:34:00.600+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:34:00.599+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:34:00.649+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:34:00.649+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:34:00.699+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.750 seconds
[2024-10-03T08:34:30.784+0000] {processor.py:186} INFO - Started process (PID=40661) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:34:30.786+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:34:30.789+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:34:30.788+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:34:31.638+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:34:31.693+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:34:31.693+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:34:31.719+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:34:31.719+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:34:31.745+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.970 seconds
[2024-10-03T08:35:02.277+0000] {processor.py:186} INFO - Started process (PID=40710) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:35:02.278+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:35:02.281+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:35:02.281+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:35:03.230+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:35:03.275+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:35:03.273+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:35:03.305+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:35:03.304+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:35:03.342+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.073 seconds
[2024-10-03T08:35:34.033+0000] {processor.py:186} INFO - Started process (PID=40759) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:35:34.047+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:35:34.049+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:35:34.048+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:35:35.215+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:35:35.302+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:35:35.301+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:35:35.334+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:35:35.333+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:35:35.362+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.340 seconds
[2024-10-03T08:36:05.636+0000] {processor.py:186} INFO - Started process (PID=41011) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:36:05.639+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:36:05.641+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:36:05.640+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:36:06.635+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:36:06.682+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:36:06.681+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:36:06.725+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:36:06.725+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:36:06.765+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.142 seconds
[2024-10-03T08:36:37.448+0000] {processor.py:186} INFO - Started process (PID=41060) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:36:37.461+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:36:37.463+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:36:37.462+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:36:38.299+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:36:38.337+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:36:38.336+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:36:38.364+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:36:38.363+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:36:38.387+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.948 seconds
[2024-10-03T08:37:08.938+0000] {processor.py:186} INFO - Started process (PID=41112) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:37:08.943+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:37:08.945+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:37:08.944+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:37:09.819+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:37:09.855+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:37:09.854+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:37:09.881+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:37:09.881+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:37:09.903+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.974 seconds
[2024-10-03T08:37:40.536+0000] {processor.py:186} INFO - Started process (PID=41282) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:37:40.551+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:37:40.554+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:37:40.553+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:37:42.522+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:37:42.606+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:37:42.605+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:37:42.671+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:37:42.671+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:37:42.711+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 2.190 seconds
[2024-10-03T08:38:13.210+0000] {processor.py:186} INFO - Started process (PID=41460) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:38:13.212+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:38:13.216+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:38:13.214+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:38:14.170+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:38:14.213+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:38:14.213+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:38:14.244+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:38:14.244+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:38:14.269+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.072 seconds
[2024-10-03T08:38:44.692+0000] {processor.py:186} INFO - Started process (PID=41509) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:38:44.706+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:38:44.708+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:38:44.707+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:38:45.733+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:38:45.781+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:38:45.780+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:38:45.816+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:38:45.815+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:38:45.857+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.175 seconds
[2024-10-03T08:39:16.084+0000] {processor.py:186} INFO - Started process (PID=41612) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:39:16.088+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:39:16.099+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:39:16.092+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:39:17.861+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:39:17.915+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:39:17.914+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:39:17.954+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:39:17.954+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:39:17.984+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.939 seconds
[2024-10-03T08:39:48.281+0000] {processor.py:186} INFO - Started process (PID=41835) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:39:48.283+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:39:48.285+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:39:48.284+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:39:49.388+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:39:49.452+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:39:49.451+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:39:49.487+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:39:49.487+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:39:49.520+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.248 seconds
[2024-10-03T08:40:20.148+0000] {processor.py:186} INFO - Started process (PID=41884) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:40:20.161+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:40:20.163+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:40:20.162+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:40:21.036+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:40:21.075+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:40:21.074+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:40:21.101+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:40:21.101+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:40:21.132+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.991 seconds
[2024-10-03T08:40:51.531+0000] {processor.py:186} INFO - Started process (PID=41933) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:40:51.544+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:40:51.546+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:40:51.545+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:40:52.446+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:40:52.483+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:40:52.483+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:40:52.511+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:40:52.511+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:40:52.535+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.012 seconds
[2024-10-03T08:41:22.959+0000] {processor.py:186} INFO - Started process (PID=42042) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:41:22.973+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:41:22.975+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:41:22.974+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:41:24.050+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:41:24.112+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:41:24.111+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:41:24.148+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:41:24.148+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:41:24.180+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.231 seconds
[2024-10-03T08:41:54.573+0000] {processor.py:186} INFO - Started process (PID=42285) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:41:54.588+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:41:54.592+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:41:54.591+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:41:55.967+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:41:56.025+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:41:56.024+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:41:56.078+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:41:56.078+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:41:56.119+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.564 seconds
[2024-10-03T08:42:26.796+0000] {processor.py:186} INFO - Started process (PID=42367) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:42:26.798+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:42:26.800+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:42:26.799+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:42:27.838+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:42:27.884+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:42:27.884+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:42:27.917+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:42:27.917+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:42:27.959+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.173 seconds
[2024-10-03T08:42:58.520+0000] {processor.py:186} INFO - Started process (PID=42416) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:42:58.533+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:42:58.536+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:42:58.535+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:42:59.500+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:42:59.552+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:42:59.552+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:42:59.577+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:42:59.576+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:42:59.612+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.104 seconds
[2024-10-03T08:43:29.778+0000] {processor.py:186} INFO - Started process (PID=42465) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:43:29.780+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:43:29.783+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:43:29.782+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:43:30.715+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:43:30.772+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:43:30.771+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:43:30.820+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:43:30.820+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:43:30.871+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.100 seconds
[2024-10-03T08:44:01.181+0000] {processor.py:186} INFO - Started process (PID=42550) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:44:01.194+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:44:01.196+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:44:01.196+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:44:02.342+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:44:02.392+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:44:02.392+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:44:02.430+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:44:02.430+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:44:02.471+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.298 seconds
[2024-10-03T08:44:32.994+0000] {processor.py:186} INFO - Started process (PID=42607) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:44:32.996+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:44:32.998+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:44:32.997+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:44:34.355+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:44:34.400+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:44:34.400+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:44:34.436+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:44:34.436+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:44:34.468+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.484 seconds
[2024-10-03T08:45:05.281+0000] {processor.py:186} INFO - Started process (PID=42672) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:45:05.286+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:45:05.290+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:45:05.288+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:45:06.622+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:45:06.667+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:45:06.667+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:45:06.711+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:45:06.711+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:45:06.754+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.496 seconds
[2024-10-03T08:45:37.738+0000] {processor.py:186} INFO - Started process (PID=42881) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:45:37.818+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:45:37.823+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:45:37.822+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:45:39.694+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:45:39.785+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:45:39.784+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:45:39.850+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:45:39.849+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:45:39.946+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 2.231 seconds
[2024-10-03T08:46:10.890+0000] {processor.py:186} INFO - Started process (PID=43047) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:46:10.903+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:46:10.905+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:46:10.905+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:46:11.979+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:46:12.026+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:46:12.025+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:46:12.055+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:46:12.055+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:46:12.081+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.203 seconds
[2024-10-03T08:46:42.432+0000] {processor.py:186} INFO - Started process (PID=43096) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:46:42.444+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:46:42.446+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:46:42.446+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:46:43.670+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:46:43.707+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:46:43.707+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:46:43.736+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:46:43.735+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:46:43.769+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.346 seconds
[2024-10-03T08:47:13.889+0000] {processor.py:186} INFO - Started process (PID=43145) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:47:13.902+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:47:13.904+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:47:13.903+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:47:15.028+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:47:15.077+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:47:15.076+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:47:15.115+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:47:15.114+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:47:15.153+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.273 seconds
[2024-10-03T08:47:45.291+0000] {processor.py:186} INFO - Started process (PID=43194) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:47:45.294+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:47:45.296+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:47:45.296+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:47:46.283+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:47:46.322+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:47:46.321+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:47:46.353+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:47:46.352+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:47:46.379+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.099 seconds
[2024-10-03T08:48:16.864+0000] {processor.py:186} INFO - Started process (PID=43249) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:48:16.876+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:48:16.877+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:48:16.877+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:48:17.801+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:48:17.837+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:48:17.836+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:48:17.866+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:48:17.866+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:48:17.894+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.039 seconds
[2024-10-03T08:48:48.087+0000] {processor.py:186} INFO - Started process (PID=43424) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:48:48.102+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:48:48.111+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:48:48.110+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:48:49.784+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:48:49.880+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:48:49.879+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:48:49.945+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:48:49.944+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:48:50.018+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.952 seconds
[2024-10-03T08:49:20.247+0000] {processor.py:186} INFO - Started process (PID=43585) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:49:20.249+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:49:20.252+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:49:20.251+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:49:21.562+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:49:21.611+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:49:21.610+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:49:21.667+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:49:21.666+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:49:21.703+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.477 seconds
[2024-10-03T08:49:52.037+0000] {processor.py:186} INFO - Started process (PID=43634) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:49:52.050+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:49:52.055+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:49:52.055+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:49:53.064+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:49:53.115+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:49:53.115+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:49:53.156+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:49:53.156+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:49:53.188+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.163 seconds
[2024-10-03T08:50:23.296+0000] {processor.py:186} INFO - Started process (PID=43686) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:50:23.298+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:50:23.302+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:50:23.302+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:50:24.304+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:50:24.338+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:50:24.338+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:50:24.366+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:50:24.366+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:50:24.401+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.116 seconds
[2024-10-03T08:50:54.608+0000] {processor.py:186} INFO - Started process (PID=43737) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:50:54.609+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:50:54.611+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:50:54.611+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:50:55.483+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:50:55.533+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:50:55.533+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:50:55.565+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:50:55.564+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:50:55.599+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.001 seconds
[2024-10-03T08:51:26.341+0000] {processor.py:186} INFO - Started process (PID=43853) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:51:26.345+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:51:26.347+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:51:26.347+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:51:27.960+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:51:28.027+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:51:28.026+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:51:28.079+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:51:28.078+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:51:28.127+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.809 seconds
[2024-10-03T08:51:58.204+0000] {processor.py:186} INFO - Started process (PID=44095) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:51:58.205+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:51:58.207+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:51:58.207+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:51:59.286+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:51:59.329+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:51:59.328+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:51:59.358+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:51:59.358+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:51:59.399+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.208 seconds
[2024-10-03T08:52:29.917+0000] {processor.py:186} INFO - Started process (PID=44144) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:52:29.919+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:52:29.922+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:52:29.922+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:52:30.948+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:52:31.046+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:52:31.045+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:52:31.101+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:52:31.101+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:52:31.155+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.246 seconds
[2024-10-03T08:53:01.561+0000] {processor.py:186} INFO - Started process (PID=44359) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:53:01.576+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:53:01.580+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:53:01.579+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:53:03.458+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:53:03.527+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:53:03.526+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:53:03.597+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:53:03.596+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:53:03.660+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 2.119 seconds
[2024-10-03T08:53:34.306+0000] {processor.py:186} INFO - Started process (PID=44496) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:53:34.309+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:53:34.313+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:53:34.312+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:53:35.248+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:53:35.289+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:53:35.288+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:53:35.320+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:53:35.319+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:53:35.348+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.052 seconds
[2024-10-03T08:54:05.460+0000] {processor.py:186} INFO - Started process (PID=44545) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:54:05.472+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:54:05.475+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:54:05.474+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:54:06.321+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:54:06.355+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:54:06.354+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:54:06.382+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:54:06.381+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:54:06.415+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.962 seconds
[2024-10-03T08:54:36.710+0000] {processor.py:186} INFO - Started process (PID=44594) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:54:36.722+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:54:36.724+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:54:36.724+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:54:37.544+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:54:37.578+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:54:37.578+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:54:37.603+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:54:37.603+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:54:37.640+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.937 seconds
[2024-10-03T08:55:08.008+0000] {processor.py:186} INFO - Started process (PID=44643) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:55:08.020+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:55:08.023+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:55:08.021+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:55:08.999+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:55:09.049+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:55:09.048+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:55:09.099+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:55:09.098+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:55:09.131+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.131 seconds
[2024-10-03T08:55:39.453+0000] {processor.py:186} INFO - Started process (PID=44692) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:55:39.466+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:55:39.470+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:55:39.469+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:55:40.465+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:55:40.513+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:55:40.512+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:55:40.553+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:55:40.552+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:55:40.579+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.144 seconds
[2024-10-03T08:56:11.304+0000] {processor.py:186} INFO - Started process (PID=44802) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:56:11.306+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:56:11.312+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:56:11.311+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:56:12.471+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:56:12.533+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:56:12.532+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:56:12.583+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:56:12.582+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:56:12.629+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.345 seconds
[2024-10-03T08:56:43.235+0000] {processor.py:186} INFO - Started process (PID=45098) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:56:43.247+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:56:43.250+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:56:43.249+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:56:44.214+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:56:44.275+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:56:44.275+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:56:44.304+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:56:44.303+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:56:44.327+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.102 seconds
[2024-10-03T08:57:14.564+0000] {processor.py:186} INFO - Started process (PID=45147) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:57:14.577+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:57:14.580+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:57:14.579+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:57:15.543+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:57:15.589+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:57:15.588+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:57:15.627+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:57:15.626+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:57:15.655+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.099 seconds
[2024-10-03T08:57:45.936+0000] {processor.py:186} INFO - Started process (PID=45199) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:57:45.943+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:57:45.946+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:57:45.945+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:57:46.862+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:57:46.902+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:57:46.901+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:57:46.928+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:57:46.927+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:57:46.964+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.037 seconds
[2024-10-03T08:58:17.330+0000] {processor.py:186} INFO - Started process (PID=45252) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:58:17.343+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:58:17.345+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:58:17.345+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:58:18.150+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:58:18.185+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:58:18.185+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:58:18.210+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:58:18.210+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:58:18.242+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.922 seconds
[2024-10-03T08:58:48.929+0000] {processor.py:186} INFO - Started process (PID=45306) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:58:48.933+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:58:48.936+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:58:48.935+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:58:49.977+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:58:50.017+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:58:50.016+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:58:50.046+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:58:50.045+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:58:50.080+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.166 seconds
[2024-10-03T08:59:20.201+0000] {processor.py:186} INFO - Started process (PID=45355) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:59:20.213+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:59:20.216+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:59:20.215+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:59:21.150+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:59:21.211+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:59:21.210+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:59:21.255+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:59:21.254+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:59:21.285+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.095 seconds
[2024-10-03T08:59:51.352+0000] {processor.py:186} INFO - Started process (PID=45467) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:59:51.353+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T08:59:51.355+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:59:51.355+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:59:52.873+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T08:59:52.926+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:59:52.926+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T08:59:52.960+0000] {logging_mixin.py:190} INFO - [2024-10-03T08:59:52.959+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T08:59:53.001+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.659 seconds
[2024-10-03T09:00:23.214+0000] {processor.py:186} INFO - Started process (PID=45746) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:00:23.220+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:00:23.223+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:00:23.222+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:00:24.530+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:00:24.578+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:00:24.577+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:00:24.609+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:00:24.609+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:00:24.644+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.465 seconds
[2024-10-03T09:00:55.610+0000] {processor.py:186} INFO - Started process (PID=45796) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:00:55.612+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:00:55.613+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:00:55.613+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:00:56.517+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:00:56.560+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:00:56.559+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:00:56.595+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:00:56.595+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:00:56.626+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.027 seconds
[2024-10-03T09:01:26.909+0000] {processor.py:186} INFO - Started process (PID=45845) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:01:26.912+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:01:26.925+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:01:26.924+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:01:28.614+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:01:28.674+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:01:28.673+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:01:28.719+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:01:28.718+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:01:28.789+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.904 seconds
[2024-10-03T09:01:59.456+0000] {processor.py:186} INFO - Started process (PID=45894) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:01:59.469+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:01:59.471+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:01:59.470+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:02:00.632+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:02:00.682+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:02:00.681+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:02:00.717+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:02:00.716+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:02:00.755+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.311 seconds
[2024-10-03T09:02:31.727+0000] {processor.py:186} INFO - Started process (PID=45943) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:02:31.741+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:02:31.743+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:02:31.742+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:02:32.976+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:02:33.033+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:02:33.032+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:02:33.079+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:02:33.078+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:02:33.121+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.406 seconds
[2024-10-03T09:03:03.966+0000] {processor.py:186} INFO - Started process (PID=45992) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:03:03.968+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:03:03.971+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:03:03.970+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:03:05.419+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:03:05.468+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:03:05.467+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:03:05.511+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:03:05.511+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:03:05.543+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.588 seconds
[2024-10-03T09:03:35.736+0000] {processor.py:186} INFO - Started process (PID=46041) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:03:35.751+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:03:35.753+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:03:35.753+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:03:37.192+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:03:37.239+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:03:37.238+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:03:37.278+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:03:37.278+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:03:37.317+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.598 seconds
[2024-10-03T09:04:07.757+0000] {processor.py:186} INFO - Started process (PID=46090) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:04:07.770+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:04:07.772+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:04:07.772+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:04:09.130+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:04:09.199+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:04:09.199+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:04:09.233+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:04:09.233+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:04:09.271+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.527 seconds
[2024-10-03T09:04:39.677+0000] {processor.py:186} INFO - Started process (PID=46274) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:04:39.680+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:04:39.683+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:04:39.682+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:04:42.021+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:04:42.143+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:04:42.141+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:04:42.207+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:04:42.206+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:04:42.265+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 2.606 seconds
[2024-10-03T09:05:12.437+0000] {processor.py:186} INFO - Started process (PID=46472) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:05:12.439+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:05:12.441+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:05:12.440+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:05:13.614+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:05:13.657+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:05:13.656+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:05:13.688+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:05:13.687+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:05:13.729+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.304 seconds
[2024-10-03T09:05:43.932+0000] {processor.py:186} INFO - Started process (PID=46523) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:05:43.945+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:05:43.948+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:05:43.947+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:05:44.956+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:05:45.016+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:05:45.016+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:05:45.053+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:05:45.053+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:05:45.082+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.165 seconds
[2024-10-03T09:06:15.356+0000] {processor.py:186} INFO - Started process (PID=46572) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:06:15.359+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:06:15.362+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:06:15.361+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:06:16.557+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:06:16.628+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:06:16.627+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:06:16.672+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:06:16.672+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:06:16.711+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.370 seconds
[2024-10-03T09:06:47.480+0000] {processor.py:186} INFO - Started process (PID=46621) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:06:47.482+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:06:47.485+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:06:47.484+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:06:48.612+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:06:48.655+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:06:48.654+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:06:48.689+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:06:48.689+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:06:48.726+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.260 seconds
[2024-10-03T09:07:19.080+0000] {processor.py:186} INFO - Started process (PID=46670) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:07:19.082+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:07:19.085+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:07:19.084+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:07:20.647+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:07:20.738+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:07:20.736+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:07:20.787+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:07:20.787+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:07:20.816+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.750 seconds
[2024-10-03T09:07:51.280+0000] {processor.py:186} INFO - Started process (PID=46719) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:07:51.292+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:07:51.294+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:07:51.294+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:07:52.914+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:07:52.976+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:07:52.975+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:07:53.022+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:07:53.022+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:07:53.062+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.795 seconds
[2024-10-03T09:08:23.254+0000] {processor.py:186} INFO - Started process (PID=46773) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:08:23.256+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:08:23.259+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:08:23.258+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:08:24.554+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:08:24.605+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:08:24.605+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:08:24.640+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:08:24.639+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:08:24.668+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.427 seconds
[2024-10-03T09:08:55.518+0000] {processor.py:186} INFO - Started process (PID=46827) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:08:55.531+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:08:55.533+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:08:55.532+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:08:56.706+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:08:56.758+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:08:56.758+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:08:56.806+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:08:56.806+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:08:56.856+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.355 seconds
[2024-10-03T09:09:27.089+0000] {processor.py:186} INFO - Started process (PID=46880) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:09:27.091+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:09:27.094+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:09:27.093+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:09:29.364+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:09:29.466+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:09:29.465+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:09:29.550+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:09:29.549+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:09:29.623+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 2.547 seconds
[2024-10-03T09:09:59.791+0000] {processor.py:186} INFO - Started process (PID=47099) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:09:59.804+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:09:59.808+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:09:59.806+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:10:01.794+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:10:01.889+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:10:01.888+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:10:01.981+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:10:01.980+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:10:02.028+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 2.256 seconds
[2024-10-03T09:10:32.530+0000] {processor.py:186} INFO - Started process (PID=47282) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:10:32.532+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:10:32.533+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:10:32.533+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:10:33.732+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:10:33.791+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:10:33.791+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:10:33.837+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:10:33.836+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:10:33.882+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.368 seconds
[2024-10-03T09:11:03.983+0000] {processor.py:186} INFO - Started process (PID=47331) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:11:03.987+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:11:03.991+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:11:03.990+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:11:05.812+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:11:05.873+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:11:05.872+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:11:05.916+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:11:05.915+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:11:05.967+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 2.010 seconds
[2024-10-03T09:11:36.226+0000] {processor.py:186} INFO - Started process (PID=47385) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:11:36.229+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:11:36.232+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:11:36.231+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:11:37.758+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:11:37.815+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:11:37.814+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:11:37.866+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:11:37.866+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:11:37.917+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.708 seconds
[2024-10-03T09:12:08.314+0000] {processor.py:186} INFO - Started process (PID=47558) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:12:08.317+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:12:08.322+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:12:08.321+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:12:10.193+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:12:10.289+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:12:10.288+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:12:10.358+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:12:10.357+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:12:10.394+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 2.101 seconds
[2024-10-03T09:12:40.906+0000] {processor.py:186} INFO - Started process (PID=47749) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:12:40.909+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:12:40.913+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:12:40.912+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:12:42.376+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:12:42.431+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:12:42.430+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:12:42.465+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:12:42.464+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:12:42.501+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.619 seconds
[2024-10-03T09:13:12.954+0000] {processor.py:186} INFO - Started process (PID=47798) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:13:12.967+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:13:12.970+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:13:12.970+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:13:13.993+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:13:14.033+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:13:14.033+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:13:14.067+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:13:14.067+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:13:14.096+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.154 seconds
[2024-10-03T09:13:44.445+0000] {processor.py:186} INFO - Started process (PID=47847) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:13:44.447+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:13:44.449+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:13:44.449+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:13:45.593+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:13:45.644+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:13:45.643+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:13:45.686+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:13:45.686+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:13:45.716+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.288 seconds
[2024-10-03T09:14:15.919+0000] {processor.py:186} INFO - Started process (PID=47896) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:14:15.932+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:14:15.934+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:14:15.934+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:14:16.863+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:14:16.902+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:14:16.902+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:14:16.939+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:14:16.938+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:14:16.979+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.069 seconds
[2024-10-03T09:14:47.361+0000] {processor.py:186} INFO - Started process (PID=47945) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:14:47.374+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:14:47.376+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:14:47.376+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:14:48.507+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:14:48.558+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:14:48.558+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:14:48.597+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:14:48.597+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:14:48.635+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.283 seconds
[2024-10-03T09:15:19.429+0000] {processor.py:186} INFO - Started process (PID=48061) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:15:19.432+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:15:19.435+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:15:19.434+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:15:20.825+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:15:20.886+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:15:20.885+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:15:20.932+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:15:20.931+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:15:20.961+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.550 seconds
[2024-10-03T09:15:51.513+0000] {processor.py:186} INFO - Started process (PID=48308) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:15:51.516+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:15:51.522+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:15:51.521+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:15:52.980+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:15:53.049+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:15:53.049+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:15:53.096+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:15:53.095+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:15:53.128+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.636 seconds
[2024-10-03T09:16:23.609+0000] {processor.py:186} INFO - Started process (PID=48394) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:16:23.624+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:16:23.628+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:16:23.627+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:16:25.769+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:16:25.850+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:16:25.848+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:16:25.929+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:16:25.928+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:16:25.964+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 2.405 seconds
[2024-10-03T09:16:56.213+0000] {processor.py:186} INFO - Started process (PID=48527) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:16:56.215+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:16:56.220+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:16:56.219+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:16:57.962+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:16:58.054+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:16:58.053+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:16:58.125+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:16:58.125+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:16:58.169+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.975 seconds
[2024-10-03T09:17:28.952+0000] {processor.py:186} INFO - Started process (PID=48789) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:17:28.954+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:17:28.956+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:17:28.955+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:17:29.951+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:17:29.992+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:17:29.992+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:17:30.025+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:17:30.024+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:17:30.064+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.122 seconds
[2024-10-03T09:18:00.562+0000] {processor.py:186} INFO - Started process (PID=48838) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:18:00.575+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:18:00.578+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:18:00.577+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:18:01.571+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:18:01.611+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:18:01.610+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:18:01.646+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:18:01.646+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:18:01.672+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.120 seconds
[2024-10-03T09:18:32.389+0000] {processor.py:186} INFO - Started process (PID=48887) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:18:32.391+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:18:32.393+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:18:32.393+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:18:33.689+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:18:33.742+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:18:33.742+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:18:33.777+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:18:33.776+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:18:33.815+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.441 seconds
[2024-10-03T09:19:03.954+0000] {processor.py:186} INFO - Started process (PID=48989) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:19:03.958+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:19:03.962+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:19:03.961+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:19:05.740+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:19:05.823+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:19:05.822+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:19:05.903+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:19:05.902+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:19:05.988+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 2.057 seconds
[2024-10-03T09:19:36.105+0000] {processor.py:186} INFO - Started process (PID=49204) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:19:36.119+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:19:36.123+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:19:36.122+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:19:38.265+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:19:38.374+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:19:38.373+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:19:38.432+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:19:38.431+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:19:38.479+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 2.399 seconds
[2024-10-03T09:20:09.537+0000] {processor.py:186} INFO - Started process (PID=49337) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:20:09.541+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:20:09.553+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:20:09.551+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:20:10.685+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:20:10.733+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:20:10.732+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:20:10.769+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:20:10.768+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:20:10.809+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.304 seconds
[2024-10-03T09:20:41.162+0000] {processor.py:186} INFO - Started process (PID=49396) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:20:41.165+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:20:41.167+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:20:41.166+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:20:42.145+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:20:42.185+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:20:42.184+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:20:42.219+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:20:42.218+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:20:42.257+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.105 seconds
[2024-10-03T09:21:12.659+0000] {processor.py:186} INFO - Started process (PID=49574) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:21:12.677+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:21:12.684+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:21:12.682+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:21:15.460+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:21:15.579+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:21:15.577+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:21:15.657+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:21:15.656+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:21:15.720+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 3.092 seconds
[2024-10-03T09:21:46.589+0000] {processor.py:186} INFO - Started process (PID=49791) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:21:46.591+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:21:46.593+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:21:46.593+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:21:47.756+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:21:47.799+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:21:47.798+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:21:47.833+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:21:47.832+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:21:47.862+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.282 seconds
[2024-10-03T09:22:18.026+0000] {processor.py:186} INFO - Started process (PID=49840) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:22:18.028+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:22:18.031+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:22:18.030+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:22:19.220+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:22:19.269+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:22:19.268+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:22:19.309+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:22:19.308+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:22:19.344+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.329 seconds
[2024-10-03T09:22:49.490+0000] {processor.py:186} INFO - Started process (PID=49889) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:22:49.491+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:22:49.495+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:22:49.494+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:22:50.768+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:22:50.840+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:22:50.840+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:22:50.882+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:22:50.881+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:22:50.922+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.446 seconds
[2024-10-03T09:23:21.055+0000] {processor.py:186} INFO - Started process (PID=49938) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:23:21.067+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:23:21.070+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:23:21.069+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:23:22.065+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:23:22.122+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:23:22.121+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:23:22.157+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:23:22.157+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:23:22.185+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.141 seconds
[2024-10-03T09:23:52.780+0000] {processor.py:186} INFO - Started process (PID=49987) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:23:52.793+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:23:52.795+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:23:52.795+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:23:54.021+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:23:54.089+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:23:54.088+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:23:54.129+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:23:54.129+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:23:54.168+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.402 seconds
[2024-10-03T09:24:24.918+0000] {processor.py:186} INFO - Started process (PID=50036) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:24:24.920+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:24:24.922+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:24:24.922+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:24:26.148+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:24:26.202+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:24:26.201+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:24:26.246+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:24:26.246+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:24:26.288+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.382 seconds
[2024-10-03T09:24:56.392+0000] {processor.py:186} INFO - Started process (PID=50089) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:24:56.395+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:24:56.397+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:24:56.396+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:24:57.520+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:24:57.562+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:24:57.561+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:24:57.599+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:24:57.598+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:24:57.623+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.240 seconds
[2024-10-03T09:25:28.399+0000] {processor.py:186} INFO - Started process (PID=50138) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:25:28.401+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:25:28.404+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:25:28.403+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:25:29.534+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:25:29.658+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:25:29.650+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:25:29.717+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:25:29.716+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:25:29.763+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.377 seconds
[2024-10-03T09:26:00.119+0000] {processor.py:186} INFO - Started process (PID=50189) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:26:00.122+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:26:00.125+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:26:00.124+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:26:01.420+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:26:01.477+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:26:01.476+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:26:01.514+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:26:01.513+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:26:01.592+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.491 seconds
[2024-10-03T09:26:32.043+0000] {processor.py:186} INFO - Started process (PID=50238) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:26:32.046+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:26:32.049+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:26:32.048+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:26:33.444+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:26:33.490+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:26:33.489+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:26:33.547+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:26:33.547+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:26:33.594+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.566 seconds
[2024-10-03T09:27:04.542+0000] {processor.py:186} INFO - Started process (PID=50425) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:27:04.556+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:27:04.560+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:27:04.559+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:27:07.136+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:27:07.247+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:27:07.246+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:27:07.319+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:27:07.317+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:27:07.402+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 2.880 seconds
[2024-10-03T09:27:37.556+0000] {processor.py:186} INFO - Started process (PID=50572) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:27:37.702+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:27:37.704+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:27:37.703+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:27:38.856+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:27:38.937+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:27:38.936+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:27:38.977+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:27:38.976+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:27:39.181+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.634 seconds
[2024-10-03T09:28:09.296+0000] {processor.py:186} INFO - Started process (PID=50624) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:28:09.299+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:28:09.302+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:28:09.301+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:28:10.524+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:28:10.591+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:28:10.591+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:28:10.637+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:28:10.637+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:28:10.672+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.391 seconds
[2024-10-03T09:28:40.845+0000] {processor.py:186} INFO - Started process (PID=50680) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:28:40.848+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:28:40.851+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:28:40.850+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:28:41.979+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:28:42.023+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:28:42.023+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:28:42.059+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:28:42.058+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:28:42.099+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.271 seconds
[2024-10-03T09:29:13.050+0000] {processor.py:186} INFO - Started process (PID=50729) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:29:13.053+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:29:13.056+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:29:13.055+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:29:14.281+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:29:14.355+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:29:14.354+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:29:14.405+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:29:14.405+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:29:14.438+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.403 seconds
[2024-10-03T09:29:44.942+0000] {processor.py:186} INFO - Started process (PID=50778) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:29:44.950+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:29:44.958+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:29:44.956+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:29:47.355+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:29:47.431+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:29:47.430+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:29:47.487+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:29:47.486+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:29:47.520+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 2.593 seconds
[2024-10-03T09:30:27.856+0000] {processor.py:186} INFO - Started process (PID=194) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:30:27.858+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:30:27.863+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:30:27.863+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:30:33.987+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:30:34.052+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:30:34.051+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:30:34.102+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:30:34.102+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:30:34.141+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.296 seconds
[2024-10-03T09:31:04.291+0000] {processor.py:186} INFO - Started process (PID=267) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:31:04.297+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:31:04.310+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:31:04.309+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:31:05.624+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:31:05.693+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:31:05.691+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:31:05.742+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:31:05.742+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:31:05.784+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.545 seconds
[2024-10-03T09:31:35.990+0000] {processor.py:186} INFO - Started process (PID=313) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:31:36.002+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:31:36.007+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:31:36.006+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:31:36.910+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:31:36.979+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:31:36.978+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:31:37.030+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:31:37.030+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:31:37.061+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.083 seconds
[2024-10-03T09:32:07.161+0000] {processor.py:186} INFO - Started process (PID=363) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:32:07.165+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:32:07.170+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:32:07.169+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:32:09.133+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:32:09.243+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:32:09.242+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:32:09.324+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:32:09.324+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:32:09.378+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 2.240 seconds
[2024-10-03T09:32:39.736+0000] {processor.py:186} INFO - Started process (PID=558) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:32:39.754+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:32:39.761+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:32:39.760+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:32:41.379+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:32:41.481+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:32:41.480+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:32:41.551+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:32:41.551+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:32:41.596+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.882 seconds
[2024-10-03T09:33:12.002+0000] {processor.py:186} INFO - Started process (PID=685) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:33:12.004+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:33:12.007+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:33:12.007+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:33:12.778+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:33:12.814+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:33:12.813+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:33:12.850+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:33:12.850+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:33:12.885+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.895 seconds
[2024-10-03T09:33:42.965+0000] {processor.py:186} INFO - Started process (PID=742) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:33:42.966+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:33:42.970+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:33:42.969+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:33:43.763+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:33:43.805+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:33:43.804+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:33:43.844+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:33:43.844+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:33:43.887+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.931 seconds
[2024-10-03T09:34:14.239+0000] {processor.py:186} INFO - Started process (PID=926) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:34:14.243+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:34:14.250+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:34:14.249+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:34:16.396+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:34:16.508+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:34:16.506+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:34:16.608+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:34:16.607+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:34:16.725+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 2.509 seconds
[2024-10-03T09:34:46.942+0000] {processor.py:186} INFO - Started process (PID=1057) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:34:46.944+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:34:46.951+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:34:46.950+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:34:48.082+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:34:48.137+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:34:48.136+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:34:48.173+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:34:48.173+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:34:48.209+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.281 seconds
[2024-10-03T09:35:18.523+0000] {processor.py:186} INFO - Started process (PID=1239) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:35:18.529+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:35:18.535+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:35:18.534+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:35:20.130+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:35:20.221+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:35:20.220+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:35:20.309+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:35:20.308+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:35:20.365+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.877 seconds
[2024-10-03T09:35:50.926+0000] {processor.py:186} INFO - Started process (PID=1377) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:35:50.938+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:35:50.941+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:35:50.940+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:35:51.535+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:35:51.571+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:35:51.571+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:35:51.600+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:35:51.600+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:35:51.628+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.710 seconds
[2024-10-03T09:36:22.163+0000] {processor.py:186} INFO - Started process (PID=1426) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:36:22.175+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:36:22.178+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:36:22.178+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:36:22.961+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:36:23.029+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:36:23.028+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:36:23.086+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:36:23.085+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:36:23.124+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.974 seconds
[2024-10-03T09:36:53.510+0000] {processor.py:186} INFO - Started process (PID=1475) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:36:53.512+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:36:53.517+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:36:53.517+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:36:54.452+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:36:54.543+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:36:54.542+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:36:54.619+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:36:54.619+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:36:54.663+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.165 seconds
[2024-10-03T09:37:25.330+0000] {processor.py:186} INFO - Started process (PID=1524) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:37:25.343+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:37:25.346+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:37:25.346+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:37:25.944+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:37:25.978+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:37:25.977+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:37:26.004+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:37:26.003+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:37:26.033+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.714 seconds
[2024-10-03T09:37:56.244+0000] {processor.py:186} INFO - Started process (PID=1573) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:37:56.246+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:37:56.250+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:37:56.250+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:37:56.859+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:37:56.893+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:37:56.893+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:37:56.925+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:37:56.925+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:37:56.962+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.728 seconds
[2024-10-03T09:38:27.002+0000] {processor.py:186} INFO - Started process (PID=1622) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:38:27.005+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:38:27.009+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:38:27.008+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:38:27.865+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:38:27.908+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:38:27.908+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:38:27.937+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:38:27.936+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:38:27.973+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.979 seconds
[2024-10-03T09:38:58.488+0000] {processor.py:186} INFO - Started process (PID=1671) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:38:58.490+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:38:58.495+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:38:58.494+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:38:59.158+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:38:59.204+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:38:59.203+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:38:59.238+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:38:59.238+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:38:59.266+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.794 seconds
[2024-10-03T09:39:30.085+0000] {processor.py:186} INFO - Started process (PID=1720) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:39:30.097+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:39:30.101+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:39:30.101+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:39:31.052+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:39:31.104+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:39:31.103+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:39:31.139+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:39:31.139+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:39:31.164+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.091 seconds
[2024-10-03T09:40:01.326+0000] {processor.py:186} INFO - Started process (PID=1769) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:40:01.339+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:40:01.342+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:40:01.341+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:40:02.284+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:40:02.334+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:40:02.333+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:40:02.370+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:40:02.369+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:40:02.392+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.078 seconds
[2024-10-03T09:40:32.742+0000] {processor.py:186} INFO - Started process (PID=1818) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:40:32.745+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:40:32.750+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:40:32.749+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:40:33.761+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:40:33.836+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:40:33.835+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:40:33.905+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:40:33.904+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:40:33.942+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.217 seconds
[2024-10-03T09:41:04.646+0000] {processor.py:186} INFO - Started process (PID=1986) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:41:04.650+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:41:04.658+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:41:04.657+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:41:06.310+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:41:06.414+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:41:06.413+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:41:06.486+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:41:06.486+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:41:06.531+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.907 seconds
[2024-10-03T09:41:36.612+0000] {processor.py:186} INFO - Started process (PID=2120) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:41:36.615+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:41:36.619+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:41:36.619+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:41:37.495+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:41:37.536+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:41:37.536+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:41:37.565+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:41:37.565+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:41:37.589+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.991 seconds
[2024-10-03T09:42:07.840+0000] {processor.py:186} INFO - Started process (PID=2169) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:42:07.849+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:42:07.853+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:42:07.852+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:42:08.766+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:42:08.831+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:42:08.831+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:42:08.884+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:42:08.883+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:42:08.921+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.096 seconds
[2024-10-03T09:42:39.082+0000] {processor.py:186} INFO - Started process (PID=2221) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:42:39.086+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:42:39.091+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:42:39.090+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:42:40.226+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:42:40.277+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:42:40.276+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:42:40.326+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:42:40.325+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:42:40.355+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.287 seconds
[2024-10-03T09:43:58.494+0000] {processor.py:186} INFO - Started process (PID=193) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:43:58.496+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:43:58.502+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:43:58.501+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:44:03.975+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:44:04.028+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:44:04.027+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:44:04.066+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:44:04.066+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:44:04.105+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.624 seconds
[2024-10-03T09:44:34.667+0000] {processor.py:186} INFO - Started process (PID=269) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:44:34.670+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:44:34.676+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:44:34.674+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:44:35.541+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:44:35.587+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:44:35.586+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:44:35.632+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:44:35.631+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:44:35.669+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.016 seconds
[2024-10-03T09:45:05.748+0000] {processor.py:186} INFO - Started process (PID=326) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:45:05.749+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:45:05.753+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:45:05.752+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:45:06.602+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:45:06.650+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:45:06.649+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:45:06.703+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:45:06.703+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:45:06.739+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.003 seconds
[2024-10-03T09:45:37.042+0000] {processor.py:186} INFO - Started process (PID=377) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:45:37.054+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:45:37.058+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:45:37.057+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:45:38.164+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:45:38.217+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:45:38.216+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:45:38.260+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:45:38.259+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:45:38.305+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.273 seconds
[2024-10-03T09:46:08.524+0000] {processor.py:186} INFO - Started process (PID=437) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:46:08.536+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:46:08.540+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:46:08.539+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:46:09.241+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:46:09.288+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:46:09.288+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:46:09.342+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:46:09.341+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:46:09.374+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.858 seconds
[2024-10-03T09:46:54.992+0000] {processor.py:186} INFO - Started process (PID=193) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:46:54.995+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:46:55.000+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:46:54.999+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:46:59.326+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:46:59.379+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:46:59.378+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:46:59.418+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:46:59.418+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:46:59.449+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.472 seconds
[2024-10-03T09:47:30.116+0000] {processor.py:186} INFO - Started process (PID=267) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:47:30.118+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:47:30.127+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:47:30.126+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:47:31.240+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:47:31.335+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:47:31.334+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:47:31.414+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:47:31.413+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:47:31.458+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.358 seconds
[2024-10-03T09:48:01.673+0000] {processor.py:186} INFO - Started process (PID=381) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:48:01.684+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:48:01.690+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:48:01.689+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:48:03.233+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:48:03.309+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:48:03.308+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:48:03.363+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:48:03.362+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:48:03.398+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.773 seconds
[2024-10-03T09:48:33.558+0000] {processor.py:186} INFO - Started process (PID=597) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:48:33.560+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:48:33.566+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:48:33.565+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:48:34.499+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:48:34.543+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:48:34.541+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:48:34.587+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:48:34.586+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:48:34.620+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.077 seconds
[2024-10-03T09:49:04.768+0000] {processor.py:186} INFO - Started process (PID=646) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:49:04.770+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:49:04.777+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:49:04.776+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:49:05.641+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:49:05.684+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:49:05.684+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:49:05.718+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:49:05.718+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:49:05.760+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.001 seconds
[2024-10-03T09:49:35.886+0000] {processor.py:186} INFO - Started process (PID=697) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:49:35.893+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:49:35.897+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:49:35.897+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:49:36.601+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:49:36.634+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:49:36.634+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:49:36.662+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:49:36.661+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:49:36.692+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.822 seconds
[2024-10-03T09:50:07.281+0000] {processor.py:186} INFO - Started process (PID=751) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:50:07.283+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:50:07.288+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:50:07.287+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:50:08.210+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:50:08.260+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:50:08.259+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:50:08.306+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:50:08.306+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:50:08.337+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.076 seconds
[2024-10-03T09:50:38.672+0000] {processor.py:186} INFO - Started process (PID=806) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:50:38.674+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:50:38.679+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:50:38.678+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:50:39.343+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:50:39.399+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:50:39.398+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:50:39.432+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:50:39.432+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:50:39.466+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.810 seconds
[2024-10-03T09:51:09.540+0000] {processor.py:186} INFO - Started process (PID=855) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:51:09.553+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:51:09.556+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:51:09.556+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:51:10.253+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:51:10.320+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:51:10.319+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:51:10.361+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:51:10.361+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:51:10.391+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.861 seconds
[2024-10-03T09:51:40.786+0000] {processor.py:186} INFO - Started process (PID=902) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:51:40.789+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:51:40.795+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:51:40.794+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:51:41.580+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:51:41.613+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:51:41.612+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:51:41.645+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:51:41.645+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:51:41.687+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.912 seconds
[2024-10-03T09:52:11.802+0000] {processor.py:186} INFO - Started process (PID=951) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:52:11.804+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:52:11.808+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:52:11.807+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:52:12.478+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:52:12.512+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:52:12.511+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:52:12.543+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:52:12.543+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:52:12.580+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.789 seconds
[2024-10-03T09:52:43.267+0000] {processor.py:186} INFO - Started process (PID=1050) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:52:43.269+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:52:43.275+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:52:43.274+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:52:44.646+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:52:44.720+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:52:44.718+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:52:44.780+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:52:44.779+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:52:44.825+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.578 seconds
[2024-10-03T09:53:15.418+0000] {processor.py:186} INFO - Started process (PID=1276) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:53:15.431+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:53:15.435+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:53:15.434+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:53:16.341+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:53:16.386+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:53:16.385+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:53:16.425+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:53:16.425+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:53:16.450+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.049 seconds
[2024-10-03T09:53:46.721+0000] {processor.py:186} INFO - Started process (PID=1328) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:53:46.733+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:53:46.736+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:53:46.736+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:53:47.778+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:53:47.817+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:53:47.817+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:53:47.850+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:53:47.850+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:53:47.893+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.182 seconds
[2024-10-03T09:54:18.366+0000] {processor.py:186} INFO - Started process (PID=1374) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:54:18.379+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:54:18.382+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:54:18.382+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:54:19.152+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:54:19.193+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:54:19.193+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:54:19.226+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:54:19.226+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:54:19.257+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.905 seconds
[2024-10-03T09:54:49.373+0000] {processor.py:186} INFO - Started process (PID=1423) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:54:49.387+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:54:49.391+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:54:49.390+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:54:50.998+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:54:51.128+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:54:51.128+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:54:51.212+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:54:51.212+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:54:51.281+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.923 seconds
[2024-10-03T09:55:21.355+0000] {processor.py:186} INFO - Started process (PID=1472) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:55:21.357+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:55:21.360+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:55:21.360+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:55:22.153+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:55:22.215+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:55:22.214+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:55:22.250+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:55:22.249+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:55:22.277+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.933 seconds
[2024-10-03T09:55:52.446+0000] {processor.py:186} INFO - Started process (PID=1521) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:55:52.458+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:55:52.462+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:55:52.461+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:55:53.187+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:55:53.227+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:55:53.226+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:55:53.251+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:55:53.251+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:55:53.274+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.839 seconds
[2024-10-03T09:56:23.493+0000] {processor.py:186} INFO - Started process (PID=1573) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:56:23.496+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:56:23.499+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:56:23.499+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:56:24.186+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:56:24.215+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:56:24.215+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:56:24.242+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:56:24.241+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:56:24.274+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.790 seconds
[2024-10-03T09:56:54.495+0000] {processor.py:186} INFO - Started process (PID=1622) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:56:54.508+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:56:54.512+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:56:54.511+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:56:55.205+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:56:55.242+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:56:55.242+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:56:55.275+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:56:55.275+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:56:55.297+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.812 seconds
[2024-10-03T09:57:25.796+0000] {processor.py:186} INFO - Started process (PID=1674) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:57:25.798+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:57:25.800+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:57:25.800+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:57:26.591+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:57:26.633+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:57:26.632+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:57:26.660+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:57:26.660+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:57:26.684+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.895 seconds
[2024-10-03T09:57:57.034+0000] {processor.py:186} INFO - Started process (PID=1723) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:57:57.047+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:57:57.051+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:57:57.051+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:57:57.629+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:57:57.660+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:57:57.660+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:57:57.687+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:57:57.686+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:57:57.718+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.693 seconds
[2024-10-03T09:58:28.671+0000] {processor.py:186} INFO - Started process (PID=1772) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:58:28.673+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:58:28.679+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:58:28.677+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:58:29.299+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:58:29.330+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:58:29.329+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:58:29.354+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:58:29.353+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:58:29.392+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.735 seconds
[2024-10-03T09:59:00.171+0000] {processor.py:186} INFO - Started process (PID=1821) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:59:00.173+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:59:00.178+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:59:00.177+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:59:01.071+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:59:01.144+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:59:01.143+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:59:01.200+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:59:01.199+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:59:01.241+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.082 seconds
[2024-10-03T09:59:31.331+0000] {processor.py:186} INFO - Started process (PID=1870) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:59:31.333+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T09:59:31.338+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:59:31.338+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:59:32.216+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T09:59:32.288+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:59:32.287+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T09:59:32.326+0000] {logging_mixin.py:190} INFO - [2024-10-03T09:59:32.326+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T09:59:32.354+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.034 seconds
[2024-10-03T10:00:02.794+0000] {processor.py:186} INFO - Started process (PID=1919) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:00:02.806+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:00:02.809+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:00:02.809+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:00:03.399+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:00:03.438+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:00:03.437+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:00:03.490+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:00:03.490+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:00:03.511+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.728 seconds
[2024-10-03T10:00:33.675+0000] {processor.py:186} INFO - Started process (PID=1968) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:00:33.677+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:00:33.679+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:00:33.679+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:00:34.351+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:00:34.386+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:00:34.385+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:00:34.414+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:00:34.413+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:00:34.448+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.781 seconds
[2024-10-03T10:01:04.760+0000] {processor.py:186} INFO - Started process (PID=2017) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:01:04.772+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:01:04.776+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:01:04.776+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:01:05.320+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:01:05.353+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:01:05.353+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:01:05.379+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:01:05.379+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:01:05.410+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.657 seconds
[2024-10-03T10:01:35.747+0000] {processor.py:186} INFO - Started process (PID=2066) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:01:35.749+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:01:35.753+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:01:35.752+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:01:36.317+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:01:36.350+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:01:36.350+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:01:36.377+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:01:36.376+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:01:36.413+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.673 seconds
[2024-10-03T10:02:06.545+0000] {processor.py:186} INFO - Started process (PID=2115) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:02:06.557+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:02:06.561+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:02:06.560+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:02:07.145+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:02:07.175+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:02:07.175+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:02:07.202+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:02:07.201+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:02:07.234+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.697 seconds
[2024-10-03T10:02:37.343+0000] {processor.py:186} INFO - Started process (PID=2169) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:02:37.345+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:02:37.348+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:02:37.347+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:02:37.891+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:02:37.922+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:02:37.921+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:02:37.955+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:02:37.954+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:02:37.985+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.650 seconds
[2024-10-03T10:03:08.448+0000] {processor.py:186} INFO - Started process (PID=2218) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:03:08.450+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:03:08.454+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:03:08.454+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:03:09.070+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:03:09.102+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:03:09.101+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:03:09.128+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:03:09.128+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:03:09.165+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.728 seconds
[2024-10-03T10:03:40.096+0000] {processor.py:186} INFO - Started process (PID=2267) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:03:40.098+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:03:40.102+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:03:40.101+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:03:40.714+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:03:40.749+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:03:40.748+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:03:40.773+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:03:40.772+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:03:40.806+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.718 seconds
[2024-10-03T10:04:10.913+0000] {processor.py:186} INFO - Started process (PID=2316) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:04:10.925+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:04:10.929+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:04:10.929+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:04:11.559+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:04:11.591+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:04:11.590+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:04:11.623+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:04:11.623+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:04:11.648+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.743 seconds
[2024-10-03T10:04:42.613+0000] {processor.py:186} INFO - Started process (PID=2365) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:04:42.614+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:04:42.618+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:04:42.617+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:04:43.179+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:04:43.211+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:04:43.210+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:04:43.236+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:04:43.236+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:04:43.272+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.666 seconds
[2024-10-03T10:05:13.830+0000] {processor.py:186} INFO - Started process (PID=2414) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:05:13.837+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:05:13.840+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:05:13.840+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:05:14.372+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:05:14.402+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:05:14.401+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:05:14.431+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:05:14.430+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:05:14.452+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.629 seconds
[2024-10-03T10:05:44.761+0000] {processor.py:186} INFO - Started process (PID=2463) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:05:44.762+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:05:44.767+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:05:44.766+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:05:45.581+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:05:45.617+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:05:45.617+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:05:45.646+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:05:45.645+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:05:45.674+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.925 seconds
[2024-10-03T10:06:16.117+0000] {processor.py:186} INFO - Started process (PID=2512) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:06:16.130+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:06:16.136+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:06:16.135+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:06:16.711+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:06:16.742+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:06:16.742+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:06:16.767+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:06:16.766+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:06:16.802+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.696 seconds
[2024-10-03T10:06:47.335+0000] {processor.py:186} INFO - Started process (PID=2561) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:06:47.338+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:06:47.341+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:06:47.341+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:06:47.992+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:06:48.031+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:06:48.030+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:06:48.069+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:06:48.068+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:06:48.102+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.775 seconds
[2024-10-03T10:07:18.153+0000] {processor.py:186} INFO - Started process (PID=2610) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:07:18.154+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:07:18.157+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:07:18.157+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:07:18.771+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:07:18.802+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:07:18.801+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:07:18.835+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:07:18.835+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:07:18.865+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.719 seconds
[2024-10-03T10:07:49.170+0000] {processor.py:186} INFO - Started process (PID=2659) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:07:49.171+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:07:49.175+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:07:49.174+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:07:49.711+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:07:49.760+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:07:49.760+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:07:49.787+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:07:49.787+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:07:49.819+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.658 seconds
[2024-10-03T10:08:19.992+0000] {processor.py:186} INFO - Started process (PID=2708) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:08:19.993+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:08:19.996+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:08:19.996+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:08:20.534+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:08:20.570+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:08:20.569+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:08:20.595+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:08:20.595+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:08:20.617+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.632 seconds
[2024-10-03T10:08:50.829+0000] {processor.py:186} INFO - Started process (PID=2757) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:08:50.842+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:08:50.847+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:08:50.847+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:08:51.404+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:08:51.438+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:08:51.437+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:08:51.467+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:08:51.467+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:08:51.499+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.684 seconds
[2024-10-03T10:09:21.600+0000] {processor.py:186} INFO - Started process (PID=2806) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:09:21.612+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:09:21.615+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:09:21.615+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:09:22.189+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:09:22.221+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:09:22.221+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:09:22.246+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:09:22.246+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:09:22.282+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.690 seconds
[2024-10-03T10:09:52.491+0000] {processor.py:186} INFO - Started process (PID=2855) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:09:52.493+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:09:52.496+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:09:52.496+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:09:53.065+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:09:53.098+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:09:53.098+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:09:53.123+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:09:53.122+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:09:53.146+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.664 seconds
[2024-10-03T10:10:23.799+0000] {processor.py:186} INFO - Started process (PID=2907) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:10:23.801+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:10:23.805+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:10:23.804+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:10:24.391+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:10:24.425+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:10:24.424+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:10:24.450+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:10:24.450+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:10:24.481+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.693 seconds
[2024-10-03T10:10:55.211+0000] {processor.py:186} INFO - Started process (PID=2958) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:10:55.214+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:10:55.217+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:10:55.217+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:10:55.770+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:10:55.819+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:10:55.819+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:10:55.865+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:10:55.865+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:10:55.910+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.707 seconds
[2024-10-03T10:11:26.246+0000] {processor.py:186} INFO - Started process (PID=3007) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:11:26.259+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:11:26.262+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:11:26.261+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:11:26.820+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:11:26.853+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:11:26.852+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:11:26.880+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:11:26.880+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:11:26.912+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.673 seconds
[2024-10-03T10:11:57.068+0000] {processor.py:186} INFO - Started process (PID=3056) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:11:57.080+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:11:57.083+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:11:57.082+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:11:57.641+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:11:57.674+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:11:57.674+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:11:57.699+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:11:57.698+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:11:57.723+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.662 seconds
[2024-10-03T10:12:28.039+0000] {processor.py:186} INFO - Started process (PID=3105) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:12:28.052+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:12:28.055+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:12:28.054+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:12:28.690+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:12:28.720+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:12:28.719+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:12:28.748+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:12:28.748+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:12:28.783+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.751 seconds
[2024-10-03T10:12:58.843+0000] {processor.py:186} INFO - Started process (PID=3154) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:12:58.856+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:12:58.859+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:12:58.859+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:12:59.387+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:12:59.420+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:12:59.420+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:12:59.445+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:12:59.445+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:12:59.469+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.639 seconds
[2024-10-03T10:13:29.705+0000] {processor.py:186} INFO - Started process (PID=3203) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:13:29.720+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:13:29.724+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:13:29.724+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:13:30.297+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:13:30.329+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:13:30.328+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:13:30.355+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:13:30.355+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:13:30.379+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.680 seconds
[2024-10-03T10:14:00.569+0000] {processor.py:186} INFO - Started process (PID=3252) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:14:00.571+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:14:00.574+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:14:00.574+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:14:01.141+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:14:01.191+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:14:01.191+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:14:01.226+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:14:01.226+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:14:01.268+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.708 seconds
[2024-10-03T10:14:31.790+0000] {processor.py:186} INFO - Started process (PID=3301) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:14:31.793+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:14:31.798+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:14:31.798+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:14:32.394+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:14:32.427+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:14:32.427+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:14:32.453+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:14:32.453+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:14:32.485+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.711 seconds
[2024-10-03T10:15:02.869+0000] {processor.py:186} INFO - Started process (PID=3350) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:15:02.875+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:15:02.890+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:15:02.888+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:15:03.726+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:15:03.760+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:15:03.759+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:15:03.786+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:15:03.786+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:15:03.810+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.971 seconds
[2024-10-03T10:15:33.960+0000] {processor.py:186} INFO - Started process (PID=3399) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:15:33.963+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:15:33.968+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:15:33.967+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:15:35.464+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:15:35.531+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:15:35.530+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:15:35.597+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:15:35.596+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:15:35.646+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.697 seconds
[2024-10-03T10:16:06.526+0000] {processor.py:186} INFO - Started process (PID=3458) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:16:06.527+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:16:06.531+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:16:06.531+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:16:07.161+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:16:07.198+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:16:07.198+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:16:07.229+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:16:07.229+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:16:07.275+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.759 seconds
[2024-10-03T10:16:37.724+0000] {processor.py:186} INFO - Started process (PID=3507) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:16:37.738+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:16:37.744+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:16:37.743+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:16:38.992+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:16:39.026+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:16:39.026+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:16:39.055+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:16:39.055+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:16:39.089+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.382 seconds
[2024-10-03T10:17:09.526+0000] {processor.py:186} INFO - Started process (PID=3561) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:17:09.539+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:17:09.546+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:17:09.545+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:17:10.182+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:17:10.217+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:17:10.217+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:17:10.244+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:17:10.244+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:17:10.295+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.785 seconds
[2024-10-03T10:17:40.432+0000] {processor.py:186} INFO - Started process (PID=3610) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:17:40.437+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:17:40.452+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:17:40.450+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:17:41.838+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:17:41.976+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:17:41.974+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:17:42.102+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:17:42.101+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:17:42.158+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.759 seconds
[2024-10-03T10:18:12.349+0000] {processor.py:186} INFO - Started process (PID=3659) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:18:12.366+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:18:12.378+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:18:12.376+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:18:13.100+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:18:13.140+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:18:13.139+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:18:13.173+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:18:13.172+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:18:13.203+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.887 seconds
[2024-10-03T10:18:43.287+0000] {processor.py:186} INFO - Started process (PID=3708) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:18:43.290+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:18:43.300+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:18:43.299+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:18:44.782+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:18:44.819+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:18:44.818+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:18:44.850+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:18:44.849+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:18:44.894+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.627 seconds
[2024-10-03T10:19:15.477+0000] {processor.py:186} INFO - Started process (PID=3757) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:19:15.480+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:19:15.485+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:19:15.484+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:19:16.159+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:19:16.193+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:19:16.192+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:19:16.221+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:19:16.221+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:19:16.263+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.806 seconds
[2024-10-03T10:19:46.777+0000] {processor.py:186} INFO - Started process (PID=3806) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:19:46.780+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:19:46.794+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:19:46.785+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:19:47.486+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:19:47.521+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:19:47.520+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:19:47.556+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:19:47.556+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:19:47.580+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.824 seconds
[2024-10-03T10:20:17.784+0000] {processor.py:186} INFO - Started process (PID=3855) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:20:17.798+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:20:17.804+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:20:17.803+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:20:18.512+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:20:18.560+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:20:18.559+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:20:18.591+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:20:18.591+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:20:18.627+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.877 seconds
[2024-10-03T10:20:48.766+0000] {processor.py:186} INFO - Started process (PID=3904) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:20:48.780+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:20:48.788+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:20:48.787+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:20:49.469+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:20:49.506+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:20:49.505+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:20:49.538+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:20:49.538+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:20:49.573+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.825 seconds
[2024-10-03T10:21:20.248+0000] {processor.py:186} INFO - Started process (PID=3953) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:21:20.258+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:21:20.267+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:21:20.266+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:21:21.366+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:21:21.411+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:21:21.411+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:21:21.439+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:21:21.438+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:21:21.476+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.255 seconds
[2024-10-03T10:21:51.601+0000] {processor.py:186} INFO - Started process (PID=4128) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:21:51.605+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:21:51.614+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:21:51.613+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:21:53.468+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:21:53.581+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:21:53.580+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:21:53.673+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:21:53.672+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:21:53.748+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 2.166 seconds
[2024-10-03T10:22:24.147+0000] {processor.py:186} INFO - Started process (PID=4264) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:22:24.160+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:22:24.165+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:22:24.164+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:22:24.823+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:22:24.869+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:22:24.868+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:22:24.922+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:22:24.922+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:22:24.964+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.831 seconds
[2024-10-03T10:22:55.342+0000] {processor.py:186} INFO - Started process (PID=4313) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:22:55.357+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:22:55.362+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:22:55.361+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:22:56.059+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:22:56.096+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:22:56.095+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:22:56.125+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:22:56.124+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:22:56.160+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.833 seconds
[2024-10-03T10:23:26.825+0000] {processor.py:186} INFO - Started process (PID=4365) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:23:26.827+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:23:26.831+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:23:26.830+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:23:27.432+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:23:27.502+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:23:27.501+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:23:27.539+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:23:27.539+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:23:27.570+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.759 seconds
[2024-10-03T10:23:58.053+0000] {processor.py:186} INFO - Started process (PID=4416) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:23:58.055+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:23:58.059+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:23:58.058+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:23:58.656+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:23:58.691+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:23:58.691+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:23:58.723+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:23:58.722+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:23:58.780+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.741 seconds
[2024-10-03T10:24:29.497+0000] {processor.py:186} INFO - Started process (PID=4465) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:24:29.499+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:24:29.502+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:24:29.502+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:24:30.111+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:24:30.152+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:24:30.151+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:24:30.180+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:24:30.180+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:24:30.207+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.724 seconds
[2024-10-03T10:25:00.659+0000] {processor.py:186} INFO - Started process (PID=4514) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:25:00.673+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:25:00.679+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:25:00.678+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:25:01.401+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:25:01.470+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:25:01.469+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:25:01.506+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:25:01.506+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:25:01.554+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.913 seconds
[2024-10-03T10:25:32.382+0000] {processor.py:186} INFO - Started process (PID=4563) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:25:32.387+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:25:32.400+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:25:32.399+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:25:33.218+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:25:33.259+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:25:33.259+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:25:33.294+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:25:33.293+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:25:33.336+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.975 seconds
[2024-10-03T10:26:03.926+0000] {processor.py:186} INFO - Started process (PID=4841) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:26:03.928+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:26:03.933+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:26:03.933+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:26:04.904+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:26:04.954+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:26:04.953+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:26:05.011+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:26:05.011+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:26:05.081+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.173 seconds
[2024-10-03T10:26:35.368+0000] {processor.py:186} INFO - Started process (PID=4931) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:26:35.370+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:26:35.377+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:26:35.376+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:26:36.075+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:26:36.121+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:26:36.120+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:26:36.148+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:26:36.148+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:26:36.171+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.821 seconds
[2024-10-03T10:27:06.865+0000] {processor.py:186} INFO - Started process (PID=4980) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:27:06.866+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:27:06.869+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:27:06.869+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:27:07.533+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:27:07.582+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:27:07.581+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:27:07.627+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:27:07.627+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:27:07.657+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.801 seconds
[2024-10-03T10:27:37.789+0000] {processor.py:186} INFO - Started process (PID=5029) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:27:37.803+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:27:37.809+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:27:37.808+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:27:38.503+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:27:38.539+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:27:38.538+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:27:38.573+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:27:38.573+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:27:38.621+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.851 seconds
[2024-10-03T10:28:08.761+0000] {processor.py:186} INFO - Started process (PID=5113) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:28:08.767+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:28:08.772+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:28:08.772+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:28:10.296+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:28:10.638+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:28:10.636+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:28:10.696+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:28:10.695+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:28:10.757+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 2.009 seconds
[2024-10-03T10:28:41.399+0000] {processor.py:186} INFO - Started process (PID=5211) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:28:41.401+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:28:41.406+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:28:41.405+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:28:42.141+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:28:42.198+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:28:42.197+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:28:42.239+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:28:42.239+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:28:42.278+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.897 seconds
[2024-10-03T10:29:12.599+0000] {processor.py:186} INFO - Started process (PID=5271) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:29:12.612+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:29:12.616+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:29:12.615+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:29:13.451+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:29:13.499+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:29:13.498+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:29:13.547+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:29:13.546+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:29:13.581+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.995 seconds
[2024-10-03T10:29:43.924+0000] {processor.py:186} INFO - Started process (PID=5487) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:29:43.933+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:29:43.939+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:29:43.938+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:29:45.403+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:29:45.465+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:29:45.464+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:29:45.507+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:29:45.506+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:29:45.571+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.671 seconds
[2024-10-03T10:30:16.506+0000] {processor.py:186} INFO - Started process (PID=5536) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:30:16.508+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:30:16.512+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:30:16.511+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:30:17.150+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:30:17.191+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:30:17.190+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:30:17.223+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:30:17.223+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:30:17.261+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.769 seconds
[2024-10-03T10:30:47.510+0000] {processor.py:186} INFO - Started process (PID=5585) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:30:47.523+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:30:47.527+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:30:47.526+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:30:48.200+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:30:48.241+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:30:48.241+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:30:48.270+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:30:48.269+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:30:48.294+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.800 seconds
[2024-10-03T10:31:18.669+0000] {processor.py:186} INFO - Started process (PID=5634) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:31:18.673+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:31:18.676+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:31:18.675+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:31:19.261+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:31:19.307+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:31:19.306+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:31:19.336+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:31:19.335+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:31:19.364+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.706 seconds
[2024-10-03T10:31:49.850+0000] {processor.py:186} INFO - Started process (PID=5683) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:31:49.852+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:31:49.859+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:31:49.858+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:31:50.766+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:31:50.819+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:31:50.818+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:31:50.868+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:31:50.868+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:31:50.900+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.061 seconds
[2024-10-03T10:32:21.367+0000] {processor.py:186} INFO - Started process (PID=5735) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:32:21.371+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:32:21.375+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:32:21.374+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:32:22.576+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:32:22.643+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:32:22.642+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:32:22.692+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:32:22.691+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:32:22.745+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.390 seconds
[2024-10-03T10:32:53.145+0000] {processor.py:186} INFO - Started process (PID=5791) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:32:53.147+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:32:53.151+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:32:53.150+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:32:54.185+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:32:54.256+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:32:54.255+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:32:54.299+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:32:54.299+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:32:54.330+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.200 seconds
[2024-10-03T10:33:24.544+0000] {processor.py:186} INFO - Started process (PID=5846) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:33:24.546+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:33:24.552+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:33:24.551+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:33:25.414+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:33:25.461+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:33:25.460+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:33:25.497+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:33:25.496+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:33:25.536+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.004 seconds
[2024-10-03T10:33:55.822+0000] {processor.py:186} INFO - Started process (PID=5900) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:33:55.835+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:33:55.839+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:33:55.839+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:33:56.995+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:33:57.045+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:33:57.045+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:33:57.085+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:33:57.084+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:33:57.123+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.314 seconds
[2024-10-03T10:34:27.418+0000] {processor.py:186} INFO - Started process (PID=5949) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:34:27.420+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:34:27.425+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:34:27.424+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:34:28.451+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:34:28.525+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:34:28.524+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:34:28.588+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:34:28.588+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:34:28.640+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.235 seconds
[2024-10-03T10:34:59.079+0000] {processor.py:186} INFO - Started process (PID=5998) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:34:59.091+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:34:59.096+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:34:59.096+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:35:00.254+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:35:00.314+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:35:00.313+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:35:00.363+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:35:00.362+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:35:00.406+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.340 seconds
[2024-10-03T10:35:31.253+0000] {processor.py:186} INFO - Started process (PID=6047) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:35:31.265+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:35:31.269+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:35:31.268+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:35:32.676+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:35:32.744+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:35:32.743+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:35:32.790+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:35:32.790+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:35:32.825+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.584 seconds
[2024-10-03T10:36:03.222+0000] {processor.py:186} INFO - Started process (PID=6096) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:36:03.224+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:36:03.230+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:36:03.229+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:36:04.384+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:36:04.468+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:36:04.467+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:36:04.523+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:36:04.522+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:36:04.571+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.366 seconds
[2024-10-03T10:36:35.212+0000] {processor.py:186} INFO - Started process (PID=6145) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:36:35.217+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:36:35.223+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:36:35.222+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:36:36.847+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:36:36.949+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:36:36.948+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:36:37.021+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:36:37.021+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:36:37.075+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.891 seconds
[2024-10-03T10:37:07.202+0000] {processor.py:186} INFO - Started process (PID=6194) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:37:07.216+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:37:07.222+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:37:07.221+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:37:08.630+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:37:08.700+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:37:08.699+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:37:08.753+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:37:08.753+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:37:08.811+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.637 seconds
[2024-10-03T10:37:39.325+0000] {processor.py:186} INFO - Started process (PID=6248) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:37:39.338+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:37:39.346+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:37:39.345+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:37:40.759+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:37:40.849+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:37:40.848+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:37:40.919+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:37:40.918+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:37:40.974+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.674 seconds
[2024-10-03T10:38:11.776+0000] {processor.py:186} INFO - Started process (PID=6297) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:38:11.778+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:38:11.786+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:38:11.785+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:38:13.212+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:38:13.278+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:38:13.277+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:38:13.335+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:38:13.335+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:38:13.400+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.642 seconds
[2024-10-03T10:38:44.039+0000] {processor.py:186} INFO - Started process (PID=6346) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:38:44.053+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:38:44.062+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:38:44.061+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:38:45.472+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:38:45.548+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:38:45.547+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:38:45.609+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:38:45.608+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:38:45.652+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.628 seconds
[2024-10-03T10:39:15.768+0000] {processor.py:186} INFO - Started process (PID=6395) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:39:15.781+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:39:15.789+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:39:15.788+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:39:17.394+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:39:17.466+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:39:17.465+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:39:17.527+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:39:17.526+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:39:17.580+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.831 seconds
[2024-10-03T10:39:48.036+0000] {processor.py:186} INFO - Started process (PID=6449) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:39:48.051+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:39:48.058+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:39:48.057+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:39:49.200+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:39:49.319+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:39:49.318+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:39:49.389+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:39:49.389+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:39:49.432+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.420 seconds
[2024-10-03T10:40:19.800+0000] {processor.py:186} INFO - Started process (PID=6552) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:40:19.804+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:40:19.812+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:40:19.811+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:40:21.877+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:40:22.046+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:40:22.045+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:40:22.214+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:40:22.213+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:40:22.316+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 2.539 seconds
[2024-10-03T10:40:52.935+0000] {processor.py:186} INFO - Started process (PID=6693) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:40:52.948+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:40:52.962+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:40:52.960+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:40:56.123+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:40:56.330+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:40:56.326+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:40:56.541+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:40:56.540+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:40:56.674+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 3.774 seconds
[2024-10-03T10:41:27.193+0000] {processor.py:186} INFO - Started process (PID=6797) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:41:27.196+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:41:27.212+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:41:27.211+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:41:31.798+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:41:32.087+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:41:32.081+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:41:32.458+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:41:32.458+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:41:32.604+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.474 seconds
[2024-10-03T10:42:02.782+0000] {processor.py:186} INFO - Started process (PID=6928) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:42:02.785+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:42:02.794+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:42:02.793+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:42:04.493+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:42:04.604+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:42:04.602+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:42:04.677+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:42:04.676+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:42:04.736+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.971 seconds
[2024-10-03T10:42:35.213+0000] {processor.py:186} INFO - Started process (PID=6977) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:42:35.227+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:42:35.233+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:42:35.232+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:42:36.401+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:42:36.486+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:42:36.485+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:42:36.559+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:42:36.559+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:42:36.604+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.411 seconds
[2024-10-03T10:43:07.187+0000] {processor.py:186} INFO - Started process (PID=7026) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:43:07.201+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:43:07.207+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:43:07.206+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:43:08.632+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:43:08.728+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:43:08.728+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:43:08.789+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:43:08.788+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:43:08.839+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.667 seconds
[2024-10-03T10:43:39.321+0000] {processor.py:186} INFO - Started process (PID=7078) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:43:39.324+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:43:39.333+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:43:39.332+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:43:40.585+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:43:40.710+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:43:40.709+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:43:40.798+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:43:40.798+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:43:40.859+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.553 seconds
[2024-10-03T10:44:11.136+0000] {processor.py:186} INFO - Started process (PID=7188) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:44:11.140+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:44:11.165+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:44:11.157+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:44:13.332+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:44:13.455+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:44:13.454+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:44:13.573+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:44:13.571+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:44:13.672+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 2.577 seconds
[2024-10-03T10:44:44.752+0000] {processor.py:186} INFO - Started process (PID=7337) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:44:44.762+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:44:44.780+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:44:44.776+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:44:48.052+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:44:48.248+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:44:48.247+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:44:48.384+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:44:48.384+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:44:48.466+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 3.763 seconds
[2024-10-03T10:45:18.799+0000] {processor.py:186} INFO - Started process (PID=7458) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:45:18.807+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:45:18.818+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:45:18.816+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:45:25.628+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:45:25.896+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:45:25.895+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:45:26.350+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:45:26.348+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:45:26.551+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 7.840 seconds
[2024-10-03T10:45:57.078+0000] {processor.py:186} INFO - Started process (PID=7573) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:45:57.091+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:45:57.096+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:45:57.095+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:45:58.852+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:45:58.957+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:45:58.956+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:45:59.065+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:45:59.064+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:45:59.143+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 2.083 seconds
[2024-10-03T10:46:29.784+0000] {processor.py:186} INFO - Started process (PID=7622) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:46:29.787+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:46:29.793+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:46:29.792+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:46:31.481+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:46:31.597+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:46:31.596+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:46:31.667+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:46:31.666+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:46:34.021+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.252 seconds
[2024-10-03T10:47:04.439+0000] {processor.py:186} INFO - Started process (PID=7675) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:47:04.442+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:47:04.449+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:47:04.448+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:47:05.907+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:47:05.990+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:47:05.989+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:47:06.057+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:47:06.057+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:47:06.102+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.679 seconds
[2024-10-03T10:47:36.260+0000] {processor.py:186} INFO - Started process (PID=7729) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:47:36.267+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:47:36.274+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:47:36.273+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:47:37.583+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:47:37.673+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:47:37.672+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:47:37.739+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:47:37.738+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:47:37.789+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.551 seconds
[2024-10-03T10:48:08.616+0000] {processor.py:186} INFO - Started process (PID=7784) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:48:08.629+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:48:08.634+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:48:08.633+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:48:10.151+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:48:10.231+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:48:10.230+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:48:10.289+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:48:10.288+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:48:10.336+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.736 seconds
[2024-10-03T10:48:40.875+0000] {processor.py:186} INFO - Started process (PID=7835) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:48:40.877+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:48:40.883+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:48:40.882+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:48:42.219+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:48:42.319+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:48:42.318+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:48:42.400+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:48:42.400+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:48:42.855+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.997 seconds
[2024-10-03T10:49:13.576+0000] {processor.py:186} INFO - Started process (PID=7884) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:49:13.589+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:49:13.594+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:49:13.593+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:49:15.089+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:49:15.177+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:49:15.176+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:49:15.235+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:49:15.235+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:49:15.280+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.720 seconds
[2024-10-03T10:49:45.656+0000] {processor.py:186} INFO - Started process (PID=7933) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:49:45.669+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:49:45.674+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:49:45.673+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:49:46.958+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:49:47.027+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:49:47.026+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:49:47.079+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:49:47.078+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:49:47.128+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.487 seconds
[2024-10-03T10:50:17.865+0000] {processor.py:186} INFO - Started process (PID=7987) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:50:17.878+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:50:17.883+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:50:17.882+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:50:19.131+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:50:19.194+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:50:19.193+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:50:19.249+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:50:19.249+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:50:19.297+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.445 seconds
[2024-10-03T10:50:49.425+0000] {processor.py:186} INFO - Started process (PID=8036) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:50:49.427+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:50:49.439+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:50:49.437+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:50:51.321+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:50:51.416+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:50:51.414+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:50:51.488+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:50:51.488+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:50:51.893+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 2.503 seconds
[2024-10-03T10:51:21.988+0000] {processor.py:186} INFO - Started process (PID=8090) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:51:22.002+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:51:22.008+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:51:22.007+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:51:23.207+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:51:23.276+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:51:23.275+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:51:23.335+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:51:23.334+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:51:23.381+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.409 seconds
[2024-10-03T10:51:53.817+0000] {processor.py:186} INFO - Started process (PID=8147) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:51:53.820+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:51:53.827+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:51:53.826+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:51:55.171+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:51:55.243+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:51:55.242+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:51:55.333+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:51:55.332+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:51:55.371+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.571 seconds
[2024-10-03T10:52:25.621+0000] {processor.py:186} INFO - Started process (PID=8198) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:52:25.635+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:52:25.643+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:52:25.642+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:52:27.329+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:52:27.465+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:52:27.464+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:52:27.539+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:52:27.538+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:52:27.594+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.996 seconds
[2024-10-03T10:52:58.124+0000] {processor.py:186} INFO - Started process (PID=8247) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:52:58.125+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:52:58.131+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:52:58.129+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:52:59.372+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:52:59.442+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:52:59.441+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:52:59.496+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:52:59.495+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:52:59.788+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.685 seconds
[2024-10-03T10:53:29.948+0000] {processor.py:186} INFO - Started process (PID=8296) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:53:29.973+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:53:30.027+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:53:30.023+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:53:33.508+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:53:33.598+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:53:33.593+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:53:35.487+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:53:35.487+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:53:35.562+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.690 seconds
[2024-10-03T10:56:45.240+0000] {processor.py:186} INFO - Started process (PID=193) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:56:45.242+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:56:45.248+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:56:45.247+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:56:56.065+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:56:56.185+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:56:56.183+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:56:56.267+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:56:56.266+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:56:56.315+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 11.091 seconds
[2024-10-03T10:57:26.621+0000] {processor.py:186} INFO - Started process (PID=258) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:57:26.628+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:57:26.635+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:57:26.635+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:57:28.472+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:57:28.567+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:57:28.566+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:57:28.655+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:57:28.654+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:57:28.701+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 2.104 seconds
[2024-10-03T10:57:59.895+0000] {processor.py:186} INFO - Started process (PID=321) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:57:59.897+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:57:59.912+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:57:59.911+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:58:03.737+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:58:03.888+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:58:03.886+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:58:04.075+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:58:04.074+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:58:04.126+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.285 seconds
[2024-10-03T10:58:34.477+0000] {processor.py:186} INFO - Started process (PID=377) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:58:34.481+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:58:34.488+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:58:34.487+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:58:36.389+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:58:36.533+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:58:36.532+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:58:36.611+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:58:36.610+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:58:36.671+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 2.212 seconds
[2024-10-03T10:59:07.014+0000] {processor.py:186} INFO - Started process (PID=426) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:59:07.016+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:59:07.029+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:59:07.025+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:59:08.408+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:59:08.479+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:59:08.478+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:59:08.536+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:59:08.535+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:59:08.586+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.595 seconds
[2024-10-03T10:59:38.683+0000] {processor.py:186} INFO - Started process (PID=475) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:59:38.697+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T10:59:38.702+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:59:38.701+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:59:40.363+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T10:59:40.435+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:59:40.434+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T10:59:40.491+0000] {logging_mixin.py:190} INFO - [2024-10-03T10:59:40.491+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T10:59:40.545+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.877 seconds
[2024-10-03T11:12:42.409+0000] {processor.py:186} INFO - Started process (PID=193) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:12:42.413+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T11:12:42.422+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:12:42.421+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:12:48.284+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:12:48.327+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:12:48.327+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T11:12:48.369+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:12:48.368+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T11:12:48.397+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.009 seconds
[2024-10-03T11:13:18.577+0000] {processor.py:186} INFO - Started process (PID=263) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:13:18.579+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T11:13:18.582+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:13:18.582+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:13:19.411+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:13:19.452+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:13:19.452+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T11:13:19.487+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:13:19.486+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T11:13:19.512+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.944 seconds
[2024-10-03T11:13:50.026+0000] {processor.py:186} INFO - Started process (PID=312) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:13:50.038+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T11:13:50.040+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:13:50.040+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:13:50.573+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:13:50.603+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:13:50.602+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T11:13:50.628+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:13:50.628+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T11:13:50.649+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.631 seconds
[2024-10-03T11:14:21.452+0000] {processor.py:186} INFO - Started process (PID=361) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:14:21.453+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T11:14:21.456+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:14:21.456+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:14:22.039+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:14:22.077+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:14:22.076+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T11:14:22.106+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:14:22.106+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T11:14:22.128+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.684 seconds
[2024-10-03T11:14:52.593+0000] {processor.py:186} INFO - Started process (PID=416) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:14:52.595+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T11:14:52.597+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:14:52.597+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:14:53.104+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:14:53.134+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:14:53.134+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T11:14:53.158+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:14:53.158+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T11:14:53.178+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.592 seconds
[2024-10-03T11:15:23.278+0000] {processor.py:186} INFO - Started process (PID=478) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:15:23.279+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T11:15:23.282+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:15:23.281+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:15:23.758+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:15:23.789+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:15:23.788+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T11:15:23.813+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:15:23.813+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T11:15:23.844+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.573 seconds
[2024-10-03T11:15:53.890+0000] {processor.py:186} INFO - Started process (PID=527) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:15:53.891+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T11:15:53.895+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:15:53.894+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:15:54.419+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:15:54.448+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:15:54.447+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T11:15:54.473+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:15:54.472+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T11:15:54.502+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.618 seconds
[2024-10-03T11:16:24.565+0000] {processor.py:186} INFO - Started process (PID=576) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:16:24.567+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T11:16:24.569+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:16:24.569+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:16:25.082+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:16:25.115+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:16:25.114+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T11:16:25.139+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:16:25.139+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T11:16:25.168+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.610 seconds
[2024-10-03T11:17:47.326+0000] {processor.py:186} INFO - Started process (PID=193) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:17:47.328+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T11:17:47.331+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:17:47.331+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:17:51.839+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:17:51.890+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:17:51.889+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T11:17:51.923+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:17:51.923+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T11:17:51.948+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.632 seconds
[2024-10-03T11:18:22.098+0000] {processor.py:186} INFO - Started process (PID=274) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:18:22.101+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T11:18:22.105+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:18:22.104+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:18:23.231+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:18:23.518+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:18:23.517+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T11:18:23.576+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:18:23.575+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T11:18:23.616+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.529 seconds
[2024-10-03T11:18:54.449+0000] {processor.py:186} INFO - Started process (PID=467) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:18:54.451+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T11:18:54.457+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:18:54.456+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:18:56.526+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:18:56.661+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:18:56.660+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T11:18:56.738+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:18:56.737+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T11:18:56.825+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 2.392 seconds
[2024-10-03T11:19:27.121+0000] {processor.py:186} INFO - Started process (PID=617) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:19:27.133+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T11:19:27.136+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:19:27.135+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:19:27.606+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:19:27.636+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:19:27.635+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T11:19:27.658+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:19:27.658+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T11:19:27.676+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.561 seconds
[2024-10-03T11:19:57.743+0000] {processor.py:186} INFO - Started process (PID=666) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:19:57.745+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T11:19:57.747+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:19:57.747+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:19:58.238+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:19:58.265+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:19:58.265+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T11:19:58.287+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:19:58.286+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T11:19:58.315+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.579 seconds
[2024-10-03T11:20:29.140+0000] {processor.py:186} INFO - Started process (PID=715) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:20:29.141+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T11:20:29.144+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:20:29.143+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:20:29.705+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:20:29.742+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:20:29.741+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T11:20:29.773+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:20:29.773+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T11:20:29.798+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.665 seconds
[2024-10-03T11:20:59.996+0000] {processor.py:186} INFO - Started process (PID=775) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:20:59.998+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T11:21:00.000+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:21:00.000+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:21:00.486+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:21:00.514+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:21:00.513+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T11:21:00.536+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:21:00.536+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T11:21:00.565+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.575 seconds
[2024-10-03T11:21:30.734+0000] {processor.py:186} INFO - Started process (PID=818) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:21:30.735+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T11:21:30.738+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:21:30.738+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:21:31.228+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:21:31.257+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:21:31.256+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T11:21:31.278+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:21:31.278+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T11:21:31.306+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.580 seconds
[2024-10-03T11:23:17.816+0000] {processor.py:186} INFO - Started process (PID=194) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:23:17.817+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T11:23:17.821+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:23:17.820+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:23:21.612+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:23:21.652+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:23:21.652+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T11:23:21.683+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:23:21.683+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T11:23:21.719+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 3.914 seconds
[2024-10-03T11:23:52.003+0000] {processor.py:186} INFO - Started process (PID=264) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:23:52.005+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T11:23:52.007+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:23:52.007+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:23:52.519+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:23:52.551+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:23:52.551+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T11:23:52.575+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:23:52.575+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T11:23:52.594+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.598 seconds
[2024-10-03T11:24:23.311+0000] {processor.py:186} INFO - Started process (PID=448) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:24:23.313+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T11:24:23.319+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:24:23.318+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:24:24.860+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:24:25.004+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:24:25.003+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T11:24:25.085+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:24:25.085+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T11:24:25.132+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 1.838 seconds
[2024-10-03T11:24:55.309+0000] {processor.py:186} INFO - Started process (PID=597) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:24:55.315+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T11:24:55.318+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:24:55.318+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:24:56.109+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:24:56.169+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:24:56.168+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T11:24:56.208+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:24:56.208+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T11:24:56.254+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.954 seconds
[2024-10-03T11:25:26.305+0000] {processor.py:186} INFO - Started process (PID=654) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:25:26.306+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T11:25:26.309+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:25:26.308+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:25:26.789+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:25:26.818+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:25:26.818+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T11:25:26.841+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:25:26.840+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T11:25:26.869+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.570 seconds
[2024-10-03T11:25:56.904+0000] {processor.py:186} INFO - Started process (PID=703) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:25:56.906+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T11:25:56.909+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:25:56.908+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:25:57.642+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:25:57.673+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:25:57.673+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T11:25:57.700+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:25:57.700+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T11:25:57.721+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.823 seconds
[2024-10-03T11:26:27.784+0000] {processor.py:186} INFO - Started process (PID=754) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:26:27.795+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T11:26:27.798+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:26:27.798+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:26:28.439+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:26:28.470+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:26:28.470+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T11:26:28.494+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:26:28.494+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T11:26:28.526+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.750 seconds
[2024-10-03T11:26:58.918+0000] {processor.py:186} INFO - Started process (PID=807) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:26:58.921+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T11:26:58.924+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:26:58.924+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:26:59.415+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:26:59.444+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:26:59.444+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T11:26:59.470+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:26:59.470+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T11:26:59.491+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.580 seconds
[2024-10-03T11:27:29.938+0000] {processor.py:186} INFO - Started process (PID=863) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:27:29.939+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-03T11:27:29.941+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:27:29.941+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:27:30.407+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-03T11:27:30.436+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:27:30.436+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-03T11:27:30.458+0000] {logging_mixin.py:190} INFO - [2024-10-03T11:27:30.458+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-03 00:00:00+00:00, run_after=2024-10-04 00:00:00+00:00
[2024-10-03T11:27:30.479+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.549 seconds

[2024-10-02T16:38:43.034+0000] {processor.py:186} INFO - Started process (PID=186) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:38:43.037+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T16:38:43.045+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:38:43.044+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:38:45.210+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:38:45.218+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:38:45.217+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T16:38:45.287+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:38:45.287+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T16:38:45.356+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 2.341 seconds
[2024-10-02T16:39:42.921+0000] {processor.py:186} INFO - Started process (PID=185) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:39:42.924+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T16:39:42.934+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:39:42.931+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:39:50.186+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:39:50.986+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:39:50.985+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T16:39:51.098+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:39:51.087+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T16:39:51.169+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 8.262 seconds
[2024-10-02T16:40:22.011+0000] {processor.py:186} INFO - Started process (PID=269) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:40:22.025+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T16:40:22.030+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:40:22.029+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:40:23.824+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:40:24.525+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:40:24.524+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T16:40:24.603+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:40:24.602+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T16:40:24.691+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 2.700 seconds
[2024-10-02T16:40:54.975+0000] {processor.py:186} INFO - Started process (PID=348) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:40:54.978+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T16:40:54.984+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:40:54.983+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:40:56.634+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:40:57.251+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:40:57.250+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T16:40:57.323+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:40:57.322+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T16:40:57.471+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 2.515 seconds
[2024-10-02T16:41:27.637+0000] {processor.py:186} INFO - Started process (PID=418) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:41:27.651+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T16:41:27.656+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:41:27.655+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:41:29.268+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:41:29.463+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:41:29.462+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T16:41:29.578+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:41:29.577+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T16:41:29.631+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 2.026 seconds
[2024-10-02T16:42:00.525+0000] {processor.py:186} INFO - Started process (PID=491) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:42:00.555+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T16:42:00.576+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:42:00.574+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:42:02.724+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:42:03.182+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:42:03.181+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T16:42:03.240+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:42:03.239+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T16:42:03.327+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 2.850 seconds
[2024-10-02T16:42:33.417+0000] {processor.py:186} INFO - Started process (PID=565) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:42:33.420+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T16:42:33.426+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:42:33.425+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:42:35.050+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:42:35.593+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:42:35.591+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T16:42:35.670+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:42:35.670+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T16:42:35.758+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 2.359 seconds
[2024-10-02T16:43:06.720+0000] {processor.py:186} INFO - Started process (PID=641) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:43:06.733+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T16:43:06.739+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:43:06.738+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:43:08.427+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:43:08.845+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:43:08.844+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T16:43:08.927+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:43:08.926+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T16:43:08.990+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 2.285 seconds
[2024-10-02T16:43:39.759+0000] {processor.py:186} INFO - Started process (PID=719) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:43:39.775+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T16:43:39.781+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:43:39.780+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:43:41.776+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:43:42.318+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:43:42.316+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T16:43:42.389+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:43:42.388+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T16:43:42.540+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 2.803 seconds
[2024-10-02T16:44:16.321+0000] {processor.py:186} INFO - Started process (PID=794) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:44:16.324+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T16:44:16.339+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:44:16.338+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:44:19.428+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:44:19.706+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:44:19.704+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T16:44:19.847+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:44:19.847+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T16:44:19.934+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 3.647 seconds
[2024-10-02T16:44:50.422+0000] {processor.py:186} INFO - Started process (PID=869) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:44:50.425+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T16:44:50.434+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:44:50.433+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:44:52.440+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:44:53.430+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:44:53.420+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T16:44:53.705+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:44:53.705+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T16:44:53.872+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 3.468 seconds
[2024-10-02T16:45:24.156+0000] {processor.py:186} INFO - Started process (PID=940) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:45:24.159+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T16:45:24.176+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:45:24.175+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:45:26.729+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:45:27.484+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:45:27.483+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T16:45:27.556+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:45:27.556+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T16:45:27.627+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 3.504 seconds
[2024-10-02T16:45:57.872+0000] {processor.py:186} INFO - Started process (PID=1009) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:45:57.875+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T16:45:57.881+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:45:57.880+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:45:59.533+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:46:00.093+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:46:00.092+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T16:46:00.208+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:46:00.207+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T16:46:00.288+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 2.431 seconds
[2024-10-02T16:46:30.602+0000] {processor.py:186} INFO - Started process (PID=1078) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:46:30.607+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T16:46:30.613+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:46:30.611+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:46:33.128+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:46:35.958+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:46:35.957+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T16:46:36.088+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:46:36.087+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T16:46:36.192+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.625 seconds
[2024-10-02T16:47:06.516+0000] {processor.py:186} INFO - Started process (PID=1153) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:47:06.519+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T16:47:06.533+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:47:06.532+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:47:09.712+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:47:10.008+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:47:10.007+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T16:47:10.243+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:47:10.242+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T16:47:10.343+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 3.848 seconds
[2024-10-02T16:47:40.814+0000] {processor.py:186} INFO - Started process (PID=1222) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:47:40.818+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T16:47:40.825+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:47:40.824+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:47:43.386+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:47:43.625+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:47:43.623+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T16:47:43.718+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:47:43.717+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T16:47:44.478+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 3.689 seconds
[2024-10-02T16:48:15.374+0000] {processor.py:186} INFO - Started process (PID=1291) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:48:15.388+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T16:48:15.396+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:48:15.394+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:48:17.933+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:48:18.238+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:48:18.237+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T16:48:18.794+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:48:18.793+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T16:48:18.858+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 3.510 seconds
[2024-10-02T16:48:49.228+0000] {processor.py:186} INFO - Started process (PID=1369) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:48:49.241+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T16:48:49.249+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:48:49.248+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:48:51.848+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:48:52.545+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:48:52.544+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T16:48:52.629+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:48:52.628+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T16:48:52.693+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 3.489 seconds
[2024-10-02T16:49:22.902+0000] {processor.py:186} INFO - Started process (PID=1448) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:49:22.906+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T16:49:22.919+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:49:22.918+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:49:25.244+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:49:25.474+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:49:25.473+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T16:49:25.565+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:49:25.564+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T16:49:25.637+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 2.763 seconds
[2024-10-02T16:49:55.819+0000] {processor.py:186} INFO - Started process (PID=1517) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:49:55.834+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T16:49:55.842+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:49:55.839+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:49:58.318+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:49:58.560+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:49:58.559+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T16:49:58.657+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:49:58.656+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T16:49:59.187+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 3.392 seconds
[2024-10-02T16:50:29.924+0000] {processor.py:186} INFO - Started process (PID=1588) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:50:29.937+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T16:50:29.944+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:50:29.943+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:50:32.163+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:50:32.378+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:50:32.377+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T16:50:33.051+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:50:33.050+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T16:50:33.108+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 3.205 seconds
[2024-10-02T16:51:03.827+0000] {processor.py:186} INFO - Started process (PID=1661) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:51:03.830+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T16:51:03.838+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:51:03.837+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:51:05.824+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:51:06.429+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:51:06.428+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T16:51:06.504+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:51:06.503+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T16:51:06.560+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 2.750 seconds
[2024-10-02T16:51:37.397+0000] {processor.py:186} INFO - Started process (PID=1730) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:51:37.401+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T16:51:37.416+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:51:37.415+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:51:40.498+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:51:40.724+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:51:40.723+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T16:51:40.836+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:51:40.835+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T16:51:41.395+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.023 seconds
[2024-10-02T16:52:11.870+0000] {processor.py:186} INFO - Started process (PID=1805) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:52:11.874+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T16:52:11.887+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:52:11.885+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:52:14.292+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:52:14.576+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:52:14.575+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T16:52:15.204+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:52:15.202+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T16:52:15.270+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 3.432 seconds
[2024-10-02T16:52:45.468+0000] {processor.py:186} INFO - Started process (PID=1874) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:52:45.481+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T16:52:45.488+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:52:45.487+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:52:47.988+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:52:48.734+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:52:48.733+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T16:52:48.832+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:52:48.831+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T16:52:48.892+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 3.459 seconds
[2024-10-02T16:53:19.794+0000] {processor.py:186} INFO - Started process (PID=1949) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:53:19.801+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T16:53:19.811+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:53:19.810+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:53:22.744+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:53:23.006+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:53:23.005+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T16:53:23.088+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:53:23.087+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T16:53:23.162+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 3.397 seconds
[2024-10-02T16:53:53.389+0000] {processor.py:186} INFO - Started process (PID=2020) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:53:53.391+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T16:53:53.398+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:53:53.397+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:53:55.925+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:53:56.171+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:53:56.170+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T16:53:56.277+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:53:56.276+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T16:53:56.876+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 3.511 seconds
[2024-10-02T16:54:27.090+0000] {processor.py:186} INFO - Started process (PID=2089) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:54:27.099+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T16:54:27.120+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:54:27.119+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:54:30.685+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:54:30.975+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:54:30.974+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T16:54:31.698+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:54:31.698+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T16:54:31.789+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.743 seconds
[2024-10-02T16:55:02.047+0000] {processor.py:186} INFO - Started process (PID=2167) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:55:02.052+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T16:55:02.060+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:55:02.059+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:55:03.907+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:55:04.607+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:55:04.606+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T16:55:04.692+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:55:04.692+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T16:55:04.746+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 2.721 seconds
[2024-10-02T16:55:35.185+0000] {processor.py:186} INFO - Started process (PID=2243) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:55:35.188+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T16:55:35.196+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:55:35.195+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:55:37.498+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:55:37.676+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:55:37.674+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T16:55:37.740+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:55:37.740+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T16:55:37.811+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 2.661 seconds
[2024-10-02T16:56:08.335+0000] {processor.py:186} INFO - Started process (PID=2472) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:56:08.339+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T16:56:08.348+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:56:08.347+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:56:22.499+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:56:23.061+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:56:23.058+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T16:56:23.126+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:56:23.125+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T16:56:23.191+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 14.876 seconds
[2024-10-02T16:56:53.799+0000] {processor.py:186} INFO - Started process (PID=2838) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:56:53.809+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T16:56:53.817+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:56:53.816+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:57:10.835+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:57:12.315+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:57:12.313+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T16:57:12.441+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:57:12.440+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T16:57:12.596+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 18.819 seconds
[2024-10-02T16:57:43.197+0000] {processor.py:186} INFO - Started process (PID=3237) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:57:43.200+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T16:57:43.214+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:57:43.213+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:58:01.164+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:58:01.681+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:58:01.680+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T16:58:01.745+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:58:01.744+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T16:58:01.807+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 18.634 seconds
[2024-10-02T16:58:32.083+0000] {processor.py:186} INFO - Started process (PID=3620) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:58:32.096+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T16:58:32.106+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:58:32.103+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:58:51.969+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:58:53.165+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:58:53.163+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T16:58:53.320+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:58:53.316+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T16:58:53.454+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 21.392 seconds
[2024-10-02T16:59:24.161+0000] {processor.py:186} INFO - Started process (PID=4020) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:59:24.164+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T16:59:24.171+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:59:24.170+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:59:39.458+0000] {logging_mixin.py:190} INFO - [2024-10-02T16:59:39.438+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 268, in warehouse
    step_1() >> step_2() >> step_3()
    ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 91, in step_1
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 24, in extract_transform
    application=f'{BASE_PATH}/etl_pipeline/tasks/warehouse/components/extract_transform.py',
                   ^^^^^^^^^
NameError: name 'BASE_PATH' is not defined
[2024-10-02T16:59:39.469+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T16:59:39.506+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 15.366 seconds
[2024-10-02T17:00:09.957+0000] {processor.py:186} INFO - Started process (PID=4403) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:00:09.970+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:00:09.976+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:00:09.975+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:00:23.945+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:00:24.687+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:00:24.677+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:00:24.806+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:00:24.796+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:00:24.892+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 14.952 seconds
[2024-10-02T17:00:55.254+0000] {processor.py:186} INFO - Started process (PID=4647) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:00:55.257+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:00:55.269+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:00:55.268+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:01:25.302+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:01:25.287+0000] {timeout.py:68} ERROR - Process timed out, PID: 4647
[2024-10-02T17:01:25.382+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:01:25.306+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 5, in <module>
    from etl_pipeline.tasks.warehouse.main import warehouse
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 4, in <module>
    from etl_pipeline.tasks.warehouse.components.extract_transform import ExtractTransform
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/components/extract_transform.py", line 5, in <module>
    from etl_pipeline.tasks.warehouse.components.validations import Validation, ValidationType
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/components/validations.py", line 11, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 104, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/etl_pipeline/run.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.10.2/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.10.2/best-practices.html#reducing-dag-complexity, PID: 4647
[2024-10-02T17:01:25.386+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:01:25.763+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 30.543 seconds
[2024-10-02T17:02:28.718+0000] {processor.py:186} INFO - Started process (PID=5918) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:02:28.790+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:02:28.805+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:02:28.804+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:02:59.051+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:02:58.913+0000] {timeout.py:68} ERROR - Process timed out, PID: 5918
[2024-10-02T17:03:00.283+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:02:59.054+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 5, in <module>
    from etl_pipeline.tasks.warehouse.main import warehouse
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 4, in <module>
    from etl_pipeline.tasks.warehouse.components.extract_transform import ExtractTransform
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/components/extract_transform.py", line 4, in <module>
    from etl_pipeline.tasks.warehouse.components.extract import _extract
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/components/extract.py", line 4, in <module>
    from pyspark.sql import SparkSession
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/__init__.py", line 148, in <module>
    from pyspark.sql import SQLContext, HiveContext, Row  # noqa: F401
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/__init__.py", line 42, in <module>
    from pyspark.sql.types import Row
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/types.py", line 1246, in <module>
    _INTERVAL_YEARMONTH = re.compile(r"interval (year|month)( to (year|month))?")
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/re/__init__.py", line 226, in compile
    def compile(pattern, flags=0):
    
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/etl_pipeline/run.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.10.2/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.10.2/best-practices.html#reducing-dag-complexity, PID: 5918
[2024-10-02T17:03:00.323+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:03:00.769+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 32.563 seconds
[2024-10-02T17:03:31.643+0000] {processor.py:186} INFO - Started process (PID=6574) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:03:31.645+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:03:31.650+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:03:31.649+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:03:47.852+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:03:48.481+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:03:48.479+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:03:48.559+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:03:48.558+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:03:48.631+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 17.012 seconds
[2024-10-02T17:04:18.989+0000] {processor.py:186} INFO - Started process (PID=6816) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:04:18.992+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:04:18.996+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:04:18.995+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:04:42.495+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:04:43.383+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:04:43.381+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:04:43.507+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:04:43.506+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:04:43.626+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 24.655 seconds
[2024-10-02T17:05:13.867+0000] {processor.py:186} INFO - Started process (PID=7200) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:05:13.870+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:05:13.874+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:05:13.873+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:05:29.242+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:05:29.413+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:05:29.411+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:05:29.480+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:05:29.479+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:05:29.523+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 15.674 seconds
[2024-10-02T17:06:00.166+0000] {processor.py:186} INFO - Started process (PID=7593) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:06:00.170+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:06:00.176+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:06:00.175+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:06:17.865+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:06:18.703+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:06:18.699+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:06:18.869+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:06:18.866+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:06:18.991+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 18.851 seconds
[2024-10-02T17:06:58.788+0000] {processor.py:186} INFO - Started process (PID=8525) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:06:58.853+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:06:58.899+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:06:58.863+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:07:28.987+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:07:28.962+0000] {timeout.py:68} ERROR - Process timed out, PID: 8525
[2024-10-02T17:07:29.087+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:07:29.022+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 5, in <module>
    from etl_pipeline.tasks.warehouse.main import warehouse
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 4, in <module>
    from etl_pipeline.tasks.warehouse.components.extract_transform import ExtractTransform
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/components/extract_transform.py", line 5, in <module>
    from etl_pipeline.tasks.warehouse.components.validations import Validation, ValidationType
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/components/validations.py", line 11, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 104, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/etl_pipeline/run.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.10.2/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.10.2/best-practices.html#reducing-dag-complexity, PID: 8525
[2024-10-02T17:07:29.128+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:07:29.481+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 30.884 seconds
[2024-10-02T17:08:17.680+0000] {processor.py:186} INFO - Started process (PID=9489) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:08:17.684+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:08:17.691+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:08:17.689+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:08:36.133+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:08:36.387+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:08:36.386+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:08:36.417+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:08:36.416+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:08:36.453+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 18.824 seconds
[2024-10-02T17:09:07.149+0000] {processor.py:186} INFO - Started process (PID=9994) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:09:07.150+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:09:07.152+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:09:07.151+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:09:16.209+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:09:16.712+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:09:16.710+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:09:16.774+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:09:16.774+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:09:16.875+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 9.735 seconds
[2024-10-02T17:09:47.049+0000] {processor.py:186} INFO - Started process (PID=10374) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:09:47.052+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:09:47.056+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:09:47.055+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:09:57.184+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:09:57.757+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:09:57.756+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:09:57.820+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:09:57.819+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:09:57.887+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 10.866 seconds
[2024-10-02T17:10:28.058+0000] {processor.py:186} INFO - Started process (PID=10773) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:10:28.060+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:10:28.062+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:10:28.061+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:10:36.617+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:10:36.861+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:10:36.860+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:10:36.893+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:10:36.893+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:10:36.934+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 8.885 seconds
[2024-10-02T17:11:10.294+0000] {processor.py:186} INFO - Started process (PID=11528) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:11:10.310+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:11:10.315+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:11:10.314+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:11:40.327+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:11:40.322+0000] {timeout.py:68} ERROR - Process timed out, PID: 11528
[2024-10-02T17:11:40.369+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:11:40.335+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 5, in <module>
    from etl_pipeline.tasks.warehouse.main import warehouse
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 4, in <module>
    from etl_pipeline.tasks.warehouse.components.extract_transform import ExtractTransform
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/components/extract_transform.py", line 5, in <module>
    from etl_pipeline.tasks.warehouse.components.validations import Validation, ValidationType
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/components/validations.py", line 11, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 104, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/etl_pipeline/run.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.10.2/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.10.2/best-practices.html#reducing-dag-complexity, PID: 11528
[2024-10-02T17:11:40.382+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:11:40.605+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 30.356 seconds
[2024-10-02T17:11:48.010+0000] {processor.py:186} INFO - Started process (PID=13125) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:11:48.026+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:11:48.043+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:11:48.029+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:12:04.246+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:12:04.271+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:12:04.270+0000] {taskinstance.py:3312} ERROR - Executor LocalExecutor(parallelism=32) reported that the task instance <TaskInstance: etl_pipeline.staging.dellstore_db.extract.orderlines manual__2024-10-02T17:10:54.658014+00:00 [queued]> finished with state failed, but the task instance's state attribute is queued. Learn more: https://airflow.apache.org/docs/apache-airflow/stable/troubleshooting.html#task-state-changed-externally
[2024-10-02T17:12:04.334+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:12:04.334+0000] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=etl_pipeline, task_id=staging.dellstore_db.extract.orderlines, run_id=manual__2024-10-02T17:10:54.658014+00:00, execution_date=20241002T171054, start_date=, end_date=20241002T171204
[2024-10-02T17:12:04.335+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:12:04.335+0000] {taskinstance.py:1563} INFO - Executing callback at index 0: slack_notifier
[2024-10-02T17:12:04.341+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:12:04.336+0000] {taskinstance.py:1567} ERROR - Error in callback at index 0: slack_notifier
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 1565, in _run_finished_callback
    callback(context)
  File "/opt/airflow/dags/helper/callbacks/slack_notifier.py", line 12, in slack_notifier
    traceback = "".join(tb.format_exception(type(exception), exception, exception.__traceback__)) if context.get('exception') else 'No traceback'
                                                                        ^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute '__traceback__'
[2024-10-02T17:12:04.460+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:12:04.460+0000] {processor.py:876} INFO - Executed callback for <TaskInstance: etl_pipeline.staging.dellstore_db.extract.orderlines manual__2024-10-02T17:10:54.658014+00:00 [failed]> in state failed
[2024-10-02T17:12:04.466+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:12:04.466+0000] {taskinstance.py:3312} ERROR - Executor LocalExecutor(parallelism=32) reported that the task instance <TaskInstance: etl_pipeline.staging.dellstore_db.extract.cust_hist manual__2024-10-02T17:10:54.658014+00:00 [queued]> finished with state failed, but the task instance's state attribute is queued. Learn more: https://airflow.apache.org/docs/apache-airflow/stable/troubleshooting.html#task-state-changed-externally
[2024-10-02T17:12:04.491+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:12:04.490+0000] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=etl_pipeline, task_id=staging.dellstore_db.extract.cust_hist, run_id=manual__2024-10-02T17:10:54.658014+00:00, execution_date=20241002T171054, start_date=, end_date=20241002T171204
[2024-10-02T17:12:04.491+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:12:04.491+0000] {taskinstance.py:1563} INFO - Executing callback at index 0: slack_notifier
[2024-10-02T17:12:04.494+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:12:04.492+0000] {taskinstance.py:1567} ERROR - Error in callback at index 0: slack_notifier
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 1565, in _run_finished_callback
    callback(context)
  File "/opt/airflow/dags/helper/callbacks/slack_notifier.py", line 12, in slack_notifier
    traceback = "".join(tb.format_exception(type(exception), exception, exception.__traceback__)) if context.get('exception') else 'No traceback'
                                                                        ^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute '__traceback__'
[2024-10-02T17:12:04.528+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:12:04.528+0000] {processor.py:876} INFO - Executed callback for <TaskInstance: etl_pipeline.staging.dellstore_db.extract.cust_hist manual__2024-10-02T17:10:54.658014+00:00 [failed]> in state failed
[2024-10-02T17:12:04.532+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:12:04.532+0000] {taskinstance.py:3312} ERROR - Executor LocalExecutor(parallelism=32) reported that the task instance <TaskInstance: etl_pipeline.staging.dellstore_db.extract.customers manual__2024-10-02T17:10:54.658014+00:00 [queued]> finished with state failed, but the task instance's state attribute is queued. Learn more: https://airflow.apache.org/docs/apache-airflow/stable/troubleshooting.html#task-state-changed-externally
[2024-10-02T17:12:04.548+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:12:04.547+0000] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=etl_pipeline, task_id=staging.dellstore_db.extract.customers, run_id=manual__2024-10-02T17:10:54.658014+00:00, execution_date=20241002T171054, start_date=, end_date=20241002T171204
[2024-10-02T17:12:04.548+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:12:04.548+0000] {taskinstance.py:1563} INFO - Executing callback at index 0: slack_notifier
[2024-10-02T17:12:04.553+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:12:04.549+0000] {taskinstance.py:1567} ERROR - Error in callback at index 0: slack_notifier
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 1565, in _run_finished_callback
    callback(context)
  File "/opt/airflow/dags/helper/callbacks/slack_notifier.py", line 12, in slack_notifier
    traceback = "".join(tb.format_exception(type(exception), exception, exception.__traceback__)) if context.get('exception') else 'No traceback'
                                                                        ^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute '__traceback__'
[2024-10-02T17:12:04.566+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:12:04.566+0000] {processor.py:876} INFO - Executed callback for <TaskInstance: etl_pipeline.staging.dellstore_db.extract.customers manual__2024-10-02T17:10:54.658014+00:00 [failed]> in state failed
[2024-10-02T17:12:04.570+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:12:04.570+0000] {taskinstance.py:3312} ERROR - Executor LocalExecutor(parallelism=32) reported that the task instance <TaskInstance: etl_pipeline.staging.dellstore_db.extract.orders manual__2024-10-02T17:10:54.658014+00:00 [queued]> finished with state failed, but the task instance's state attribute is queued. Learn more: https://airflow.apache.org/docs/apache-airflow/stable/troubleshooting.html#task-state-changed-externally
[2024-10-02T17:12:04.585+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:12:04.585+0000] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=etl_pipeline, task_id=staging.dellstore_db.extract.orders, run_id=manual__2024-10-02T17:10:54.658014+00:00, execution_date=20241002T171054, start_date=, end_date=20241002T171204
[2024-10-02T17:12:04.586+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:12:04.586+0000] {taskinstance.py:1563} INFO - Executing callback at index 0: slack_notifier
[2024-10-02T17:12:04.589+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:12:04.586+0000] {taskinstance.py:1567} ERROR - Error in callback at index 0: slack_notifier
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 1565, in _run_finished_callback
    callback(context)
  File "/opt/airflow/dags/helper/callbacks/slack_notifier.py", line 12, in slack_notifier
    traceback = "".join(tb.format_exception(type(exception), exception, exception.__traceback__)) if context.get('exception') else 'No traceback'
                                                                        ^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute '__traceback__'
[2024-10-02T17:12:04.603+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:12:04.603+0000] {processor.py:876} INFO - Executed callback for <TaskInstance: etl_pipeline.staging.dellstore_db.extract.orders manual__2024-10-02T17:10:54.658014+00:00 [failed]> in state failed
[2024-10-02T17:12:04.844+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:12:04.843+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:12:04.885+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:12:04.885+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:12:04.958+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 17.031 seconds
[2024-10-02T17:12:35.124+0000] {processor.py:186} INFO - Started process (PID=13661) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:12:35.146+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:12:35.151+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:12:35.150+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:12:44.119+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:12:44.271+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:12:44.270+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:12:44.312+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:12:44.311+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:12:44.349+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 9.246 seconds
[2024-10-02T17:13:15.709+0000] {processor.py:186} INFO - Started process (PID=14071) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:13:15.713+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:13:15.718+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:13:15.717+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:13:25.252+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:13:25.415+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:13:25.414+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:13:25.459+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:13:25.458+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:13:25.500+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 9.807 seconds
[2024-10-02T17:13:56.682+0000] {processor.py:186} INFO - Started process (PID=14517) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:13:56.695+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:13:56.699+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:13:56.698+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:14:05.565+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:14:05.691+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:14:05.690+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:14:05.746+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:14:05.746+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:14:05.780+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 9.112 seconds
[2024-10-02T17:14:36.513+0000] {processor.py:186} INFO - Started process (PID=14943) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:14:36.514+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:14:36.516+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:14:36.515+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:14:43.841+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:14:44.105+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:14:44.105+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:14:44.145+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:14:44.144+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:14:44.180+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 7.676 seconds
[2024-10-02T17:15:14.326+0000] {processor.py:186} INFO - Started process (PID=15361) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:15:14.333+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:15:14.344+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:15:14.343+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:15:27.729+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:15:27.926+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:15:27.925+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:15:27.963+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:15:27.963+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:15:27.993+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 13.717 seconds
[2024-10-02T17:15:58.331+0000] {processor.py:186} INFO - Started process (PID=15944) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:15:58.344+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:15:58.348+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:15:58.347+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:16:08.757+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:16:09.347+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:16:09.345+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:16:09.427+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:16:09.426+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:16:09.481+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 11.172 seconds
[2024-10-02T17:16:39.863+0000] {processor.py:186} INFO - Started process (PID=16869) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:16:39.867+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:16:39.872+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:16:39.871+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:16:51.006+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:16:51.159+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:16:51.158+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:16:51.212+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:16:51.211+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:16:51.256+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 11.411 seconds
[2024-10-02T17:17:21.480+0000] {processor.py:186} INFO - Started process (PID=17515) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:17:21.488+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:17:21.493+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:17:21.492+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:17:33.043+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:17:33.170+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:17:33.169+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:17:33.229+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:17:33.229+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:17:33.264+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 11.810 seconds
[2024-10-02T17:18:03.633+0000] {processor.py:186} INFO - Started process (PID=18294) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:18:03.646+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:18:03.650+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:18:03.649+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:18:12.702+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:18:12.821+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:18:12.820+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:18:12.870+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:18:12.870+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:18:12.902+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 9.299 seconds
[2024-10-02T17:18:43.548+0000] {processor.py:186} INFO - Started process (PID=18713) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:18:43.550+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:18:43.552+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:18:43.551+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:18:51.880+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:18:52.006+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:18:52.004+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:18:52.071+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:18:52.071+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:18:52.108+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 8.568 seconds
[2024-10-02T17:19:22.633+0000] {processor.py:186} INFO - Started process (PID=19066) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:19:22.645+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:19:22.647+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:19:22.646+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:19:28.384+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:19:28.481+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:19:28.480+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:19:28.525+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:19:28.524+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:19:28.549+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.926 seconds
[2024-10-02T17:19:58.763+0000] {processor.py:186} INFO - Started process (PID=19537) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:19:58.778+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:19:58.784+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:19:58.782+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:20:08.541+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:20:08.817+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:20:08.816+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:20:08.852+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:20:08.851+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:20:08.903+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 10.215 seconds
[2024-10-02T17:20:39.553+0000] {processor.py:186} INFO - Started process (PID=20300) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:20:39.559+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:20:39.563+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:20:39.562+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:21:01.153+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:21:01.580+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:21:01.579+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:21:01.628+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:21:01.628+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:21:01.676+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 22.148 seconds
[2024-10-02T17:21:31.886+0000] {processor.py:186} INFO - Started process (PID=21341) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:21:31.888+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:21:31.896+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:21:31.895+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:21:46.252+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:21:46.393+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:21:46.392+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:21:46.447+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:21:46.447+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:21:46.479+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 14.623 seconds
[2024-10-02T17:22:16.879+0000] {processor.py:186} INFO - Started process (PID=21815) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:22:16.881+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:22:16.882+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:22:16.882+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:22:23.298+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:22:23.385+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:22:23.385+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:22:23.418+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:22:23.417+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:22:23.442+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.572 seconds
[2024-10-02T17:22:54.049+0000] {processor.py:186} INFO - Started process (PID=22160) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:22:54.061+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:22:54.062+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:22:54.062+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:22:59.586+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:22:59.693+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:22:59.692+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:22:59.730+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:22:59.730+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:22:59.757+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.717 seconds
[2024-10-02T17:23:29.916+0000] {processor.py:186} INFO - Started process (PID=22518) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:23:29.918+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:23:29.920+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:23:29.919+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:23:38.016+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:23:38.174+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:23:38.173+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:23:38.242+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:23:38.241+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:23:38.289+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 8.385 seconds
[2024-10-02T17:24:08.623+0000] {processor.py:186} INFO - Started process (PID=22889) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:24:08.625+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:24:08.627+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:24:08.626+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:24:14.724+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:24:14.858+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:24:14.857+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:24:14.898+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:24:14.898+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:24:14.927+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.311 seconds
[2024-10-02T17:24:45.552+0000] {processor.py:186} INFO - Started process (PID=23233) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:24:45.553+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:24:45.555+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:24:45.554+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:24:52.143+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:24:52.230+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:24:52.230+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:24:52.267+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:24:52.267+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:24:52.301+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.757 seconds
[2024-10-02T17:25:22.860+0000] {processor.py:186} INFO - Started process (PID=23580) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:25:22.862+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:25:22.865+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:25:22.864+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:25:28.625+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:25:28.888+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:25:28.888+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:25:28.925+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:25:28.925+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:25:28.960+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.112 seconds
[2024-10-02T17:25:59.831+0000] {processor.py:186} INFO - Started process (PID=23927) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:25:59.837+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:25:59.839+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:25:59.839+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:26:07.700+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:26:07.912+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:26:07.912+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:26:07.941+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:26:07.941+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:26:07.974+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 8.151 seconds
[2024-10-02T17:26:38.161+0000] {processor.py:186} INFO - Started process (PID=24301) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:26:38.173+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:26:38.174+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:26:38.174+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:26:45.100+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:26:45.206+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:26:45.205+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:26:45.255+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:26:45.255+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:26:45.283+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 7.132 seconds
[2024-10-02T17:27:15.576+0000] {processor.py:186} INFO - Started process (PID=24659) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:27:15.577+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:27:15.579+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:27:15.579+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:27:22.480+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:27:22.596+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:27:22.595+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:27:22.633+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:27:22.633+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:27:22.659+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 7.090 seconds
[2024-10-02T17:27:52.990+0000] {processor.py:186} INFO - Started process (PID=25005) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:27:52.992+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:27:52.994+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:27:52.993+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:28:01.181+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:28:01.280+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:28:01.279+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:28:01.317+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:28:01.317+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:28:01.357+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 8.377 seconds
[2024-10-02T17:28:32.040+0000] {processor.py:186} INFO - Started process (PID=25512) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:28:32.045+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:28:32.049+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:28:32.047+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:28:51.396+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:28:51.681+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:28:51.680+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:28:51.722+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:28:51.722+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:28:51.773+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 19.753 seconds
[2024-10-02T17:29:22.356+0000] {processor.py:186} INFO - Started process (PID=26230) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:29:22.357+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:29:22.359+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:29:22.358+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:29:28.310+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:29:28.526+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:29:28.526+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:29:28.553+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:29:28.553+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:29:28.591+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.244 seconds
[2024-10-02T17:29:58.676+0000] {processor.py:186} INFO - Started process (PID=26578) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:29:58.678+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:29:58.679+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:29:58.679+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:30:04.296+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:30:04.494+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:30:04.494+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:30:04.521+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:30:04.521+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:30:04.557+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.889 seconds
[2024-10-02T17:30:34.785+0000] {processor.py:186} INFO - Started process (PID=26922) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:30:34.798+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:30:34.799+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:30:34.799+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:30:39.478+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:30:39.565+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:30:39.564+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:30:39.598+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:30:39.598+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:30:39.626+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.848 seconds
[2024-10-02T17:31:09.839+0000] {processor.py:186} INFO - Started process (PID=27272) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:31:09.841+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:31:09.842+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:31:09.842+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:31:14.764+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:31:14.845+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:31:14.844+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:31:14.876+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:31:14.876+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:31:14.899+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.068 seconds
[2024-10-02T17:31:45.192+0000] {processor.py:186} INFO - Started process (PID=27624) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:31:45.204+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:31:45.206+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:31:45.205+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:31:49.930+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:31:50.014+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:31:50.014+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:31:50.050+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:31:50.050+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:31:50.082+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.897 seconds
[2024-10-02T17:32:20.669+0000] {processor.py:186} INFO - Started process (PID=27971) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:32:20.681+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:32:20.683+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:32:20.682+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:32:26.199+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:32:26.287+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:32:26.287+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:32:26.321+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:32:26.320+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:32:26.346+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.686 seconds
[2024-10-02T17:32:57.075+0000] {processor.py:186} INFO - Started process (PID=28340) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:32:57.087+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:32:57.088+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:32:57.088+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:33:02.009+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:33:02.088+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:33:02.088+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:33:02.124+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:33:02.124+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:33:02.160+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.093 seconds
[2024-10-02T17:33:32.845+0000] {processor.py:186} INFO - Started process (PID=28685) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:33:32.858+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:33:32.859+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:33:32.859+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:33:37.681+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:33:37.754+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:33:37.754+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:33:37.787+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:33:37.786+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:33:37.810+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.972 seconds
[2024-10-02T17:34:07.899+0000] {processor.py:186} INFO - Started process (PID=29030) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:34:07.901+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:34:07.903+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:34:07.903+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:34:16.359+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:34:16.486+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:34:16.485+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:34:16.533+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:34:16.532+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:34:16.561+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 8.669 seconds
[2024-10-02T17:34:46.695+0000] {processor.py:186} INFO - Started process (PID=29394) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:34:46.707+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:34:46.709+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:34:46.709+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:34:52.093+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:34:52.312+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:34:52.311+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:34:52.340+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:34:52.339+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:34:52.377+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.690 seconds
[2024-10-02T17:35:23.049+0000] {processor.py:186} INFO - Started process (PID=29738) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:35:23.061+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:35:23.064+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:35:23.063+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:35:27.970+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:35:28.193+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:35:28.192+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:35:28.226+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:35:28.225+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:35:28.263+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.221 seconds
[2024-10-02T17:35:58.391+0000] {processor.py:186} INFO - Started process (PID=30089) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:35:58.403+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:35:58.405+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:35:58.405+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:36:03.615+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:36:03.728+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:36:03.727+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:36:03.776+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:36:03.775+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:36:03.806+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.422 seconds
[2024-10-02T17:36:33.912+0000] {processor.py:186} INFO - Started process (PID=30446) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:36:33.913+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:36:33.915+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:36:33.914+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:36:38.996+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:36:39.218+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:36:39.218+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:36:39.245+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:36:39.245+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:36:39.282+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.378 seconds
[2024-10-02T17:37:09.758+0000] {processor.py:186} INFO - Started process (PID=30794) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:37:09.770+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:37:09.772+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:37:09.771+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:37:15.171+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:37:15.377+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:37:15.376+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:37:15.406+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:37:15.405+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:37:15.434+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.683 seconds
[2024-10-02T17:37:45.882+0000] {processor.py:186} INFO - Started process (PID=31139) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:37:45.884+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:37:45.886+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:37:45.886+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:37:50.815+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:37:51.032+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:37:51.031+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:37:51.058+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:37:51.058+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:37:51.101+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.227 seconds
[2024-10-02T17:38:21.177+0000] {processor.py:186} INFO - Started process (PID=31492) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:38:21.189+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:38:21.191+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:38:21.190+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:38:26.305+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:38:26.388+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:38:26.387+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:38:26.420+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:38:26.420+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:38:26.445+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.275 seconds
[2024-10-02T17:38:57.307+0000] {processor.py:186} INFO - Started process (PID=31839) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:38:57.319+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:38:57.320+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:38:57.320+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:39:02.206+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:39:02.415+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:39:02.415+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:39:02.443+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:39:02.442+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:39:02.480+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.180 seconds
[2024-10-02T17:39:32.534+0000] {processor.py:186} INFO - Started process (PID=32185) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:39:32.536+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:39:32.538+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:39:32.537+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:39:37.404+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:39:37.612+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:39:37.612+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:39:37.641+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:39:37.641+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:39:37.670+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.144 seconds
[2024-10-02T17:40:07.912+0000] {processor.py:186} INFO - Started process (PID=32533) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:40:07.924+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:40:07.925+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:40:07.925+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:40:13.221+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:40:13.305+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:40:13.304+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:40:13.336+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:40:13.335+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:40:13.362+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.458 seconds
[2024-10-02T17:40:43.523+0000] {processor.py:186} INFO - Started process (PID=32889) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:40:43.524+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:40:43.526+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:40:43.525+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:40:48.946+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:40:49.151+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:40:49.150+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:40:49.183+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:40:49.182+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:40:49.213+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.699 seconds
[2024-10-02T17:41:19.966+0000] {processor.py:186} INFO - Started process (PID=33245) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:41:19.978+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:41:19.979+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:41:19.979+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:41:24.899+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:41:25.114+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:41:25.113+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:41:25.139+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:41:25.138+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:41:25.179+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.221 seconds
[2024-10-02T17:41:55.523+0000] {processor.py:186} INFO - Started process (PID=33595) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:41:55.535+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:41:55.536+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:41:55.536+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:42:00.687+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:42:00.769+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:42:00.768+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:42:00.800+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:42:00.800+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:42:00.824+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.309 seconds
[2024-10-02T17:42:30.880+0000] {processor.py:186} INFO - Started process (PID=33940) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:42:30.881+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:42:30.883+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:42:30.883+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:42:36.335+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:42:36.553+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:42:36.552+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:42:36.582+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:42:36.581+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:42:36.619+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.746 seconds
[2024-10-02T17:43:06.687+0000] {processor.py:186} INFO - Started process (PID=34289) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:43:06.699+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:43:06.701+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:43:06.700+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:43:11.539+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:43:11.750+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:43:11.749+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:43:11.780+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:43:11.780+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:43:11.819+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.139 seconds
[2024-10-02T17:43:42.595+0000] {processor.py:186} INFO - Started process (PID=34635) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:43:42.597+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:43:42.599+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:43:42.598+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:43:47.654+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:43:47.742+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:43:47.741+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:43:47.774+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:43:47.773+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:43:47.800+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.211 seconds
[2024-10-02T17:44:18.222+0000] {processor.py:186} INFO - Started process (PID=34983) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:44:18.224+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:44:18.226+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:44:18.226+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:44:23.553+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:44:23.632+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:44:23.631+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:44:23.670+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:44:23.669+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:44:23.700+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.486 seconds
[2024-10-02T17:44:53.782+0000] {processor.py:186} INFO - Started process (PID=35340) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:44:53.783+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:44:53.785+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:44:53.784+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:44:58.818+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:44:58.924+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:44:58.923+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:44:58.977+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:44:58.976+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:44:59.026+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.252 seconds
[2024-10-02T17:45:29.335+0000] {processor.py:186} INFO - Started process (PID=35694) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:45:29.337+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:45:29.339+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:45:29.338+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:45:34.260+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:45:34.335+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:45:34.334+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:45:34.364+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:45:34.363+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:45:34.388+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.060 seconds
[2024-10-02T17:46:05.037+0000] {processor.py:186} INFO - Started process (PID=36038) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:46:05.039+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:46:05.040+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:46:05.040+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:46:09.879+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:46:10.099+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:46:10.098+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:46:10.129+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:46:10.129+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:46:10.159+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.130 seconds
[2024-10-02T17:46:40.342+0000] {processor.py:186} INFO - Started process (PID=36386) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:46:40.349+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:46:40.350+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:46:40.350+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:46:45.098+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:46:45.305+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:46:45.305+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:46:45.332+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:46:45.331+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:46:45.371+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.038 seconds
[2024-10-02T17:47:15.423+0000] {processor.py:186} INFO - Started process (PID=36735) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:47:15.424+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:47:15.426+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:47:15.425+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:47:20.419+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:47:20.501+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:47:20.501+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:47:20.532+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:47:20.532+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:47:20.569+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.152 seconds
[2024-10-02T17:47:51.161+0000] {processor.py:186} INFO - Started process (PID=37086) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:47:51.162+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:47:51.164+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:47:51.163+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:47:55.934+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:47:56.134+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:47:56.133+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:47:56.159+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:47:56.159+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:47:56.195+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.042 seconds
[2024-10-02T17:48:26.953+0000] {processor.py:186} INFO - Started process (PID=37434) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:48:26.965+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:48:26.967+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:48:26.967+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:48:32.021+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:48:32.220+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:48:32.219+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:48:32.251+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:48:32.250+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:48:32.291+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.346 seconds
[2024-10-02T17:49:02.646+0000] {processor.py:186} INFO - Started process (PID=37784) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:49:02.647+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:49:02.649+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:49:02.649+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:49:08.133+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:49:08.220+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:49:08.218+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:49:08.261+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:49:08.261+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:49:08.286+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.650 seconds
[2024-10-02T17:49:38.423+0000] {processor.py:186} INFO - Started process (PID=38141) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:49:38.432+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:49:38.434+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:49:38.433+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:49:43.363+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:49:43.566+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:49:43.565+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:49:43.594+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:49:43.593+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:49:43.621+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.206 seconds
[2024-10-02T17:50:14.257+0000] {processor.py:186} INFO - Started process (PID=38486) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:50:14.259+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:50:14.262+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:50:14.261+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:50:19.112+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:50:19.321+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:50:19.320+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:50:19.346+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:50:19.345+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:50:19.372+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.124 seconds
[2024-10-02T17:50:49.428+0000] {processor.py:186} INFO - Started process (PID=38840) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:50:49.440+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:50:49.442+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:50:49.442+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:50:54.481+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:50:54.567+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:50:54.566+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:50:54.599+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:50:54.599+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:50:54.632+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.211 seconds
[2024-10-02T17:51:24.777+0000] {processor.py:186} INFO - Started process (PID=39188) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:51:24.779+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:51:24.781+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:51:24.780+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:51:29.705+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:51:29.923+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:51:29.923+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:51:29.951+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:51:29.951+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:51:29.988+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.220 seconds
[2024-10-02T17:52:00.087+0000] {processor.py:186} INFO - Started process (PID=39540) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:52:00.089+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:52:00.090+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:52:00.090+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:52:05.113+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:52:05.329+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:52:05.328+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:52:05.354+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:52:05.354+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:52:05.395+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.315 seconds
[2024-10-02T17:52:35.527+0000] {processor.py:186} INFO - Started process (PID=39892) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:52:35.528+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:52:35.530+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:52:35.529+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:52:40.390+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:52:40.608+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:52:40.607+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:52:40.634+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:52:40.634+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:52:40.672+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.154 seconds
[2024-10-02T17:53:10.777+0000] {processor.py:186} INFO - Started process (PID=40240) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:53:10.778+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:53:10.780+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:53:10.779+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:53:16.132+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:53:16.351+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:53:16.350+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:53:16.379+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:53:16.379+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:53:16.416+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.647 seconds
[2024-10-02T17:53:46.817+0000] {processor.py:186} INFO - Started process (PID=40596) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:53:46.818+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:53:46.820+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:53:46.819+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:53:51.785+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:53:51.990+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:53:51.989+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:53:52.016+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:53:52.016+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:53:52.054+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.244 seconds
[2024-10-02T17:54:22.674+0000] {processor.py:186} INFO - Started process (PID=40946) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:54:22.676+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:54:22.677+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:54:22.677+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:54:27.722+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:54:27.925+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:54:27.924+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:54:27.951+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:54:27.951+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:54:27.979+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.312 seconds
[2024-10-02T17:54:58.505+0000] {processor.py:186} INFO - Started process (PID=41291) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:54:58.507+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:54:58.508+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:54:58.508+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:55:03.431+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:55:03.646+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:55:03.645+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:55:03.673+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:55:03.673+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:55:03.703+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.206 seconds
[2024-10-02T17:55:34.174+0000] {processor.py:186} INFO - Started process (PID=41647) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:55:34.186+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:55:34.188+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:55:34.187+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:55:39.080+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:55:39.156+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:55:39.155+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:55:39.189+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:55:39.188+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:55:39.224+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.058 seconds
[2024-10-02T17:56:09.649+0000] {processor.py:186} INFO - Started process (PID=41996) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:56:09.661+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:56:09.663+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:56:09.662+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:56:14.385+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:56:14.608+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:56:14.607+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:56:14.635+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:56:14.635+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:56:14.673+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.032 seconds
[2024-10-02T17:56:44.905+0000] {processor.py:186} INFO - Started process (PID=42339) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:56:44.917+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:56:44.919+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:56:44.918+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:56:49.617+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:56:49.822+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:56:49.821+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:56:49.851+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:56:49.851+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:56:49.879+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.982 seconds
[2024-10-02T17:57:20.294+0000] {processor.py:186} INFO - Started process (PID=42684) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:57:20.296+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:57:20.298+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:57:20.298+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:57:25.610+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:57:25.828+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:57:25.827+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:57:25.854+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:57:25.853+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:57:25.883+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.597 seconds
[2024-10-02T17:57:56.063+0000] {processor.py:186} INFO - Started process (PID=43044) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:57:56.065+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:57:56.066+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:57:56.066+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:58:01.299+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:58:01.497+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:58:01.497+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:58:01.523+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:58:01.522+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:58:01.560+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.504 seconds
[2024-10-02T17:58:31.863+0000] {processor.py:186} INFO - Started process (PID=43391) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:58:31.875+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:58:31.878+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:58:31.877+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:58:37.054+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:58:37.331+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:58:37.330+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:58:37.383+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:58:37.383+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:58:37.437+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.582 seconds
[2024-10-02T17:59:07.798+0000] {processor.py:186} INFO - Started process (PID=43747) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:59:07.810+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:59:07.811+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:59:07.811+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:59:12.844+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:59:13.042+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:59:13.042+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:59:13.069+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:59:13.069+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:59:13.105+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.316 seconds
[2024-10-02T17:59:43.528+0000] {processor.py:186} INFO - Started process (PID=44096) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:59:43.531+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T17:59:43.533+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:59:43.532+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:59:48.297+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T17:59:48.502+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:59:48.501+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T17:59:48.529+0000] {logging_mixin.py:190} INFO - [2024-10-02T17:59:48.528+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T17:59:48.559+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.039 seconds
[2024-10-02T18:00:18.716+0000] {processor.py:186} INFO - Started process (PID=44443) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:00:18.718+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:00:18.720+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:00:18.720+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:00:23.615+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:00:23.837+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:00:23.836+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:00:23.867+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:00:23.867+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:00:23.906+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.198 seconds
[2024-10-02T18:00:54.264+0000] {processor.py:186} INFO - Started process (PID=44786) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:00:54.276+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:00:54.278+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:00:54.277+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:00:59.256+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:00:59.345+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:00:59.344+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:00:59.384+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:00:59.384+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:00:59.409+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.155 seconds
[2024-10-02T18:01:29.759+0000] {processor.py:186} INFO - Started process (PID=45138) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:01:29.772+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:01:29.774+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:01:29.773+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:01:35.367+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:01:35.604+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:01:35.603+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:01:35.632+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:01:35.632+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:01:35.660+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.908 seconds
[2024-10-02T18:02:05.989+0000] {processor.py:186} INFO - Started process (PID=45499) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:02:05.991+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:02:05.992+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:02:05.992+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:02:11.155+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:02:11.366+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:02:11.365+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:02:11.394+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:02:11.393+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:02:11.431+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.449 seconds
[2024-10-02T18:02:41.557+0000] {processor.py:186} INFO - Started process (PID=45850) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:02:41.569+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:02:41.571+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:02:41.571+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:02:47.025+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:02:47.222+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:02:47.221+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:02:47.252+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:02:47.252+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:02:47.293+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.744 seconds
[2024-10-02T18:03:17.741+0000] {processor.py:186} INFO - Started process (PID=46203) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:03:17.753+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:03:17.755+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:03:17.754+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:03:22.822+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:03:23.023+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:03:23.022+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:03:23.048+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:03:23.047+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:03:23.086+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.352 seconds
[2024-10-02T18:03:53.612+0000] {processor.py:186} INFO - Started process (PID=46545) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:03:53.613+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:03:53.615+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:03:53.614+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:03:58.594+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:03:58.853+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:03:58.852+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:03:58.899+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:03:58.898+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:03:58.948+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.343 seconds
[2024-10-02T18:04:29.364+0000] {processor.py:186} INFO - Started process (PID=46886) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:04:29.366+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:04:29.367+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:04:29.367+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:04:34.571+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:04:34.752+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:04:34.751+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:04:34.777+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:04:34.777+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:04:34.804+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.447 seconds
[2024-10-02T18:05:04.895+0000] {processor.py:186} INFO - Started process (PID=47236) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:05:04.898+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:05:04.899+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:05:04.899+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:05:09.941+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:05:10.041+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:05:10.040+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:05:10.079+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:05:10.078+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:05:10.116+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.228 seconds
[2024-10-02T18:05:40.429+0000] {processor.py:186} INFO - Started process (PID=47585) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:05:40.431+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:05:40.434+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:05:40.433+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:05:45.836+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:05:46.077+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:05:46.076+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:05:46.107+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:05:46.107+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:05:46.145+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.725 seconds
[2024-10-02T18:06:16.432+0000] {processor.py:186} INFO - Started process (PID=47950) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:06:16.434+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:06:16.435+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:06:16.435+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:06:21.486+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:06:21.696+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:06:21.696+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:06:21.727+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:06:21.727+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:06:21.759+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.334 seconds
[2024-10-02T18:06:51.817+0000] {processor.py:186} INFO - Started process (PID=48293) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:06:51.819+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:06:51.821+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:06:51.820+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:06:56.914+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:06:56.999+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:06:56.999+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:06:57.032+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:06:57.032+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:06:57.067+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.257 seconds
[2024-10-02T18:07:27.419+0000] {processor.py:186} INFO - Started process (PID=48645) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:07:27.420+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:07:27.422+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:07:27.421+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:07:32.357+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:07:32.561+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:07:32.561+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:07:32.591+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:07:32.590+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:07:32.618+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.207 seconds
[2024-10-02T18:08:03.366+0000] {processor.py:186} INFO - Started process (PID=48989) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:08:03.378+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:08:03.380+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:08:03.380+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:08:08.229+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:08:08.417+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:08:08.416+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:08:08.442+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:08:08.441+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:08:08.470+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.111 seconds
[2024-10-02T18:08:39.102+0000] {processor.py:186} INFO - Started process (PID=49338) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:08:39.103+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:08:39.105+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:08:39.104+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:08:44.132+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:08:44.231+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:08:44.230+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:08:44.276+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:08:44.275+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:08:44.304+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.209 seconds
[2024-10-02T18:09:14.930+0000] {processor.py:186} INFO - Started process (PID=49687) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:09:14.931+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:09:14.933+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:09:14.932+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:09:20.106+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:09:20.345+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:09:20.344+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:09:20.375+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:09:20.374+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:09:20.404+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.481 seconds
[2024-10-02T18:09:50.927+0000] {processor.py:186} INFO - Started process (PID=50042) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:09:50.939+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:09:50.941+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:09:50.941+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:09:56.403+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:09:56.640+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:09:56.639+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:09:56.668+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:09:56.668+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:09:56.706+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.787 seconds
[2024-10-02T18:10:26.889+0000] {processor.py:186} INFO - Started process (PID=50395) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:10:26.901+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:10:26.902+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:10:26.902+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:10:32.032+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:10:32.257+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:10:32.256+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:10:32.285+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:10:32.284+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:10:32.325+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.444 seconds
[2024-10-02T18:11:03.196+0000] {processor.py:186} INFO - Started process (PID=50744) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:11:03.209+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:11:03.210+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:11:03.210+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:11:08.327+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:11:08.540+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:11:08.540+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:11:08.570+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:11:08.570+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:11:08.609+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.420 seconds
[2024-10-02T18:11:39.028+0000] {processor.py:186} INFO - Started process (PID=51088) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:11:39.029+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:11:39.031+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:11:39.031+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:11:43.855+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:11:43.942+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:11:43.941+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:11:43.973+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:11:43.973+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:11:44.007+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.987 seconds
[2024-10-02T18:12:14.351+0000] {processor.py:186} INFO - Started process (PID=51434) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:12:14.352+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:12:14.354+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:12:14.353+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:12:19.312+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:12:19.508+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:12:19.508+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:12:19.534+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:12:19.534+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:12:19.575+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.232 seconds
[2024-10-02T18:12:50.545+0000] {processor.py:186} INFO - Started process (PID=51786) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:12:50.546+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:12:50.548+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:12:50.548+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:12:55.295+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:12:55.503+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:12:55.502+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:12:55.530+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:12:55.529+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:12:55.557+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.019 seconds
[2024-10-02T18:13:25.813+0000] {processor.py:186} INFO - Started process (PID=52134) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:13:25.825+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:13:25.827+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:13:25.827+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:13:30.961+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:13:31.191+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:13:31.190+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:13:31.222+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:13:31.222+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:13:31.259+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.453 seconds
[2024-10-02T18:14:01.833+0000] {processor.py:186} INFO - Started process (PID=52483) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:14:01.838+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:14:01.840+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:14:01.839+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:14:07.042+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:14:07.256+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:14:07.255+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:14:07.288+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:14:07.288+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:14:07.327+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.502 seconds
[2024-10-02T18:14:37.505+0000] {processor.py:186} INFO - Started process (PID=52839) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:14:37.517+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:14:37.518+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:14:37.518+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:14:42.577+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:14:42.654+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:14:42.654+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:14:42.687+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:14:42.687+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:14:42.720+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.222 seconds
[2024-10-02T18:15:13.587+0000] {processor.py:186} INFO - Started process (PID=53184) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:15:13.599+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:15:13.601+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:15:13.601+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:15:18.800+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:15:18.887+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:15:18.886+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:15:18.921+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:15:18.921+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:15:18.954+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.375 seconds
[2024-10-02T18:15:49.216+0000] {processor.py:186} INFO - Started process (PID=53536) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:15:49.228+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:15:49.230+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:15:49.229+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:15:54.337+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:15:54.552+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:15:54.551+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:15:54.579+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:15:54.579+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:15:54.617+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.409 seconds
[2024-10-02T18:16:24.669+0000] {processor.py:186} INFO - Started process (PID=53885) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:16:24.672+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:16:24.674+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:16:24.674+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:16:29.438+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:16:29.512+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:16:29.511+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:16:29.545+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:16:29.544+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:16:29.569+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.906 seconds
[2024-10-02T18:17:00.040+0000] {processor.py:186} INFO - Started process (PID=54228) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:17:00.041+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:17:00.043+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:17:00.042+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:17:04.886+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:17:05.095+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:17:05.094+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:17:05.120+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:17:05.120+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:17:05.157+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.125 seconds
[2024-10-02T18:17:35.645+0000] {processor.py:186} INFO - Started process (PID=54569) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:17:35.657+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:17:35.659+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:17:35.658+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:17:40.759+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:17:40.858+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:17:40.857+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:17:40.899+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:17:40.898+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:17:40.925+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.287 seconds
[2024-10-02T18:18:11.217+0000] {processor.py:186} INFO - Started process (PID=54918) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:18:11.220+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:18:11.222+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:18:11.221+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:18:16.401+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:18:16.625+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:18:16.624+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:18:16.653+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:18:16.653+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:18:16.691+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.481 seconds
[2024-10-02T18:18:46.989+0000] {processor.py:186} INFO - Started process (PID=55277) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:18:47.001+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:18:47.003+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:18:47.002+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:18:52.354+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:18:52.584+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:18:52.583+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:18:52.610+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:18:52.610+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:18:52.649+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.667 seconds
[2024-10-02T18:19:22.854+0000] {processor.py:186} INFO - Started process (PID=55631) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:19:22.865+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:19:22.868+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:19:22.867+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:19:28.374+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:19:28.599+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:19:28.598+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:19:28.624+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:19:28.623+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:19:28.651+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.806 seconds
[2024-10-02T18:19:59.380+0000] {processor.py:186} INFO - Started process (PID=55987) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:19:59.382+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:19:59.384+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:19:59.383+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:20:04.388+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:20:04.569+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:20:04.569+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:20:04.596+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:20:04.595+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:20:04.631+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.260 seconds
[2024-10-02T18:20:34.791+0000] {processor.py:186} INFO - Started process (PID=56332) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:20:34.792+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:20:34.795+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:20:34.794+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:20:39.525+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:20:39.731+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:20:39.730+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:20:39.758+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:20:39.758+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:20:39.797+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.013 seconds
[2024-10-02T18:21:10.269+0000] {processor.py:186} INFO - Started process (PID=56677) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:21:10.281+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:21:10.283+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:21:10.282+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:21:15.007+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:21:15.211+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:21:15.210+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:21:15.238+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:21:15.237+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:21:15.281+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.023 seconds
[2024-10-02T18:21:45.762+0000] {processor.py:186} INFO - Started process (PID=57021) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:21:45.774+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:21:45.776+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:21:45.776+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:21:51.374+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:21:51.599+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:21:51.598+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:21:51.627+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:21:51.627+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:21:51.655+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.903 seconds
[2024-10-02T18:22:22.050+0000] {processor.py:186} INFO - Started process (PID=57392) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:22:22.051+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:22:22.053+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:22:22.053+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:22:27.342+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:22:27.432+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:22:27.431+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:22:27.466+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:22:27.466+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:22:27.496+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.452 seconds
[2024-10-02T18:22:57.865+0000] {processor.py:186} INFO - Started process (PID=57741) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:22:57.877+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:22:57.878+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:22:57.878+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:23:02.998+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:23:03.217+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:23:03.216+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:23:03.246+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:23:03.246+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:23:03.278+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.420 seconds
[2024-10-02T18:23:33.505+0000] {processor.py:186} INFO - Started process (PID=58090) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:23:33.507+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:23:33.509+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:23:33.508+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:23:38.560+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:23:38.772+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:23:38.771+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:23:38.798+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:23:38.798+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:23:38.831+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.334 seconds
[2024-10-02T18:24:08.972+0000] {processor.py:186} INFO - Started process (PID=58433) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:24:08.974+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:24:08.975+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:24:08.975+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:24:13.938+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:24:14.115+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:24:14.114+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:24:14.141+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:24:14.140+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:24:14.176+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.213 seconds
[2024-10-02T18:24:44.626+0000] {processor.py:186} INFO - Started process (PID=58777) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:24:44.638+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:24:44.640+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:24:44.639+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:24:49.497+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:24:49.584+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:24:49.583+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:24:49.616+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:24:49.616+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:24:49.642+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.023 seconds
[2024-10-02T18:25:20.144+0000] {processor.py:186} INFO - Started process (PID=59123) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:25:20.157+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:25:20.158+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:25:20.158+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:25:25.679+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:25:25.788+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:25:25.787+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:25:25.824+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:25:25.824+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:25:25.860+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.723 seconds
[2024-10-02T18:25:56.218+0000] {processor.py:186} INFO - Started process (PID=59479) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:25:56.219+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:25:56.221+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:25:56.220+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:26:02.317+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:26:02.557+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:26:02.557+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:26:02.589+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:26:02.588+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:26:02.622+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.412 seconds
[2024-10-02T18:26:32.751+0000] {processor.py:186} INFO - Started process (PID=59840) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:26:32.763+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:26:32.764+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:26:32.764+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:26:38.195+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:26:38.422+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:26:38.421+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:26:38.448+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:26:38.448+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:26:38.487+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.744 seconds
[2024-10-02T18:27:08.577+0000] {processor.py:186} INFO - Started process (PID=60192) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:27:08.589+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:27:08.592+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:27:08.591+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:27:13.632+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:27:13.848+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:27:13.848+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:27:13.881+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:27:13.881+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:27:13.909+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.341 seconds
[2024-10-02T18:27:44.373+0000] {processor.py:186} INFO - Started process (PID=60538) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:27:44.385+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:27:44.386+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:27:44.386+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:27:49.464+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:27:49.542+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:27:49.542+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:27:49.580+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:27:49.580+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:27:49.605+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.240 seconds
[2024-10-02T18:28:19.851+0000] {processor.py:186} INFO - Started process (PID=60883) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:28:19.863+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:28:19.864+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:28:19.864+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:28:24.670+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:28:24.760+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:28:24.760+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:28:24.792+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:28:24.791+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:28:24.818+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.974 seconds
[2024-10-02T18:28:54.954+0000] {processor.py:186} INFO - Started process (PID=61227) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:28:54.956+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:28:54.958+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:28:54.958+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:28:59.774+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:28:59.854+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:28:59.853+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:28:59.889+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:28:59.888+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:28:59.924+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.977 seconds
[2024-10-02T18:29:30.292+0000] {processor.py:186} INFO - Started process (PID=61577) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:29:30.293+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:29:30.294+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:29:30.294+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:29:35.292+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:29:35.509+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:29:35.509+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:29:35.537+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:29:35.537+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:29:35.574+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.290 seconds
[2024-10-02T18:30:06.276+0000] {processor.py:186} INFO - Started process (PID=61936) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:30:06.288+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:30:06.289+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:30:06.289+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:30:10.814+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:30:10.882+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:30:10.882+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:30:10.909+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:30:10.909+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:30:10.929+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.661 seconds
[2024-10-02T18:30:40.993+0000] {processor.py:186} INFO - Started process (PID=62292) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:30:40.995+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:30:40.996+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:30:40.996+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:30:45.155+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:30:45.226+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:30:45.226+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:30:45.254+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:30:45.254+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:30:45.275+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.291 seconds
[2024-10-02T18:31:15.830+0000] {processor.py:186} INFO - Started process (PID=62635) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:31:15.843+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:31:15.845+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:31:15.844+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:31:20.034+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:31:20.186+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:31:20.186+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:31:20.207+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:31:20.207+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:31:20.229+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.405 seconds
[2024-10-02T18:31:50.783+0000] {processor.py:186} INFO - Started process (PID=62977) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:31:50.796+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:31:50.798+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:31:50.797+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:31:55.026+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:31:55.086+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:31:55.085+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:31:55.111+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:31:55.111+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:31:55.128+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.352 seconds
[2024-10-02T18:32:26.090+0000] {processor.py:186} INFO - Started process (PID=63319) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:32:26.092+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:32:26.094+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:32:26.093+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:32:30.323+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:32:30.380+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:32:30.380+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:32:30.405+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:32:30.405+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:32:30.432+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.350 seconds
[2024-10-02T18:33:00.686+0000] {processor.py:186} INFO - Started process (PID=63663) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:33:00.699+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:33:00.701+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:33:00.701+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:33:05.036+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:33:05.197+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:33:05.196+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:33:05.220+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:33:05.220+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:33:05.243+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.563 seconds
[2024-10-02T18:33:35.492+0000] {processor.py:186} INFO - Started process (PID=64013) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:33:35.505+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:33:35.506+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:33:35.506+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:33:39.787+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:33:39.859+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:33:39.859+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:33:39.883+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:33:39.883+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:33:39.903+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.418 seconds
[2024-10-02T18:34:09.947+0000] {processor.py:186} INFO - Started process (PID=64366) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:34:09.948+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:34:09.950+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:34:09.950+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:34:14.193+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:34:14.252+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:34:14.251+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:34:14.279+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:34:14.279+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:34:14.303+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.365 seconds
[2024-10-02T18:34:44.691+0000] {processor.py:186} INFO - Started process (PID=64715) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:34:44.693+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:34:44.695+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:34:44.694+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:34:48.996+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:34:49.205+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:34:49.204+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:34:49.240+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:34:49.240+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:34:49.270+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.586 seconds
[2024-10-02T18:35:19.568+0000] {processor.py:186} INFO - Started process (PID=65056) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:35:19.569+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:35:19.571+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:35:19.570+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:35:23.817+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:35:23.980+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:35:23.980+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:35:24.000+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:35:23.999+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:35:24.021+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.461 seconds
[2024-10-02T18:35:54.480+0000] {processor.py:186} INFO - Started process (PID=65411) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:35:54.492+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:35:54.494+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:35:54.494+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:35:58.757+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:35:58.818+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:35:58.818+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:35:58.842+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:35:58.842+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:35:58.870+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.397 seconds
[2024-10-02T18:36:29.024+0000] {processor.py:186} INFO - Started process (PID=65754) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:36:29.036+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:36:29.037+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:36:29.037+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:36:33.347+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:36:33.412+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:36:33.411+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:36:33.437+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:36:33.436+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:36:33.455+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.439 seconds
[2024-10-02T18:37:03.785+0000] {processor.py:186} INFO - Started process (PID=66100) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:37:03.797+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:37:03.799+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:37:03.798+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:37:07.983+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:37:08.130+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:37:08.129+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:37:08.150+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:37:08.150+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:37:08.185+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.407 seconds
[2024-10-02T18:37:38.890+0000] {processor.py:186} INFO - Started process (PID=66446) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:37:38.902+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:37:38.903+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:37:38.903+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:37:43.069+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:37:43.230+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:37:43.230+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:37:43.252+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:37:43.251+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:37:43.275+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.393 seconds
[2024-10-02T18:38:13.479+0000] {processor.py:186} INFO - Started process (PID=66789) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:38:13.487+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:38:13.488+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:38:13.488+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:38:17.693+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:38:17.845+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:38:17.844+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:38:17.865+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:38:17.864+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:38:17.896+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.424 seconds
[2024-10-02T18:38:48.769+0000] {processor.py:186} INFO - Started process (PID=67140) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:38:48.782+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:38:48.784+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:38:48.784+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:38:53.048+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:38:53.196+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:38:53.195+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:38:53.217+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:38:53.217+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:38:53.238+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.475 seconds
[2024-10-02T18:39:23.342+0000] {processor.py:186} INFO - Started process (PID=67488) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:39:23.354+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:39:23.356+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:39:23.356+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:39:27.463+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:39:27.617+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:39:27.616+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:39:27.637+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:39:27.637+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:39:27.670+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.335 seconds
[2024-10-02T18:39:58.317+0000] {processor.py:186} INFO - Started process (PID=67831) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:39:58.329+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:39:58.330+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:39:58.330+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:40:02.697+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:40:02.755+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:40:02.755+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:40:02.785+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:40:02.785+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:40:02.803+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.494 seconds
[2024-10-02T18:40:33.083+0000] {processor.py:186} INFO - Started process (PID=68186) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:40:33.084+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:40:33.086+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:40:33.085+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:40:37.323+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:40:37.386+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:40:37.385+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:40:37.408+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:40:37.408+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:40:37.436+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.361 seconds
[2024-10-02T18:41:07.500+0000] {processor.py:186} INFO - Started process (PID=68533) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:41:07.501+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:41:07.503+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:41:07.502+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:41:11.752+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:41:11.815+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:41:11.814+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:41:11.838+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:41:11.838+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:41:11.855+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.362 seconds
[2024-10-02T18:41:42.557+0000] {processor.py:186} INFO - Started process (PID=68876) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:41:42.569+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:41:42.571+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:41:42.570+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:41:46.799+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:41:46.957+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:41:46.957+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:41:46.978+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:41:46.978+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:41:47.011+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.463 seconds
[2024-10-02T18:42:17.762+0000] {processor.py:186} INFO - Started process (PID=69218) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:42:17.764+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:42:17.766+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:42:17.765+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:42:22.035+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:42:22.188+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:42:22.187+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:42:22.209+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:42:22.209+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:42:22.232+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.477 seconds
[2024-10-02T18:42:52.349+0000] {processor.py:186} INFO - Started process (PID=69570) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:42:52.350+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:42:52.352+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:42:52.352+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:42:58.546+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:42:58.654+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:42:58.653+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:42:58.697+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:42:58.697+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:42:58.739+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.397 seconds
[2024-10-02T18:43:29.532+0000] {processor.py:186} INFO - Started process (PID=69917) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:43:29.533+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:43:29.535+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:43:29.534+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:43:38.410+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:43:38.637+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:43:38.637+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:43:38.668+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:43:38.668+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:43:38.696+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 9.172 seconds
[2024-10-02T18:44:09.049+0000] {processor.py:186} INFO - Started process (PID=70279) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:44:09.051+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:44:09.052+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:44:09.052+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:44:14.344+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:44:14.548+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:44:14.547+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:44:14.574+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:44:14.574+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:44:14.600+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.559 seconds
[2024-10-02T18:44:44.807+0000] {processor.py:186} INFO - Started process (PID=70639) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:44:44.820+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:44:44.821+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:44:44.821+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:44:49.122+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:44:49.271+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:44:49.271+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:44:49.293+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:44:49.292+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:44:49.325+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.525 seconds
[2024-10-02T18:45:19.410+0000] {processor.py:186} INFO - Started process (PID=70983) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:45:19.423+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:45:19.424+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:45:19.424+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:45:27.578+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:45:27.835+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:45:27.835+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:45:27.878+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:45:27.878+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:45:27.912+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 8.511 seconds
[2024-10-02T18:45:58.337+0000] {processor.py:186} INFO - Started process (PID=71506) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:45:58.344+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:45:58.349+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:45:58.348+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:46:28.365+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:46:28.356+0000] {timeout.py:68} ERROR - Process timed out, PID: 71506
[2024-10-02T18:46:28.393+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:46:28.382+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 5, in <module>
    from etl_pipeline.tasks.warehouse.main import warehouse
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 4, in <module>
    from etl_pipeline.tasks.warehouse.components.extract_transform import ExtractTransform
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/components/extract_transform.py", line 5, in <module>
    from etl_pipeline.tasks.warehouse.components.validations import Validation, ValidationType
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/components/validations.py", line 11, in <module>
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py", line 497, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 515, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 201, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/context.py", line 436, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py", line 104, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/etl_pipeline/run.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.10.2/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.10.2/best-practices.html#reducing-dag-complexity, PID: 71506
[2024-10-02T18:46:28.396+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:46:28.832+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 30.530 seconds
[2024-10-02T18:46:59.192+0000] {processor.py:186} INFO - Started process (PID=72989) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:46:59.194+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:46:59.197+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:46:59.196+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:47:16.869+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:47:17.408+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:47:17.407+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:47:17.489+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:47:17.488+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:47:17.570+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 18.397 seconds
[2024-10-02T18:47:47.938+0000] {processor.py:186} INFO - Started process (PID=73387) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:47:47.939+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:47:47.941+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:47:47.941+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:47:57.608+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:47:57.993+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:47:57.992+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:47:58.045+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:47:58.044+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:47:58.097+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 10.167 seconds
[2024-10-02T18:48:28.904+0000] {processor.py:186} INFO - Started process (PID=73739) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:48:28.916+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:48:28.918+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:48:28.917+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:48:40.196+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:48:40.398+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:48:40.397+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:48:40.476+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:48:40.475+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:48:40.545+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 11.650 seconds
[2024-10-02T18:49:10.881+0000] {processor.py:186} INFO - Started process (PID=74245) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:49:10.895+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:49:10.901+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:49:10.898+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:49:28.172+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:49:28.620+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:49:28.618+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:49:28.698+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:49:28.697+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:49:28.806+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 17.952 seconds
[2024-10-02T18:49:59.159+0000] {processor.py:186} INFO - Started process (PID=74950) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:49:59.167+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:49:59.170+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:49:59.169+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:50:09.617+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:50:09.793+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:50:09.792+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:50:09.838+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:50:09.838+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:50:09.869+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 10.718 seconds
[2024-10-02T18:50:40.474+0000] {processor.py:186} INFO - Started process (PID=75315) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:50:40.476+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:50:40.478+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:50:40.478+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:50:49.845+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:50:49.992+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:50:49.991+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:50:50.041+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:50:50.041+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:50:50.085+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 9.626 seconds
[2024-10-02T18:51:20.628+0000] {processor.py:186} INFO - Started process (PID=75678) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:51:20.630+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:51:20.632+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:51:20.632+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:51:30.818+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:51:31.148+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:51:31.147+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:51:31.181+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:51:31.181+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:51:31.231+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 10.610 seconds
[2024-10-02T18:52:01.775+0000] {processor.py:186} INFO - Started process (PID=76034) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:52:01.777+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:52:01.778+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:52:01.778+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:52:11.937+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:52:12.335+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:52:12.334+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:52:12.400+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:52:12.399+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:52:12.452+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 10.691 seconds
[2024-10-02T18:52:42.852+0000] {processor.py:186} INFO - Started process (PID=76389) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:52:42.854+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:52:42.857+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:52:42.856+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:52:51.624+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:52:51.944+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:52:51.942+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:52:52.034+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:52:52.033+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:52:52.099+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 9.259 seconds
[2024-10-02T18:53:22.315+0000] {processor.py:186} INFO - Started process (PID=76744) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:53:22.326+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:53:22.328+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:53:22.328+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:53:31.027+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:53:31.470+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:53:31.469+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:53:31.511+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:53:31.510+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:53:31.555+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 9.250 seconds
[2024-10-02T18:54:01.824+0000] {processor.py:186} INFO - Started process (PID=77108) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:54:01.836+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:54:01.838+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:54:01.837+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:54:16.666+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:54:16.852+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:54:16.851+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:54:16.917+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:54:16.916+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:54:16.953+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 15.138 seconds
[2024-10-02T18:54:47.566+0000] {processor.py:186} INFO - Started process (PID=77483) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:54:47.577+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:54:47.579+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:54:47.579+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:54:53.480+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:54:53.776+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:54:53.775+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:54:53.813+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:54:53.812+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:54:53.858+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.301 seconds
[2024-10-02T18:55:24.540+0000] {processor.py:186} INFO - Started process (PID=77912) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:55:24.552+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:55:24.554+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:55:24.554+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:55:30.600+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:55:30.898+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:55:30.897+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:55:30.944+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:55:30.943+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:55:30.987+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.455 seconds
[2024-10-02T18:56:01.413+0000] {processor.py:186} INFO - Started process (PID=78393) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:56:01.415+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:56:01.418+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:56:01.417+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:56:10.650+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:56:10.974+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:56:10.973+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:56:11.009+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:56:11.008+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:56:11.039+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 9.634 seconds
[2024-10-02T18:56:41.328+0000] {processor.py:186} INFO - Started process (PID=78775) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:56:41.340+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:56:41.342+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:56:41.341+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:56:50.428+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:56:50.555+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:56:50.554+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:56:50.604+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:56:50.604+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:56:50.642+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 9.324 seconds
[2024-10-02T18:57:21.075+0000] {processor.py:186} INFO - Started process (PID=79200) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:57:21.076+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:57:21.078+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:57:21.077+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:57:27.608+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:57:27.717+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:57:27.716+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:57:27.751+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:57:27.750+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:57:27.787+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.719 seconds
[2024-10-02T18:57:58.270+0000] {processor.py:186} INFO - Started process (PID=79556) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:57:58.287+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:57:58.303+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:57:58.291+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:58:10.241+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:58:10.360+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:58:10.359+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:58:10.405+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:58:10.404+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:58:10.448+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 12.225 seconds
[2024-10-02T18:58:40.911+0000] {processor.py:186} INFO - Started process (PID=80106) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:58:40.923+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:58:40.925+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:58:40.925+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:58:47.224+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:58:47.318+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:58:47.317+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:58:47.354+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:58:47.353+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:58:47.391+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.488 seconds
[2024-10-02T18:59:18.109+0000] {processor.py:186} INFO - Started process (PID=80624) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:59:18.111+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:59:18.112+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:59:18.112+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:59:27.812+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:59:27.934+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:59:27.933+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T18:59:28.025+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:59:28.025+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T18:59:28.154+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 10.053 seconds
[2024-10-02T18:59:59.002+0000] {processor.py:186} INFO - Started process (PID=80996) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T18:59:59.014+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T18:59:59.016+0000] {logging_mixin.py:190} INFO - [2024-10-02T18:59:59.015+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:00:06.397+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:00:06.512+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:00:06.512+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:00:06.547+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:00:06.546+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:00:06.583+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 7.591 seconds
[2024-10-02T19:00:36.805+0000] {processor.py:186} INFO - Started process (PID=81597) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:00:36.807+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:00:36.810+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:00:36.809+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:00:46.107+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:00:46.326+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:00:46.326+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:00:46.354+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:00:46.354+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:00:46.383+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 9.593 seconds
[2024-10-02T19:01:16.533+0000] {processor.py:186} INFO - Started process (PID=82033) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:01:16.545+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:01:16.547+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:01:16.546+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:01:29.555+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:01:30.442+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:01:30.441+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:01:30.555+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:01:30.552+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:01:31.586+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 15.061 seconds
[2024-10-02T19:02:01.850+0000] {processor.py:186} INFO - Started process (PID=82546) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:02:01.853+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:02:01.856+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:02:01.855+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:02:16.565+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:02:17.131+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:02:17.129+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:02:17.186+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:02:17.186+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:02:17.240+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 15.405 seconds
[2024-10-02T19:02:47.532+0000] {processor.py:186} INFO - Started process (PID=83066) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:02:47.544+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:02:47.545+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:02:47.545+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:02:56.630+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:02:56.781+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:02:56.780+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:02:56.838+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:02:56.838+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:02:56.881+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 9.357 seconds
[2024-10-02T19:03:27.069+0000] {processor.py:186} INFO - Started process (PID=83420) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:03:27.070+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:03:27.072+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:03:27.071+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:03:36.961+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:03:37.132+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:03:37.131+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:03:37.186+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:03:37.185+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:03:37.233+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 10.172 seconds
[2024-10-02T19:04:07.893+0000] {processor.py:186} INFO - Started process (PID=83781) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:04:07.906+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:04:07.908+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:04:07.907+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:04:15.687+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:04:15.859+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:04:15.858+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:04:15.911+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:04:15.910+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:04:15.951+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 8.065 seconds
[2024-10-02T19:04:46.149+0000] {processor.py:186} INFO - Started process (PID=84141) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:04:46.151+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:04:46.154+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:04:46.153+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:04:56.731+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:04:56.897+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:04:56.896+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:04:56.955+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:04:56.954+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:04:57.002+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 10.862 seconds
[2024-10-02T19:05:27.653+0000] {processor.py:186} INFO - Started process (PID=84510) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:05:27.665+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:05:27.666+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:05:27.666+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:05:36.052+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:05:36.532+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:05:36.530+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:05:36.601+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:05:36.600+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:05:36.674+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 9.030 seconds
[2024-10-02T19:06:07.057+0000] {processor.py:186} INFO - Started process (PID=84886) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:06:07.060+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:06:07.066+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:06:07.062+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:06:19.679+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:06:19.889+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:06:19.888+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:06:19.981+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:06:19.980+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:06:20.031+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 12.989 seconds
[2024-10-02T19:06:50.438+0000] {processor.py:186} INFO - Started process (PID=85320) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:06:50.439+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:06:50.440+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:06:50.440+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:06:56.711+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:06:57.067+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:06:57.066+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:06:57.112+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:06:57.112+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:06:57.162+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.732 seconds
[2024-10-02T19:07:27.509+0000] {processor.py:186} INFO - Started process (PID=85757) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:07:27.511+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:07:27.514+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:07:27.513+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:07:36.000+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:07:36.159+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:07:36.157+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:07:36.222+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:07:36.222+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:07:36.276+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 8.780 seconds
[2024-10-02T19:08:07.228+0000] {processor.py:186} INFO - Started process (PID=86130) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:08:07.229+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:08:07.231+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:08:07.231+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:08:15.871+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:08:16.326+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:08:16.325+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:08:16.388+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:08:16.387+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:08:16.445+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 9.226 seconds
[2024-10-02T19:08:47.385+0000] {processor.py:186} INFO - Started process (PID=86645) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:08:47.398+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:08:47.400+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:08:47.399+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:08:56.378+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:08:56.835+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:08:56.834+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:08:56.900+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:08:56.899+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:08:56.966+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 9.588 seconds
[2024-10-02T19:09:27.280+0000] {processor.py:186} INFO - Started process (PID=87006) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:09:27.282+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:09:27.284+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:09:27.283+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:09:41.638+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:09:42.371+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:09:42.369+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:09:42.443+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:09:42.442+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:09:42.530+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 15.262 seconds
[2024-10-02T19:10:13.034+0000] {processor.py:186} INFO - Started process (PID=87377) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:10:13.038+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:10:13.051+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:10:13.050+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:10:27.203+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:10:27.480+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:10:27.479+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:10:27.579+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:10:27.579+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:10:27.654+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 14.649 seconds
[2024-10-02T19:10:58.030+0000] {processor.py:186} INFO - Started process (PID=87760) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:10:58.034+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:10:58.037+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:10:58.036+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:11:09.700+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:11:10.161+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:11:10.160+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:11:10.229+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:11:10.229+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:11:10.302+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 12.289 seconds
[2024-10-02T19:11:40.865+0000] {processor.py:186} INFO - Started process (PID=88131) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:11:40.882+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:11:40.884+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:11:40.884+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:11:53.013+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:11:53.416+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:11:53.415+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:11:53.489+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:11:53.488+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:11:53.573+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 12.722 seconds
[2024-10-02T19:12:24.298+0000] {processor.py:186} INFO - Started process (PID=88500) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:12:24.311+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:12:24.314+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:12:24.314+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:12:37.701+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:12:38.286+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:12:38.284+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:12:38.349+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:12:38.349+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:12:38.426+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 14.141 seconds
[2024-10-02T19:13:09.000+0000] {processor.py:186} INFO - Started process (PID=88944) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:13:09.014+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:13:09.018+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:13:09.017+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:13:29.897+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:13:31.018+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:13:31.015+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:13:31.174+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:13:31.172+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:13:31.332+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 22.357 seconds
[2024-10-02T19:14:02.004+0000] {processor.py:186} INFO - Started process (PID=89437) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:14:02.016+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:14:02.018+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:14:02.018+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:14:15.609+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:14:16.223+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:14:16.221+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:14:16.300+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:14:16.299+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:14:16.403+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 14.412 seconds
[2024-10-02T19:14:46.657+0000] {processor.py:186} INFO - Started process (PID=89823) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:14:46.659+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:14:46.661+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:14:46.661+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:14:58.033+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:14:58.346+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:14:58.344+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:14:58.456+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:14:58.454+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:14:58.541+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 11.895 seconds
[2024-10-02T19:15:29.193+0000] {processor.py:186} INFO - Started process (PID=90196) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:15:29.206+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:15:29.209+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:15:29.208+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:15:38.624+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:15:38.800+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:15:38.799+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:15:38.903+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:15:38.902+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:15:38.976+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 9.793 seconds
[2024-10-02T19:16:09.353+0000] {processor.py:186} INFO - Started process (PID=90554) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:16:09.355+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:16:09.358+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:16:09.357+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:16:20.351+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:16:20.537+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:16:20.535+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:16:20.607+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:16:20.606+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:16:20.660+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 11.320 seconds
[2024-10-02T19:16:50.947+0000] {processor.py:186} INFO - Started process (PID=90934) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:16:50.949+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:16:50.952+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:16:50.951+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:17:00.754+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:17:01.226+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:17:01.224+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:17:01.276+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:17:01.275+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:17:01.334+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 10.402 seconds
[2024-10-02T19:17:31.929+0000] {processor.py:186} INFO - Started process (PID=91304) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:17:31.943+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:17:31.947+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:17:31.946+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:17:42.679+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:17:43.079+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:17:43.078+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:17:43.125+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:17:43.124+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:17:43.188+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 11.279 seconds
[2024-10-02T19:18:13.515+0000] {processor.py:186} INFO - Started process (PID=91673) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:18:13.518+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:18:13.522+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:18:13.521+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:18:24.063+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:18:24.221+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:18:24.220+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:18:24.295+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:18:24.294+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:18:24.343+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 10.849 seconds
[2024-10-02T19:18:55.162+0000] {processor.py:186} INFO - Started process (PID=92059) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:18:55.175+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:18:55.177+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:18:55.176+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:19:07.321+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:19:07.481+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:19:07.479+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:19:07.546+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:19:07.546+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:19:07.604+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 12.454 seconds
[2024-10-02T19:19:38.115+0000] {processor.py:186} INFO - Started process (PID=92494) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:19:38.118+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:19:38.123+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:19:38.121+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:19:57.169+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:19:57.501+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:19:57.498+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:19:57.670+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:19:57.669+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:19:57.827+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 19.730 seconds
[2024-10-02T19:20:28.046+0000] {processor.py:186} INFO - Started process (PID=93135) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:20:28.059+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:20:28.063+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:20:28.062+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:20:48.938+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:20:49.779+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:20:49.778+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:20:49.969+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:20:49.968+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:20:50.141+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 22.113 seconds
[2024-10-02T19:21:20.747+0000] {processor.py:186} INFO - Started process (PID=93749) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:21:20.749+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:21:20.751+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:21:20.751+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:21:35.385+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:21:36.318+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:21:36.316+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:21:36.436+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:21:36.436+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:21:36.546+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 15.817 seconds
[2024-10-02T19:22:07.049+0000] {processor.py:186} INFO - Started process (PID=94118) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:22:07.052+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:22:07.056+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:22:07.055+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:22:19.145+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:22:19.886+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:22:19.884+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:22:20.010+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:22:20.009+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:22:20.152+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 13.121 seconds
[2024-10-02T19:22:50.616+0000] {processor.py:186} INFO - Started process (PID=94518) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:22:50.619+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:22:50.622+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:22:50.621+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:23:09.510+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:23:09.849+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:23:09.847+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:23:09.983+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:23:09.982+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:23:10.065+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 19.466 seconds
[2024-10-02T19:23:40.599+0000] {processor.py:186} INFO - Started process (PID=95141) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:23:40.610+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:23:40.628+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:23:40.620+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:24:08.887+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:24:09.212+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:24:09.210+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:24:09.394+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:24:09.393+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:24:09.519+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 28.981 seconds
[2024-10-02T19:24:40.646+0000] {processor.py:186} INFO - Started process (PID=95871) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:24:40.670+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:24:40.675+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:24:40.674+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:25:02.361+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:25:02.669+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:25:02.664+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:25:02.848+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:25:02.847+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:25:02.928+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 22.341 seconds
[2024-10-02T19:25:33.262+0000] {processor.py:186} INFO - Started process (PID=96366) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:25:33.264+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:25:33.267+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:25:33.266+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:25:44.223+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:25:44.390+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:25:44.389+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:25:44.451+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:25:44.450+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:25:44.506+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 11.256 seconds
[2024-10-02T19:26:14.638+0000] {processor.py:186} INFO - Started process (PID=96756) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:26:14.650+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:26:14.653+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:26:14.652+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:26:24.541+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:26:24.679+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:26:24.678+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:26:24.740+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:26:24.739+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:26:24.781+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 10.155 seconds
[2024-10-02T19:26:55.475+0000] {processor.py:186} INFO - Started process (PID=97113) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:26:55.477+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:26:55.479+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:26:55.479+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:27:05.718+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:27:05.855+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:27:05.854+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:27:05.899+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:27:05.898+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:27:05.944+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 10.481 seconds
[2024-10-02T19:27:36.183+0000] {processor.py:186} INFO - Started process (PID=97477) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:27:36.195+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:27:36.197+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:27:36.196+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:27:45.549+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:27:45.665+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:27:45.664+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:27:45.707+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:27:45.706+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:27:45.746+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 9.573 seconds
[2024-10-02T19:28:16.185+0000] {processor.py:186} INFO - Started process (PID=97857) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:28:16.186+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:28:16.188+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:28:16.188+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:28:22.878+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:28:23.126+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:28:23.126+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:28:23.156+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:28:23.156+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:28:23.197+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 7.023 seconds
[2024-10-02T19:28:53.621+0000] {processor.py:186} INFO - Started process (PID=98215) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:28:53.633+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:28:53.634+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:28:53.634+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:28:59.549+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:28:59.768+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:28:59.767+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:28:59.799+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:28:59.799+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:29:00.156+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.543 seconds
[2024-10-02T19:29:30.465+0000] {processor.py:186} INFO - Started process (PID=98567) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:29:30.477+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:29:30.479+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:29:30.479+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:29:35.836+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:29:35.921+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:29:35.920+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:29:35.962+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:29:35.962+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:29:36.009+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.551 seconds
[2024-10-02T19:30:06.187+0000] {processor.py:186} INFO - Started process (PID=98921) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:30:06.200+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:30:06.206+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:30:06.204+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:30:16.257+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:30:16.716+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:30:16.715+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:30:16.778+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:30:16.778+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:30:16.839+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 10.671 seconds
[2024-10-02T19:30:47.073+0000] {processor.py:186} INFO - Started process (PID=99298) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:30:47.085+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:30:47.087+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:30:47.086+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:30:55.375+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:30:55.732+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:30:55.731+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:30:55.778+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:30:55.777+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:30:56.167+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 9.105 seconds
[2024-10-02T19:31:26.760+0000] {processor.py:186} INFO - Started process (PID=99676) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:31:26.772+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:31:26.774+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:31:26.773+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:31:33.361+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:31:33.739+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:31:33.738+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:31:33.798+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:31:33.798+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:31:33.859+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 7.106 seconds
[2024-10-02T19:32:04.159+0000] {processor.py:186} INFO - Started process (PID=100077) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:32:04.162+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:32:04.168+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:32:04.167+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:32:17.950+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:32:18.211+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:32:18.209+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:32:18.288+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:32:18.287+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:32:18.362+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 14.222 seconds
[2024-10-02T19:32:49.047+0000] {processor.py:186} INFO - Started process (PID=100700) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:32:49.049+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:32:49.051+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:32:49.050+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:32:57.444+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:32:57.595+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:32:57.594+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:32:57.674+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:32:57.674+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:32:57.746+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 8.707 seconds
[2024-10-02T19:33:28.211+0000] {processor.py:186} INFO - Started process (PID=101083) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:33:28.223+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:33:28.225+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:33:28.224+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:33:36.395+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:33:36.622+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:33:36.621+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:33:36.689+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:33:36.689+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:33:36.733+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 8.529 seconds
[2024-10-02T19:34:07.158+0000] {processor.py:186} INFO - Started process (PID=101455) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:34:07.170+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:34:07.172+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:34:07.171+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:34:15.389+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:34:15.530+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:34:15.529+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:34:15.590+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:34:15.590+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:34:15.635+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 8.484 seconds
[2024-10-02T19:34:46.010+0000] {processor.py:186} INFO - Started process (PID=101807) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:34:46.013+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:34:46.016+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:34:46.015+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:34:55.000+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:34:55.489+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:34:55.487+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:34:55.950+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:34:55.949+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:34:56.006+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 10.016 seconds
[2024-10-02T19:35:26.907+0000] {processor.py:186} INFO - Started process (PID=102174) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:35:26.911+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:35:26.915+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:35:26.914+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:35:38.864+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:35:39.173+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:35:39.171+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:35:39.381+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:35:39.381+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:35:39.535+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 12.642 seconds
[2024-10-02T19:36:09.942+0000] {processor.py:186} INFO - Started process (PID=102710) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:36:09.943+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:36:09.945+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:36:09.944+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:36:15.814+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:36:16.353+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:36:16.352+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:36:16.385+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:36:16.385+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:36:16.419+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.484 seconds
[2024-10-02T19:36:46.510+0000] {processor.py:186} INFO - Started process (PID=103201) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:36:46.514+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:36:46.517+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:36:46.517+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:36:59.617+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:36:59.897+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:36:59.894+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:36:59.990+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:36:59.989+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:37:00.101+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 13.613 seconds
[2024-10-02T19:37:30.284+0000] {processor.py:186} INFO - Started process (PID=103588) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:37:30.296+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:37:30.298+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:37:30.297+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:37:36.507+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:37:36.642+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:37:36.641+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:37:36.699+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:37:36.699+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:37:36.742+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.465 seconds
[2024-10-02T19:38:07.005+0000] {processor.py:186} INFO - Started process (PID=103956) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:38:07.011+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:38:07.013+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:38:07.012+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:38:13.833+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:38:14.008+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:38:14.007+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:38:14.110+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:38:14.109+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:38:14.179+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 7.182 seconds
[2024-10-02T19:38:44.690+0000] {processor.py:186} INFO - Started process (PID=104319) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:38:44.693+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:38:44.695+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:38:44.694+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:38:55.570+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:38:55.711+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:38:55.710+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:38:55.757+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:38:55.757+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:38:55.787+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 11.109 seconds
[2024-10-02T19:39:26.004+0000] {processor.py:186} INFO - Started process (PID=104684) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:39:26.016+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:39:26.018+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:39:26.018+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:39:36.324+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:39:36.516+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:39:36.514+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:39:36.597+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:39:36.596+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:39:36.662+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 10.666 seconds
[2024-10-02T19:40:07.061+0000] {processor.py:186} INFO - Started process (PID=105051) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:40:07.062+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:40:07.063+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:40:07.063+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:40:15.904+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:40:16.124+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:40:16.123+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:40:16.227+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:40:16.227+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:40:16.287+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 9.234 seconds
[2024-10-02T19:40:46.597+0000] {processor.py:186} INFO - Started process (PID=105557) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:40:46.611+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:40:46.614+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:40:46.613+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:41:03.329+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:41:04.184+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:41:04.183+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:41:04.234+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:41:04.234+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:41:04.280+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 17.702 seconds
[2024-10-02T19:41:34.777+0000] {processor.py:186} INFO - Started process (PID=106152) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:41:34.789+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:41:34.791+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:41:34.791+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:41:43.128+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:41:44.002+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:41:43.999+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:41:44.052+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:41:44.052+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:41:44.108+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 9.338 seconds
[2024-10-02T19:42:14.668+0000] {processor.py:186} INFO - Started process (PID=106749) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:42:14.671+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:42:14.676+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:42:14.674+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:42:29.236+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:42:29.591+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:42:29.590+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:42:29.736+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:42:29.735+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:42:29.789+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 15.146 seconds
[2024-10-02T19:42:59.990+0000] {processor.py:186} INFO - Started process (PID=107240) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:42:59.992+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:42:59.994+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:42:59.993+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:43:08.295+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:43:08.446+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:43:08.444+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:43:08.505+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:43:08.504+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:43:08.556+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 8.578 seconds
[2024-10-02T19:43:38.858+0000] {processor.py:186} INFO - Started process (PID=107605) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:43:38.869+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:43:38.871+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:43:38.871+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:43:49.696+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:43:49.870+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:43:49.869+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:43:50.446+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:43:50.445+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:43:50.517+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 11.667 seconds
[2024-10-02T19:44:21.003+0000] {processor.py:186} INFO - Started process (PID=107978) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:44:21.004+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:44:21.006+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:44:21.006+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:44:27.733+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:44:27.894+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:44:27.893+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:44:27.969+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:44:27.968+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:44:28.018+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 7.023 seconds
[2024-10-02T19:44:58.148+0000] {processor.py:186} INFO - Started process (PID=108347) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:44:58.150+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:44:58.152+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:44:58.151+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:45:05.931+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:45:06.082+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:45:06.081+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:45:06.144+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:45:06.144+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:45:06.468+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 8.329 seconds
[2024-10-02T19:45:37.125+0000] {processor.py:186} INFO - Started process (PID=108707) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:45:37.137+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:45:37.139+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:45:37.138+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:45:42.991+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:45:43.093+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:45:43.093+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:45:43.408+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:45:43.408+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:45:43.433+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.318 seconds
[2024-10-02T19:46:13.885+0000] {processor.py:186} INFO - Started process (PID=109067) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:46:13.897+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:46:13.899+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:46:13.899+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:46:21.976+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:46:22.171+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:46:22.170+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:46:22.255+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:46:22.253+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:46:22.312+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 8.436 seconds
[2024-10-02T19:46:52.803+0000] {processor.py:186} INFO - Started process (PID=109433) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:46:52.805+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:46:52.806+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:46:52.806+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:46:59.304+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:46:59.438+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:46:59.437+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:46:59.486+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:46:59.486+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:46:59.524+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.731 seconds
[2024-10-02T19:47:29.860+0000] {processor.py:186} INFO - Started process (PID=109795) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:47:29.873+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:47:29.874+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:47:29.874+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:47:36.073+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:47:36.168+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:47:36.167+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:47:36.410+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:47:36.410+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:47:36.433+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.580 seconds
[2024-10-02T19:48:06.608+0000] {processor.py:186} INFO - Started process (PID=110158) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:48:06.610+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:48:06.612+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:48:06.611+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:48:15.043+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:48:15.431+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:48:15.430+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:48:15.478+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:48:15.477+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:48:15.521+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 8.920 seconds
[2024-10-02T19:48:45.590+0000] {processor.py:186} INFO - Started process (PID=110519) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:48:45.602+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:48:45.603+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:48:45.603+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:48:50.947+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:48:51.016+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:48:51.015+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:48:51.043+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:48:51.043+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:48:51.075+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.493 seconds
[2024-10-02T19:49:21.136+0000] {processor.py:186} INFO - Started process (PID=110878) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:49:21.149+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:49:21.152+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:49:21.151+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:49:27.559+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:49:27.660+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:49:27.659+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:49:27.901+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:49:27.901+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:49:27.936+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.810 seconds
[2024-10-02T19:49:58.487+0000] {processor.py:186} INFO - Started process (PID=111236) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:49:58.489+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:49:58.491+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:49:58.491+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:50:06.974+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:50:07.426+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:50:07.425+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:50:07.484+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:50:07.483+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:50:07.526+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 9.050 seconds
[2024-10-02T19:50:38.455+0000] {processor.py:186} INFO - Started process (PID=111597) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:50:38.457+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:50:38.458+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:50:38.458+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:50:47.149+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:50:47.269+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:50:47.267+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:50:47.308+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:50:47.308+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:50:47.341+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 8.893 seconds
[2024-10-02T19:51:18.236+0000] {processor.py:186} INFO - Started process (PID=111963) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:51:18.248+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:51:18.250+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:51:18.249+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:51:25.421+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:51:25.561+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:51:25.560+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:51:25.882+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:51:25.881+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:51:25.921+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 7.695 seconds
[2024-10-02T19:51:56.899+0000] {processor.py:186} INFO - Started process (PID=112334) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:51:56.901+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:51:56.903+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:51:56.902+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:52:05.689+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:52:06.265+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:52:06.263+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:52:06.377+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:52:06.376+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:52:06.437+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 9.545 seconds
[2024-10-02T19:52:36.584+0000] {processor.py:186} INFO - Started process (PID=112691) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:52:36.586+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:52:36.588+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:52:36.588+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:52:46.936+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:52:47.405+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:52:47.402+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:52:47.496+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:52:47.495+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:52:47.569+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 10.993 seconds
[2024-10-02T19:53:18.437+0000] {processor.py:186} INFO - Started process (PID=113058) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:53:18.440+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:53:18.442+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:53:18.441+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:53:25.788+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:53:26.547+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:53:26.546+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:53:26.602+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:53:26.601+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:53:26.647+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 8.219 seconds
[2024-10-02T19:53:57.377+0000] {processor.py:186} INFO - Started process (PID=113443) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:53:57.389+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:53:57.391+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:53:57.390+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:54:04.056+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:54:04.227+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:54:04.226+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:54:04.301+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:54:04.300+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:54:04.342+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.971 seconds
[2024-10-02T19:54:34.914+0000] {processor.py:186} INFO - Started process (PID=113799) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:54:34.926+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:54:34.928+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:54:34.928+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:54:44.239+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:54:44.620+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:54:44.619+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:54:44.670+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:54:44.670+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:54:44.715+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 9.809 seconds
[2024-10-02T19:55:14.847+0000] {processor.py:186} INFO - Started process (PID=114153) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:55:14.859+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:55:14.861+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:55:14.860+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:55:23.495+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:55:24.351+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:55:24.349+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:55:24.427+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:55:24.426+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:55:24.480+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 9.641 seconds
[2024-10-02T19:55:54.980+0000] {processor.py:186} INFO - Started process (PID=114523) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:55:54.992+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:55:54.994+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:55:54.993+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:56:06.521+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:56:06.862+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:56:06.861+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:56:06.907+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:56:06.906+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:56:06.954+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 11.981 seconds
[2024-10-02T19:56:37.118+0000] {processor.py:186} INFO - Started process (PID=114900) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:56:37.120+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:56:37.122+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:56:37.121+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:56:44.807+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:56:44.952+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:56:44.952+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:56:45.288+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:56:45.288+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:56:45.326+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 8.215 seconds
[2024-10-02T19:57:15.520+0000] {processor.py:186} INFO - Started process (PID=115266) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:57:15.521+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:57:15.523+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:57:15.523+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:57:25.024+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:57:25.646+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:57:25.645+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:57:25.720+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:57:25.719+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:57:25.788+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 10.277 seconds
[2024-10-02T19:57:55.891+0000] {processor.py:186} INFO - Started process (PID=115625) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:57:55.892+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:57:55.894+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:57:55.893+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:58:05.526+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:58:05.877+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:58:05.876+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:58:05.929+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:58:05.928+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:58:05.994+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 10.112 seconds
[2024-10-02T19:58:36.434+0000] {processor.py:186} INFO - Started process (PID=115992) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:58:36.435+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:58:36.437+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:58:36.436+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:58:43.450+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:58:44.018+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:58:44.017+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:58:44.050+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:58:44.049+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:58:44.095+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 7.668 seconds
[2024-10-02T19:59:14.223+0000] {processor.py:186} INFO - Started process (PID=116364) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:59:14.235+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:59:14.237+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:59:14.237+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:59:20.232+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:59:20.368+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:59:20.367+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T19:59:20.429+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:59:20.428+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T19:59:20.489+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.272 seconds
[2024-10-02T19:59:51.119+0000] {processor.py:186} INFO - Started process (PID=116724) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:59:51.124+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T19:59:51.127+0000] {logging_mixin.py:190} INFO - [2024-10-02T19:59:51.127+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T19:59:59.750+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:00:00.136+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:00:00.135+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T20:00:00.205+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:00:00.203+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T20:00:00.287+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 9.176 seconds
[2024-10-02T20:00:30.752+0000] {processor.py:186} INFO - Started process (PID=117078) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:00:30.754+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:00:30.755+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:00:30.755+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:00:36.869+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:00:37.664+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:00:37.663+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T20:00:37.721+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:00:37.720+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T20:00:37.774+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 7.029 seconds
[2024-10-02T20:01:08.057+0000] {processor.py:186} INFO - Started process (PID=117591) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:01:08.059+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:01:08.061+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:01:08.061+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:01:20.215+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:01:20.199+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 274, in warehouse
    step_1() >> step_2() >> step_3()
    ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 91, in step_1
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 20, in extract_transform
    SparkSubmitOperator(
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 124, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 949, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/helpers.py", line 53, in validate_key
    raise TypeError(f"The key has to be a string and is {type(k)}:{k}")
TypeError: The key has to be a string and is <class 'tuple'>:('categories', 'customers', 'customers_history')
[2024-10-02T20:01:20.218+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:01:20.249+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 12.200 seconds
[2024-10-02T20:01:23.614+0000] {processor.py:186} INFO - Started process (PID=117938) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:01:23.615+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:01:23.619+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:01:23.618+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:01:31.169+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:01:31.160+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 274, in warehouse
    step_1() >> step_2() >> step_3()
    ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 91, in step_1
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 20, in extract_transform
    SparkSubmitOperator(
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 124, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 949, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/helpers.py", line 53, in validate_key
    raise TypeError(f"The key has to be a string and is {type(k)}:{k}")
TypeError: The key has to be a string and is <class 'tuple'>:('categories', 'customers', 'customers_history')
[2024-10-02T20:01:31.170+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:01:31.268+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:01:31.268+0000] {taskinstance.py:3312} ERROR - Executor LocalExecutor(parallelism=32) reported that the task instance <TaskInstance: etl_pipeline.warehouse.step_1.extract_transform.categories manual__2024-10-02T17:10:54.658014+00:00 [queued]> finished with state failed, but the task instance's state attribute is queued. Learn more: https://airflow.apache.org/docs/apache-airflow/stable/troubleshooting.html#task-state-changed-externally
[2024-10-02T20:01:31.311+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:01:31.310+0000] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=etl_pipeline, task_id=warehouse.step_1.extract_transform.categories, run_id=manual__2024-10-02T17:10:54.658014+00:00, execution_date=20241002T171054, start_date=20241002T193247, end_date=20241002T200131
[2024-10-02T20:01:31.311+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:01:31.311+0000] {taskinstance.py:1563} INFO - Executing callback at index 0: str
[2024-10-02T20:01:31.312+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:01:31.312+0000] {taskinstance.py:1567} ERROR - Error in callback at index 0: str
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 1565, in _run_finished_callback
    callback(context)
TypeError: 'str' object is not callable
[2024-10-02T20:01:31.332+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:01:31.332+0000] {processor.py:876} INFO - Executed callback for <TaskInstance: etl_pipeline.warehouse.step_1.extract_transform.categories manual__2024-10-02T17:10:54.658014+00:00 [failed]> in state failed
[2024-10-02T20:01:31.333+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 7.730 seconds
[2024-10-02T20:02:01.405+0000] {processor.py:186} INFO - Started process (PID=118297) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:02:01.417+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:02:01.419+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:02:01.418+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:02:06.675+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:02:06.671+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 274, in warehouse
    step_1() >> step_2() >> step_3()
    ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 91, in step_1
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 20, in extract_transform
    SparkSubmitOperator(
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 124, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 949, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/helpers.py", line 53, in validate_key
    raise TypeError(f"The key has to be a string and is {type(k)}:{k}")
TypeError: The key has to be a string and is <class 'tuple'>:('categories', 'customers', 'customers_history')
[2024-10-02T20:02:06.677+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:02:06.702+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.303 seconds
[2024-10-02T20:02:37.329+0000] {processor.py:186} INFO - Started process (PID=118814) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:02:37.331+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:02:37.334+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:02:37.333+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:02:47.242+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:02:47.486+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:02:47.485+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T20:02:47.514+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:02:47.514+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T20:02:47.548+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 10.243 seconds
[2024-10-02T20:03:18.073+0000] {processor.py:186} INFO - Started process (PID=119192) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:03:18.075+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:03:18.077+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:03:18.077+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:03:29.886+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:03:30.233+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:03:30.232+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T20:03:30.288+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:03:30.287+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T20:03:30.347+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 12.286 seconds
[2024-10-02T20:04:00.854+0000] {processor.py:186} INFO - Started process (PID=119719) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:04:00.865+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:04:00.867+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:04:00.867+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:04:07.325+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:04:07.555+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:04:07.554+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T20:04:07.590+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:04:07.590+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T20:04:07.623+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.777 seconds
[2024-10-02T20:04:37.766+0000] {processor.py:186} INFO - Started process (PID=120072) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:04:37.767+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:04:37.769+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:04:37.768+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:04:44.076+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:04:44.336+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:04:44.334+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T20:04:44.377+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:04:44.376+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T20:04:44.418+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.659 seconds
[2024-10-02T20:05:14.950+0000] {processor.py:186} INFO - Started process (PID=120429) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:05:14.955+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:05:14.957+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:05:14.956+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:05:20.652+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:05:20.861+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:05:20.860+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T20:05:20.886+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:05:20.886+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T20:05:20.925+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.982 seconds
[2024-10-02T20:05:51.041+0000] {processor.py:186} INFO - Started process (PID=120802) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:05:51.043+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:05:51.044+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:05:51.044+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:05:56.416+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:05:56.690+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:05:56.689+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T20:05:56.726+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:05:56.725+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T20:05:56.759+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.724 seconds
[2024-10-02T20:06:27.042+0000] {processor.py:186} INFO - Started process (PID=121163) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:06:27.054+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:06:27.055+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:06:27.055+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:06:33.022+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:06:33.215+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:06:33.214+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T20:06:33.243+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:06:33.243+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T20:06:33.286+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.251 seconds
[2024-10-02T20:07:03.716+0000] {processor.py:186} INFO - Started process (PID=121518) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:07:03.718+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:07:03.719+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:07:03.719+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:07:11.716+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:07:11.944+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:07:11.943+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T20:07:11.972+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:07:11.972+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T20:07:12.000+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 8.292 seconds
[2024-10-02T20:07:42.334+0000] {processor.py:186} INFO - Started process (PID=121873) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:07:42.336+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:07:42.338+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:07:42.337+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:07:48.993+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:07:49.189+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:07:49.189+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T20:07:49.218+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:07:49.217+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T20:07:49.248+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.922 seconds
[2024-10-02T20:08:19.851+0000] {processor.py:186} INFO - Started process (PID=122228) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:08:19.853+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:08:19.854+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:08:19.854+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:08:25.970+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:08:26.241+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:08:26.240+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T20:08:26.276+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:08:26.276+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T20:08:26.327+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.484 seconds
[2024-10-02T20:08:56.772+0000] {processor.py:186} INFO - Started process (PID=122592) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:08:56.774+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:08:56.776+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:08:56.775+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:09:03.973+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:09:04.305+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:09:04.303+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T20:09:04.352+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:09:04.352+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T20:09:04.391+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 7.626 seconds
[2024-10-02T20:09:35.157+0000] {processor.py:186} INFO - Started process (PID=122960) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:09:35.169+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:09:35.171+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:09:35.171+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:09:42.670+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:09:42.924+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:09:42.923+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T20:09:42.961+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:09:42.961+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T20:09:42.996+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 7.846 seconds
[2024-10-02T20:10:13.292+0000] {processor.py:186} INFO - Started process (PID=123168) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:10:13.294+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:10:13.297+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:10:13.296+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:10:13.859+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:10:13.857+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 5, in <module>
    from etl_pipeline.tasks.warehouse.main import warehouse
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 4, in <module>
    from etl_pipeline.tasks.warehouse.components.extract_transform import ExtractTransform
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/components/extract_transform.py", line 4, in <module>
    from etl_pipeline.tasks.warehouse.components.extract import _extract
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/components/extract.py", line 25
    connection.commit()s
                       ^
SyntaxError: invalid syntax
[2024-10-02T20:10:13.859+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:10:13.889+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 0.605 seconds
[2024-10-02T20:10:43.931+0000] {processor.py:186} INFO - Started process (PID=123217) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:10:43.943+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:10:43.944+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:10:43.944+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:10:49.073+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:10:49.356+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:10:49.355+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T20:10:49.400+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:10:49.400+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T20:10:49.448+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.524 seconds
[2024-10-02T20:11:19.591+0000] {processor.py:186} INFO - Started process (PID=123569) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:11:19.594+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:11:19.596+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:11:19.595+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:11:25.794+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:11:26.099+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:11:26.099+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T20:11:26.130+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:11:26.130+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T20:11:26.166+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.583 seconds
[2024-10-02T20:11:56.704+0000] {processor.py:186} INFO - Started process (PID=123932) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:11:56.706+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:11:56.708+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:11:56.707+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:12:04.548+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:12:04.905+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:12:04.904+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T20:12:04.957+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:12:04.956+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T20:12:05.020+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 8.323 seconds
[2024-10-02T20:12:35.094+0000] {processor.py:186} INFO - Started process (PID=124297) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:12:35.106+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:12:35.108+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:12:35.107+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:12:42.051+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:12:42.337+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:12:42.336+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T20:12:42.381+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:12:42.380+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T20:12:42.423+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 7.336 seconds
[2024-10-02T20:13:12.962+0000] {processor.py:186} INFO - Started process (PID=124669) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:13:12.965+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:13:12.967+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:13:12.967+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:13:24.036+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:13:24.522+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:13:24.521+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T20:13:24.588+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:13:24.587+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T20:13:24.645+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 11.695 seconds
[2024-10-02T20:13:55.082+0000] {processor.py:186} INFO - Started process (PID=125178) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:13:55.094+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:13:55.095+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:13:55.095+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:14:01.823+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:14:02.261+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:14:02.259+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T20:14:02.319+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:14:02.319+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T20:14:02.438+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 7.363 seconds
[2024-10-02T20:14:33.276+0000] {processor.py:186} INFO - Started process (PID=125704) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:14:33.277+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:14:33.279+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:14:33.278+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:14:38.696+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:14:38.781+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:14:38.780+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T20:14:38.815+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:14:38.814+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T20:14:38.839+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.570 seconds
[2024-10-02T20:15:09.052+0000] {processor.py:186} INFO - Started process (PID=126071) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:15:09.064+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:15:09.068+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:15:09.067+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:15:16.121+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:15:16.220+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:15:16.220+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T20:15:16.255+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:15:16.255+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T20:15:16.298+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 7.256 seconds
[2024-10-02T20:15:46.367+0000] {processor.py:186} INFO - Started process (PID=126434) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:15:46.368+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:15:46.370+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:15:46.370+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:15:55.500+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:15:55.718+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:15:55.717+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T20:15:55.750+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:15:55.750+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T20:15:55.790+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 9.437 seconds
[2024-10-02T20:16:26.497+0000] {processor.py:186} INFO - Started process (PID=126793) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:16:26.510+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:16:26.511+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:16:26.511+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:16:31.706+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:16:31.912+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:16:31.912+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T20:16:31.938+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:16:31.938+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T20:16:31.976+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.485 seconds
[2024-10-02T20:17:02.342+0000] {processor.py:186} INFO - Started process (PID=127152) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:17:02.356+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:17:02.358+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:17:02.358+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:17:09.052+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:17:09.419+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:17:09.419+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T20:17:09.460+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:17:09.460+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T20:17:09.499+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 7.166 seconds
[2024-10-02T20:17:39.792+0000] {processor.py:186} INFO - Started process (PID=127666) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:17:39.804+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:17:39.806+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:17:39.805+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:17:45.748+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:17:45.961+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:17:45.960+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T20:17:45.990+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:17:45.990+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T20:17:46.019+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.234 seconds
[2024-10-02T20:18:16.425+0000] {processor.py:186} INFO - Started process (PID=128023) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:18:16.431+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:18:16.433+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:18:16.433+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:18:24.218+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:18:24.472+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:18:24.471+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T20:18:24.500+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:18:24.500+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T20:18:24.528+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 8.111 seconds
[2024-10-02T20:18:54.761+0000] {processor.py:186} INFO - Started process (PID=128387) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:18:54.763+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:18:54.765+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:18:54.764+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:19:01.448+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:19:01.637+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:19:01.637+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T20:19:01.666+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:19:01.665+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T20:19:01.695+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.943 seconds
[2024-10-02T20:19:32.309+0000] {processor.py:186} INFO - Started process (PID=128753) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:19:32.321+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:19:32.322+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:19:32.322+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:19:39.213+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:19:39.487+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:19:39.487+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-10-02T20:19:39.523+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:19:39.522+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2024-10-02 00:00:00+00:00, run_after=2024-10-03 00:00:00+00:00
[2024-10-02T20:19:39.562+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 7.260 seconds
[2024-10-02T20:20:10.011+0000] {processor.py:186} INFO - Started process (PID=129276) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:20:10.012+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:20:10.015+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:20:10.014+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:20:19.868+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:20:19.864+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:20:19.870+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:20:19.894+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 9.891 seconds
[2024-10-02T20:20:45.789+0000] {processor.py:186} INFO - Started process (PID=129944) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:20:45.794+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:20:45.798+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:20:45.797+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:20:55.346+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:20:55.342+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:20:55.347+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:20:55.432+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:20:55.431+0000] {taskinstance.py:3312} ERROR - Executor LocalExecutor(parallelism=32) reported that the task instance <TaskInstance: etl_pipeline.warehouse.step_1.extract_transform.categories manual__2024-10-02T17:10:54.658014+00:00 [queued]> finished with state failed, but the task instance's state attribute is queued. Learn more: https://airflow.apache.org/docs/apache-airflow/stable/troubleshooting.html#task-state-changed-externally
[2024-10-02T20:20:55.472+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:20:55.472+0000] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=etl_pipeline, task_id=warehouse.step_1.extract_transform.categories, run_id=manual__2024-10-02T17:10:54.658014+00:00, execution_date=20241002T171054, start_date=20241002T202003, end_date=20241002T202055
[2024-10-02T20:20:55.473+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:20:55.473+0000] {taskinstance.py:1563} INFO - Executing callback at index 0: str
[2024-10-02T20:20:55.473+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:20:55.473+0000] {taskinstance.py:1567} ERROR - Error in callback at index 0: str
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 1565, in _run_finished_callback
    callback(context)
TypeError: 'str' object is not callable
[2024-10-02T20:20:55.494+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:20:55.493+0000] {processor.py:876} INFO - Executed callback for <TaskInstance: etl_pipeline.warehouse.step_1.extract_transform.categories manual__2024-10-02T17:10:54.658014+00:00 [failed]> in state failed
[2024-10-02T20:20:55.494+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 9.724 seconds
[2024-10-02T20:21:25.624+0000] {processor.py:186} INFO - Started process (PID=130309) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:21:25.636+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:21:25.638+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:21:25.637+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:21:31.827+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:21:31.822+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:21:31.829+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:21:31.846+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.229 seconds
[2024-10-02T20:22:02.316+0000] {processor.py:186} INFO - Started process (PID=130666) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:22:02.318+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:22:02.323+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:22:02.321+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:22:09.961+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:22:09.957+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:22:09.963+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:22:09.976+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 7.671 seconds
[2024-10-02T20:22:40.061+0000] {processor.py:186} INFO - Started process (PID=131043) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:22:40.062+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:22:40.064+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:22:40.063+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:22:48.545+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:22:48.538+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:22:48.548+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:22:48.577+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 8.526 seconds
[2024-10-02T20:23:18.737+0000] {processor.py:186} INFO - Started process (PID=131403) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:23:18.759+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:23:18.762+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:23:18.762+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:23:27.776+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:23:27.770+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:23:27.781+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:23:27.808+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 9.082 seconds
[2024-10-02T20:23:57.994+0000] {processor.py:186} INFO - Started process (PID=131768) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:23:57.996+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:23:57.998+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:23:57.997+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:24:06.189+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:24:06.183+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:24:06.191+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:24:06.210+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 8.224 seconds
[2024-10-02T20:24:36.463+0000] {processor.py:186} INFO - Started process (PID=132126) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:24:36.482+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:24:36.485+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:24:36.485+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:24:46.263+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:24:46.258+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:24:46.265+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:24:46.279+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 9.836 seconds
[2024-10-02T20:25:16.356+0000] {processor.py:186} INFO - Started process (PID=132504) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:25:16.357+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:25:16.359+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:25:16.358+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:25:22.414+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:25:22.410+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:25:22.416+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:25:22.431+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.081 seconds
[2024-10-02T20:25:53.210+0000] {processor.py:186} INFO - Started process (PID=132853) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:25:53.221+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:25:53.223+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:25:53.222+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:25:58.252+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:25:58.248+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:25:58.254+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:25:58.281+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.077 seconds
[2024-10-02T20:26:28.487+0000] {processor.py:186} INFO - Started process (PID=133208) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:26:28.488+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:26:28.489+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:26:28.489+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:26:33.893+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:26:33.887+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:26:33.896+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:26:33.926+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.446 seconds
[2024-10-02T20:27:04.142+0000] {processor.py:186} INFO - Started process (PID=133563) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:27:04.143+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:27:04.145+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:27:04.145+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:27:13.513+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:27:13.448+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:27:13.518+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:27:13.586+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 9.453 seconds
[2024-10-02T20:27:43.824+0000] {processor.py:186} INFO - Started process (PID=133928) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:27:43.836+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:27:43.837+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:27:43.837+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:27:49.743+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:27:49.739+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:27:49.745+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:27:49.761+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.945 seconds
[2024-10-02T20:28:20.607+0000] {processor.py:186} INFO - Started process (PID=134284) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:28:20.608+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:28:20.609+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:28:20.609+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:28:26.238+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:28:26.231+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:28:26.241+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:28:26.257+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.659 seconds
[2024-10-02T20:28:56.695+0000] {processor.py:186} INFO - Started process (PID=134644) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:28:56.696+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:28:56.697+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:28:56.697+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:29:02.366+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:29:02.363+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:29:02.369+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:29:02.397+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.708 seconds
[2024-10-02T20:29:32.484+0000] {processor.py:186} INFO - Started process (PID=134997) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:29:32.484+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:29:32.486+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:29:32.486+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:29:37.836+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:29:37.832+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:29:37.838+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:29:37.861+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.384 seconds
[2024-10-02T20:30:08.845+0000] {processor.py:186} INFO - Started process (PID=135350) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:30:08.847+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:30:08.850+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:30:08.850+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:30:20.546+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:30:20.538+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:30:20.551+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:30:20.572+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 11.739 seconds
[2024-10-02T20:30:51.152+0000] {processor.py:186} INFO - Started process (PID=135735) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:30:51.153+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:30:51.154+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:30:51.154+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:31:01.231+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:31:01.225+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:31:01.234+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:31:01.266+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 10.124 seconds
[2024-10-02T20:31:31.536+0000] {processor.py:186} INFO - Started process (PID=136094) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:31:31.544+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:31:31.548+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:31:31.547+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:31:49.617+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:31:49.608+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:31:49.622+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:31:49.647+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 18.161 seconds
[2024-10-02T20:32:19.761+0000] {processor.py:186} INFO - Started process (PID=136476) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:32:19.763+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:32:19.765+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:32:19.764+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:32:25.201+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:32:25.197+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:32:25.202+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:32:25.227+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.473 seconds
[2024-10-02T20:32:56.100+0000] {processor.py:186} INFO - Started process (PID=136825) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:32:56.101+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:32:56.103+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:32:56.102+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:33:01.182+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:33:01.178+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:33:01.183+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:33:01.195+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.102 seconds
[2024-10-02T20:33:31.410+0000] {processor.py:186} INFO - Started process (PID=137169) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:33:31.422+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:33:31.425+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:33:31.424+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:33:36.268+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:33:36.264+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:33:36.269+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:33:36.283+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.880 seconds
[2024-10-02T20:34:06.900+0000] {processor.py:186} INFO - Started process (PID=137517) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:34:06.902+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:34:06.904+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:34:06.903+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:34:11.758+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:34:11.754+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:34:11.760+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:34:11.785+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.891 seconds
[2024-10-02T20:34:42.261+0000] {processor.py:186} INFO - Started process (PID=137862) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:34:42.263+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:34:42.265+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:34:42.264+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:34:47.517+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:34:47.513+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:34:47.519+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:34:47.542+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.289 seconds
[2024-10-02T20:35:17.964+0000] {processor.py:186} INFO - Started process (PID=138225) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:35:17.965+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:35:17.966+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:35:17.966+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:35:23.661+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:35:23.657+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:35:23.663+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:35:23.676+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.719 seconds
[2024-10-02T20:35:53.827+0000] {processor.py:186} INFO - Started process (PID=138588) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:35:53.839+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:35:53.841+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:35:53.840+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:35:59.098+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:35:59.092+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:35:59.100+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:35:59.113+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.293 seconds
[2024-10-02T20:36:29.479+0000] {processor.py:186} INFO - Started process (PID=138939) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:36:29.492+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:36:29.494+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:36:29.493+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:36:34.873+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:36:34.868+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:36:34.875+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:36:34.898+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.426 seconds
[2024-10-02T20:37:05.652+0000] {processor.py:186} INFO - Started process (PID=139286) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:37:05.653+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:37:05.656+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:37:05.655+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:37:10.357+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:37:10.353+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:37:10.358+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:37:10.383+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.738 seconds
[2024-10-02T20:37:41.037+0000] {processor.py:186} INFO - Started process (PID=139635) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:37:41.038+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:37:41.040+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:37:41.039+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:37:46.243+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:37:46.239+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:37:46.244+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:37:46.267+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.239 seconds
[2024-10-02T20:38:16.557+0000] {processor.py:186} INFO - Started process (PID=139986) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:38:16.569+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:38:16.571+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:38:16.571+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:38:21.348+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:38:21.343+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:38:21.350+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:38:21.364+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.813 seconds
[2024-10-02T20:38:52.071+0000] {processor.py:186} INFO - Started process (PID=140340) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:38:52.073+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:38:52.075+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:38:52.074+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:38:57.583+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:38:57.579+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:38:57.584+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:38:57.609+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.545 seconds
[2024-10-02T20:39:28.154+0000] {processor.py:186} INFO - Started process (PID=140718) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:39:28.156+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:39:28.158+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:39:28.157+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:39:33.372+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:39:33.368+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:39:33.374+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:39:33.397+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.251 seconds
[2024-10-02T20:40:03.976+0000] {processor.py:186} INFO - Started process (PID=141070) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:40:03.988+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:40:03.990+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:40:03.989+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:40:08.933+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:40:08.929+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:40:08.935+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:40:08.948+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.980 seconds
[2024-10-02T20:40:39.019+0000] {processor.py:186} INFO - Started process (PID=141419) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:40:39.032+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:40:39.033+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:40:39.033+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:40:43.891+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:40:43.887+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:40:43.892+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:40:43.916+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.906 seconds
[2024-10-02T20:41:13.970+0000] {processor.py:186} INFO - Started process (PID=141768) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:41:13.972+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:41:13.973+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:41:13.973+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:41:19.567+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:41:19.563+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:41:19.569+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:41:19.583+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.619 seconds
[2024-10-02T20:41:49.976+0000] {processor.py:186} INFO - Started process (PID=142120) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:41:49.988+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:41:49.989+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:41:49.989+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:41:55.001+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:41:54.997+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:41:55.003+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:41:55.016+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.048 seconds
[2024-10-02T20:42:25.337+0000] {processor.py:186} INFO - Started process (PID=142473) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:42:25.339+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:42:25.340+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:42:25.340+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:42:30.389+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:42:30.384+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:42:30.391+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:42:30.406+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.075 seconds
[2024-10-02T20:43:01.017+0000] {processor.py:186} INFO - Started process (PID=142833) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:43:01.019+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:43:01.020+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:43:01.020+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:43:06.246+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:43:06.241+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:43:06.248+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:43:06.264+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.253 seconds
[2024-10-02T20:43:36.393+0000] {processor.py:186} INFO - Started process (PID=143200) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:43:36.394+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:43:36.396+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:43:36.395+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:43:41.695+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:43:41.692+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:43:41.697+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:43:41.709+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.323 seconds
[2024-10-02T20:44:12.366+0000] {processor.py:186} INFO - Started process (PID=143556) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:44:12.379+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:44:12.380+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:44:12.380+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:44:17.474+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:44:17.471+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:44:17.476+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:44:17.500+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.140 seconds
[2024-10-02T20:44:47.770+0000] {processor.py:186} INFO - Started process (PID=143908) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:44:47.771+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:44:47.773+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:44:47.772+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:44:52.704+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:44:52.701+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:44:52.706+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:44:52.731+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.969 seconds
[2024-10-02T20:45:23.071+0000] {processor.py:186} INFO - Started process (PID=144257) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:45:23.083+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:45:23.085+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:45:23.084+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:45:28.164+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:45:28.160+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:45:28.166+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:45:28.189+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.124 seconds
[2024-10-02T20:45:58.789+0000] {processor.py:186} INFO - Started process (PID=144614) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:45:58.790+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:45:58.792+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:45:58.792+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:46:03.943+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:46:03.940+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:46:03.945+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:46:03.958+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.176 seconds
[2024-10-02T20:46:34.288+0000] {processor.py:186} INFO - Started process (PID=144972) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:46:34.290+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:46:34.292+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:46:34.291+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:46:39.929+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:46:39.926+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:46:39.931+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:46:39.944+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.662 seconds
[2024-10-02T20:47:10.103+0000] {processor.py:186} INFO - Started process (PID=145334) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:47:10.115+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:47:10.117+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:47:10.116+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:47:15.913+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:47:15.903+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:47:15.915+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:47:15.930+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.834 seconds
[2024-10-02T20:47:46.277+0000] {processor.py:186} INFO - Started process (PID=145689) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:47:46.289+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:47:46.291+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:47:46.290+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:47:51.966+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:47:51.962+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:47:51.968+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:47:51.983+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.713 seconds
[2024-10-02T20:48:22.868+0000] {processor.py:186} INFO - Started process (PID=146044) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:48:22.870+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:48:22.872+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:48:22.871+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:48:27.973+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:48:27.969+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:48:27.975+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:48:27.989+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.128 seconds
[2024-10-02T20:48:58.634+0000] {processor.py:186} INFO - Started process (PID=146394) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:48:58.646+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:48:58.647+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:48:58.647+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:49:04.101+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:49:04.097+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:49:04.103+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:49:04.117+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.491 seconds
[2024-10-02T20:49:34.329+0000] {processor.py:186} INFO - Started process (PID=146750) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:49:34.331+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:49:34.332+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:49:34.332+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:49:39.762+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:49:39.758+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:49:39.764+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:49:39.780+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.458 seconds
[2024-10-02T20:50:09.851+0000] {processor.py:186} INFO - Started process (PID=147112) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:50:09.852+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:50:09.854+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:50:09.853+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:50:14.939+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:50:14.935+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:50:14.940+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:50:14.963+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.119 seconds
[2024-10-02T20:50:45.662+0000] {processor.py:186} INFO - Started process (PID=147465) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:50:45.674+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:50:45.676+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:50:45.676+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:50:50.618+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:50:50.613+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:50:50.621+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:50:50.634+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.980 seconds
[2024-10-02T20:51:21.153+0000] {processor.py:186} INFO - Started process (PID=147816) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:51:21.165+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:51:21.168+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:51:21.167+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:51:26.646+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:51:26.643+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:51:26.648+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:51:26.663+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.518 seconds
[2024-10-02T20:51:56.767+0000] {processor.py:186} INFO - Started process (PID=148182) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:51:56.769+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:51:56.770+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:51:56.770+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:52:02.154+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:52:02.150+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:52:02.155+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:52:02.179+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.418 seconds
[2024-10-02T20:52:32.731+0000] {processor.py:186} INFO - Started process (PID=148530) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:52:32.743+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:52:32.746+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:52:32.745+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:52:37.908+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:52:37.905+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:52:37.910+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:52:37.924+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.202 seconds
[2024-10-02T20:53:08.204+0000] {processor.py:186} INFO - Started process (PID=148886) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:53:08.208+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:53:08.210+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:53:08.209+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:53:13.413+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:53:13.409+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:53:13.415+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:53:13.431+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.235 seconds
[2024-10-02T20:53:43.719+0000] {processor.py:186} INFO - Started process (PID=149244) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:53:43.721+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:53:43.722+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:53:43.722+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:53:48.687+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:53:48.682+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:53:48.689+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:53:48.702+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.991 seconds
[2024-10-02T20:54:18.816+0000] {processor.py:186} INFO - Started process (PID=149598) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:54:18.818+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:54:18.820+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:54:18.820+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:54:24.133+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:54:24.129+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:54:24.135+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:54:24.149+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.341 seconds
[2024-10-02T20:54:54.417+0000] {processor.py:186} INFO - Started process (PID=149956) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:54:54.419+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:54:54.420+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:54:54.420+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:54:59.339+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:54:59.336+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:54:59.341+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:54:59.356+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.945 seconds
[2024-10-02T20:55:29.524+0000] {processor.py:186} INFO - Started process (PID=150306) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:55:29.525+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:55:29.527+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:55:29.526+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:55:34.943+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:55:34.933+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:55:34.946+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:55:34.960+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.443 seconds
[2024-10-02T20:56:05.021+0000] {processor.py:186} INFO - Started process (PID=150665) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:56:05.022+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:56:05.024+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:56:05.023+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:56:10.461+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:56:10.457+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:56:10.462+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:56:10.485+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.472 seconds
[2024-10-02T20:56:40.878+0000] {processor.py:186} INFO - Started process (PID=151026) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:56:40.889+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:56:40.890+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:56:40.890+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:56:46.694+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:56:46.690+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:56:46.697+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:56:46.722+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.852 seconds
[2024-10-02T20:57:17.539+0000] {processor.py:186} INFO - Started process (PID=151390) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:57:17.551+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:57:17.553+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:57:17.553+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:57:22.620+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:57:22.610+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:57:22.622+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:57:22.648+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.116 seconds
[2024-10-02T20:57:53.137+0000] {processor.py:186} INFO - Started process (PID=151741) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:57:53.139+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:57:53.141+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:57:53.141+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:57:58.393+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:57:58.389+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:57:58.395+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:57:58.407+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.277 seconds
[2024-10-02T20:58:28.512+0000] {processor.py:186} INFO - Started process (PID=152091) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:58:28.524+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:58:28.525+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:58:28.525+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:58:33.864+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:58:33.861+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:58:33.866+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:58:33.880+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.377 seconds
[2024-10-02T20:59:04.263+0000] {processor.py:186} INFO - Started process (PID=152450) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:59:04.275+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:59:04.277+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:59:04.276+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:59:09.298+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:59:09.294+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:59:09.299+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:59:09.322+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.067 seconds
[2024-10-02T20:59:39.783+0000] {processor.py:186} INFO - Started process (PID=152804) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:59:39.794+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T20:59:39.796+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:59:39.796+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:59:45.174+0000] {logging_mixin.py:190} INFO - [2024-10-02T20:59:45.170+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T20:59:45.176+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T20:59:45.192+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.415 seconds
[2024-10-02T21:00:15.746+0000] {processor.py:186} INFO - Started process (PID=153160) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:00:15.747+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:00:15.749+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:00:15.748+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:00:20.909+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:00:20.905+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:00:20.911+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:00:20.926+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.188 seconds
[2024-10-02T21:00:51.402+0000] {processor.py:186} INFO - Started process (PID=153532) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:00:51.414+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:00:51.416+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:00:51.415+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:00:56.968+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:00:56.965+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:00:56.970+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:00:56.992+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.597 seconds
[2024-10-02T21:01:27.631+0000] {processor.py:186} INFO - Started process (PID=153882) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:01:27.643+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:01:27.645+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:01:27.644+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:01:33.090+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:01:33.086+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:01:33.091+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:01:33.115+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.492 seconds
[2024-10-02T21:02:03.187+0000] {processor.py:186} INFO - Started process (PID=154230) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:02:03.189+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:02:03.190+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:02:03.190+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:02:08.227+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:02:08.223+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:02:08.229+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:02:08.253+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.073 seconds
[2024-10-02T21:02:38.514+0000] {processor.py:186} INFO - Started process (PID=154586) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:02:38.516+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:02:38.518+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:02:38.517+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:02:43.579+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:02:43.574+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:02:43.581+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:02:43.605+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.098 seconds
[2024-10-02T21:03:14.213+0000] {processor.py:186} INFO - Started process (PID=154934) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:03:14.226+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:03:14.227+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:03:14.227+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:03:19.373+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:03:19.370+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:03:19.375+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:03:19.387+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.181 seconds
[2024-10-02T21:03:49.889+0000] {processor.py:186} INFO - Started process (PID=155300) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:03:49.890+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:03:49.892+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:03:49.891+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:03:54.965+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:03:54.961+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:03:54.967+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:03:54.981+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.098 seconds
[2024-10-02T21:04:25.725+0000] {processor.py:186} INFO - Started process (PID=155660) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:04:25.736+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:04:25.738+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:04:25.738+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:04:30.914+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:04:30.910+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:04:30.916+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:04:30.940+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.225 seconds
[2024-10-02T21:05:01.257+0000] {processor.py:186} INFO - Started process (PID=156015) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:05:01.259+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:05:01.260+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:05:01.260+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:05:06.087+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:05:06.082+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:05:06.090+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:05:06.119+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.870 seconds
[2024-10-02T21:05:36.431+0000] {processor.py:186} INFO - Started process (PID=156367) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:05:36.442+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:05:36.444+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:05:36.443+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:05:41.979+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:05:41.975+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:05:41.980+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:05:42.004+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.581 seconds
[2024-10-02T21:06:12.827+0000] {processor.py:186} INFO - Started process (PID=156722) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:06:12.830+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:06:12.831+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:06:12.831+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:06:17.876+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:06:17.872+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:06:17.877+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:06:17.900+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.080 seconds
[2024-10-02T21:06:48.460+0000] {processor.py:186} INFO - Started process (PID=157072) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:06:48.472+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:06:48.474+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:06:48.473+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:06:53.105+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:06:53.099+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:06:53.107+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:06:53.131+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.677 seconds
[2024-10-02T21:07:23.412+0000] {processor.py:186} INFO - Started process (PID=157423) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:07:23.416+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:07:23.417+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:07:23.417+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:07:28.746+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:07:28.742+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:07:28.748+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:07:28.772+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.369 seconds
[2024-10-02T21:07:58.898+0000] {processor.py:186} INFO - Started process (PID=157795) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:07:58.911+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:07:58.912+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:07:58.912+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:08:03.689+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:08:03.685+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:08:03.690+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:08:03.715+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.824 seconds
[2024-10-02T21:08:34.078+0000] {processor.py:186} INFO - Started process (PID=158145) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:08:34.079+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:08:34.081+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:08:34.080+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:08:39.238+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:08:39.234+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:08:39.239+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:08:39.254+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.183 seconds
[2024-10-02T21:09:09.933+0000] {processor.py:186} INFO - Started process (PID=158499) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:09:09.935+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:09:09.937+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:09:09.937+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:09:14.725+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:09:14.720+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:09:14.727+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:09:14.743+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.817 seconds
[2024-10-02T21:09:45.108+0000] {processor.py:186} INFO - Started process (PID=158849) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:09:45.109+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:09:45.111+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:09:45.110+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:09:50.220+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:09:50.217+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:09:50.222+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:09:50.236+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.135 seconds
[2024-10-02T21:10:20.571+0000] {processor.py:186} INFO - Started process (PID=159207) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:10:20.583+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:10:20.585+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:10:20.585+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:10:25.682+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:10:25.676+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:10:25.685+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:10:25.701+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.136 seconds
[2024-10-02T21:10:56.467+0000] {processor.py:186} INFO - Started process (PID=159560) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:10:56.468+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:10:56.470+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:10:56.469+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:11:01.834+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:11:01.831+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:11:01.836+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:11:01.859+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.399 seconds
[2024-10-02T21:11:32.254+0000] {processor.py:186} INFO - Started process (PID=159927) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:11:32.256+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:11:32.258+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:11:32.258+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:11:37.561+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:11:37.558+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:11:37.563+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:11:37.586+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.342 seconds
[2024-10-02T21:12:08.408+0000] {processor.py:186} INFO - Started process (PID=160278) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:12:08.421+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:12:08.422+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:12:08.422+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:12:13.795+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:12:13.792+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:12:13.797+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:12:13.822+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.421 seconds
[2024-10-02T21:12:43.910+0000] {processor.py:186} INFO - Started process (PID=160635) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:12:43.922+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:12:43.924+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:12:43.924+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:12:49.017+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:12:49.014+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:12:49.019+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:12:49.042+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.139 seconds
[2024-10-02T21:13:19.663+0000] {processor.py:186} INFO - Started process (PID=160990) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:13:19.665+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:13:19.667+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:13:19.666+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:13:24.651+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:13:24.648+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:13:24.653+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:13:24.678+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.024 seconds
[2024-10-02T21:13:54.833+0000] {processor.py:186} INFO - Started process (PID=161338) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:13:54.835+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:13:54.836+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:13:54.836+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:14:00.061+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:14:00.055+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:14:00.064+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:14:00.090+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.265 seconds
[2024-10-02T21:14:30.865+0000] {processor.py:186} INFO - Started process (PID=161699) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:14:30.877+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:14:30.879+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:14:30.878+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:14:35.808+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:14:35.804+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:14:35.810+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:14:35.832+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.975 seconds
[2024-10-02T21:15:06.590+0000] {processor.py:186} INFO - Started process (PID=162061) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:15:06.592+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:15:06.594+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:15:06.593+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:15:11.479+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:15:11.475+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:15:11.480+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:15:11.502+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.921 seconds
[2024-10-02T21:15:42.017+0000] {processor.py:186} INFO - Started process (PID=162411) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:15:42.029+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:15:42.032+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:15:42.031+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:15:47.023+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:15:47.020+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:15:47.025+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:15:47.042+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.033 seconds
[2024-10-02T21:16:17.296+0000] {processor.py:186} INFO - Started process (PID=162767) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:16:17.298+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:16:17.300+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:16:17.300+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:16:26.919+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:16:26.913+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:16:26.922+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:16:26.935+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 9.646 seconds
[2024-10-02T21:16:57.069+0000] {processor.py:186} INFO - Started process (PID=163132) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:16:57.081+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:16:57.083+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:16:57.082+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:17:02.493+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:17:02.489+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:17:02.495+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:17:02.520+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.458 seconds
[2024-10-02T21:17:32.634+0000] {processor.py:186} INFO - Started process (PID=163496) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:17:32.647+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:17:32.649+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:17:32.649+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:17:37.926+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:17:37.922+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:17:37.928+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:17:37.940+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.313 seconds
[2024-10-02T21:18:08.612+0000] {processor.py:186} INFO - Started process (PID=163862) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:18:08.614+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:18:08.616+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:18:08.615+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:18:13.323+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:18:13.320+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:18:13.325+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:18:13.338+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.733 seconds
[2024-10-02T21:18:44.304+0000] {processor.py:186} INFO - Started process (PID=164210) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:18:44.316+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:18:44.318+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:18:44.317+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:18:48.814+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:18:48.810+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:18:48.815+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:18:48.827+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.530 seconds
[2024-10-02T21:19:18.933+0000] {processor.py:186} INFO - Started process (PID=164559) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:19:18.934+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:19:18.936+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:19:18.936+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:19:23.584+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:19:23.580+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:19:23.586+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:19:23.609+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.683 seconds
[2024-10-02T21:19:54.324+0000] {processor.py:186} INFO - Started process (PID=164907) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:19:54.325+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:19:54.326+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:19:54.326+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:19:59.133+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:19:59.129+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:19:59.134+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:19:59.156+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.840 seconds
[2024-10-02T21:20:29.267+0000] {processor.py:186} INFO - Started process (PID=165257) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:20:29.279+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:20:29.281+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:20:29.281+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:20:35.078+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:20:35.074+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:20:35.080+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:20:35.093+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.833 seconds
[2024-10-02T21:21:05.329+0000] {processor.py:186} INFO - Started process (PID=165620) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:21:05.330+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:21:05.332+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:21:05.331+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:21:10.414+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:21:10.410+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:21:10.415+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:21:10.428+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.106 seconds
[2024-10-02T21:21:41.138+0000] {processor.py:186} INFO - Started process (PID=165993) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:21:41.150+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:21:41.152+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:21:41.151+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:21:46.168+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:21:46.164+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:21:46.169+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:21:46.192+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.062 seconds
[2024-10-02T21:22:16.487+0000] {processor.py:186} INFO - Started process (PID=166342) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:22:16.488+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:22:16.490+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:22:16.489+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:22:21.950+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:22:21.946+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:22:21.951+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:22:21.976+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.496 seconds
[2024-10-02T21:22:52.070+0000] {processor.py:186} INFO - Started process (PID=166695) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:22:52.072+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:22:52.073+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:22:52.073+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:22:56.672+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:22:56.669+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:22:56.674+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:22:56.697+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.634 seconds
[2024-10-02T21:23:27.117+0000] {processor.py:186} INFO - Started process (PID=167042) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:23:27.119+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:23:27.121+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:23:27.120+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:23:31.796+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:23:31.792+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:23:31.798+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:23:31.850+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.740 seconds
[2024-10-02T21:24:02.251+0000] {processor.py:186} INFO - Started process (PID=167394) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:24:02.252+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:24:02.254+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:24:02.254+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:24:06.902+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:24:06.898+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:24:06.904+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:24:06.917+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.673 seconds
[2024-10-02T21:24:37.140+0000] {processor.py:186} INFO - Started process (PID=167744) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:24:37.152+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:24:37.154+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:24:37.153+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:24:42.560+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:24:42.557+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:24:42.562+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:24:42.585+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.452 seconds
[2024-10-02T21:25:12.700+0000] {processor.py:186} INFO - Started process (PID=168110) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:25:12.712+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:25:12.714+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:25:12.713+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:25:18.211+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:25:18.207+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:25:18.213+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:25:18.239+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.546 seconds
[2024-10-02T21:25:48.759+0000] {processor.py:186} INFO - Started process (PID=168484) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:25:48.771+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:25:48.774+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:25:48.773+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:25:54.159+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:25:54.155+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:25:54.161+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:25:54.176+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.426 seconds
[2024-10-02T21:26:24.720+0000] {processor.py:186} INFO - Started process (PID=168835) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:26:24.732+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:26:24.733+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:26:24.733+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:26:29.572+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:26:29.568+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:26:29.574+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:26:29.597+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.885 seconds
[2024-10-02T21:26:59.771+0000] {processor.py:186} INFO - Started process (PID=169183) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:26:59.783+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:26:59.785+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:26:59.784+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:27:04.562+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:27:04.558+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:27:04.564+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:27:04.577+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.813 seconds
[2024-10-02T21:27:35.304+0000] {processor.py:186} INFO - Started process (PID=169531) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:27:35.315+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:27:35.317+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:27:35.317+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:27:40.196+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:27:40.191+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:27:40.199+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:27:40.212+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.916 seconds
[2024-10-02T21:28:10.504+0000] {processor.py:186} INFO - Started process (PID=169881) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:28:10.509+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:28:10.510+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:28:10.510+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:28:15.079+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:28:15.075+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:28:15.080+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:28:15.097+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.600 seconds
[2024-10-02T21:28:45.823+0000] {processor.py:186} INFO - Started process (PID=170237) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:28:45.825+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:28:45.826+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:28:45.826+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:28:50.588+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:28:50.583+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:28:50.590+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:28:50.605+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.790 seconds
[2024-10-02T21:29:20.817+0000] {processor.py:186} INFO - Started process (PID=170596) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:29:20.829+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:29:20.830+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:29:20.830+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:29:26.065+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:29:26.062+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:29:26.067+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:29:26.081+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.272 seconds
[2024-10-02T21:29:56.164+0000] {processor.py:186} INFO - Started process (PID=170956) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:29:56.176+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:29:56.177+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:29:56.177+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:30:01.339+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:30:01.335+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:30:01.341+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:30:01.355+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.198 seconds
[2024-10-02T21:30:31.529+0000] {processor.py:186} INFO - Started process (PID=171309) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:30:31.541+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:30:31.543+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:30:31.542+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:30:36.546+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:30:36.541+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:30:36.548+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:30:36.572+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.049 seconds
[2024-10-02T21:31:06.814+0000] {processor.py:186} INFO - Started process (PID=171659) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:31:06.826+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:31:06.828+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:31:06.827+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:31:11.828+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:31:11.824+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:31:11.830+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:31:11.852+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.045 seconds
[2024-10-02T21:31:42.451+0000] {processor.py:186} INFO - Started process (PID=172007) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:31:42.453+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:31:42.454+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:31:42.454+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:31:47.435+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:31:47.432+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:31:47.437+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:31:47.450+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.005 seconds
[2024-10-02T21:32:18.338+0000] {processor.py:186} INFO - Started process (PID=172368) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:32:18.345+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:32:18.347+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:32:18.346+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:32:23.271+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:32:23.268+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:32:23.273+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:32:23.297+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.967 seconds
[2024-10-02T21:32:53.528+0000] {processor.py:186} INFO - Started process (PID=172722) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:32:53.540+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:32:53.541+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:32:53.541+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:32:58.201+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:32:58.197+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:32:58.203+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:32:58.217+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.697 seconds
[2024-10-02T21:33:28.311+0000] {processor.py:186} INFO - Started process (PID=173074) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:33:28.313+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:33:28.314+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:33:28.314+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:33:33.504+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:33:33.501+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:33:33.506+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:33:33.520+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.215 seconds
[2024-10-02T21:34:03.787+0000] {processor.py:186} INFO - Started process (PID=173433) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:34:03.799+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:34:03.801+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:34:03.800+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:34:08.897+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:34:08.894+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:34:08.898+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:34:08.911+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.132 seconds
[2024-10-02T21:34:39.063+0000] {processor.py:186} INFO - Started process (PID=173787) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:34:39.064+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:34:39.065+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:34:39.065+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:34:44.281+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:34:44.276+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:34:44.283+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:34:44.296+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.240 seconds
[2024-10-02T21:35:14.928+0000] {processor.py:186} INFO - Started process (PID=174137) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:35:14.940+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:35:14.941+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:35:14.941+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:35:19.874+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:35:19.870+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:35:19.876+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:35:19.900+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.980 seconds
[2024-10-02T21:35:50.007+0000] {processor.py:186} INFO - Started process (PID=174494) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:35:50.008+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:35:50.010+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:35:50.009+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:35:55.136+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:35:55.132+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:35:55.138+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:35:55.151+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.153 seconds
[2024-10-02T21:36:25.701+0000] {processor.py:186} INFO - Started process (PID=174847) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:36:25.702+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:36:25.704+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:36:25.704+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:36:30.533+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:36:30.529+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:36:30.534+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:36:30.547+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.853 seconds
[2024-10-02T21:37:00.817+0000] {processor.py:186} INFO - Started process (PID=175203) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:37:00.819+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:37:00.820+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:37:00.820+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:37:05.520+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:37:05.515+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:37:05.523+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:37:05.545+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.735 seconds
[2024-10-02T21:37:36.041+0000] {processor.py:186} INFO - Started process (PID=175553) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:37:36.042+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:37:36.043+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:37:36.043+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:37:41.231+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:37:41.227+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:37:41.233+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:37:41.248+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.214 seconds
[2024-10-02T21:38:11.389+0000] {processor.py:186} INFO - Started process (PID=175905) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:38:11.391+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:38:11.392+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:38:11.392+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:38:16.553+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:38:16.550+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:38:16.554+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:38:16.567+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.186 seconds
[2024-10-02T21:38:47.001+0000] {processor.py:186} INFO - Started process (PID=176264) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:38:47.003+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:38:47.005+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:38:47.004+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:38:51.786+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:38:51.779+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:38:51.788+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:38:51.813+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.819 seconds
[2024-10-02T21:39:22.295+0000] {processor.py:186} INFO - Started process (PID=176614) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:39:22.296+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:39:22.298+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:39:22.298+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:39:27.424+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:39:27.420+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:39:27.425+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:39:27.439+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.152 seconds
[2024-10-02T21:39:57.661+0000] {processor.py:186} INFO - Started process (PID=176979) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:39:57.664+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:39:57.666+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:39:57.665+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:40:02.566+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:40:02.562+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:40:02.568+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:40:02.584+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.931 seconds
[2024-10-02T21:40:33.085+0000] {processor.py:186} INFO - Started process (PID=177330) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:40:33.092+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:40:33.094+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:40:33.094+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:40:40.161+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:40:40.155+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:40:40.163+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:40:40.178+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 7.100 seconds
[2024-10-02T21:41:10.470+0000] {processor.py:186} INFO - Started process (PID=177688) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:41:10.472+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:41:10.474+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:41:10.474+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:41:15.307+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:41:15.303+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:41:15.309+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:41:15.331+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.868 seconds
[2024-10-02T21:41:46.316+0000] {processor.py:186} INFO - Started process (PID=178038) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:41:46.328+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:41:46.330+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:41:46.329+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:41:51.615+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:41:51.611+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:41:51.617+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:41:51.641+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.332 seconds
[2024-10-02T21:42:21.756+0000] {processor.py:186} INFO - Started process (PID=178394) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:42:21.768+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:42:21.769+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:42:21.769+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:42:26.969+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:42:26.966+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:42:26.971+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:42:26.994+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.246 seconds
[2024-10-02T21:42:57.189+0000] {processor.py:186} INFO - Started process (PID=178763) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:42:57.202+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:42:57.203+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:42:57.203+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:43:02.318+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:43:02.314+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:43:02.319+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:43:02.343+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.161 seconds
[2024-10-02T21:43:32.643+0000] {processor.py:186} INFO - Started process (PID=179117) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:43:32.655+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:43:32.657+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:43:32.656+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:43:37.593+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:43:37.589+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:43:37.595+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:43:37.618+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.983 seconds
[2024-10-02T21:44:07.858+0000] {processor.py:186} INFO - Started process (PID=179465) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:44:07.871+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:44:07.872+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:44:07.872+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:44:12.840+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:44:12.834+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:44:12.843+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:44:12.864+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.013 seconds
[2024-10-02T21:44:43.392+0000] {processor.py:186} INFO - Started process (PID=179821) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:44:43.404+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:44:43.406+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:44:43.405+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:44:48.370+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:44:48.367+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:44:48.372+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:44:48.396+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.010 seconds
[2024-10-02T21:45:18.891+0000] {processor.py:186} INFO - Started process (PID=180172) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:45:18.893+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:45:18.895+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:45:18.895+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:45:23.630+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:45:23.626+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:45:23.632+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:45:23.646+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.762 seconds
[2024-10-02T21:45:54.095+0000] {processor.py:186} INFO - Started process (PID=180521) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:45:54.107+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:45:54.109+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:45:54.109+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:45:59.452+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:45:59.447+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:45:59.454+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:45:59.467+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.379 seconds
[2024-10-02T21:46:29.856+0000] {processor.py:186} INFO - Started process (PID=180886) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:46:29.868+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:46:29.869+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:46:29.869+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:46:35.368+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:46:35.364+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:46:35.371+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:46:35.397+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.548 seconds
[2024-10-02T21:47:05.761+0000] {processor.py:186} INFO - Started process (PID=181248) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:47:05.763+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:47:05.764+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:47:05.764+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:47:10.986+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:47:10.982+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:47:10.987+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:47:11.000+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.246 seconds
[2024-10-02T21:47:41.133+0000] {processor.py:186} INFO - Started process (PID=181602) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:47:41.134+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:47:41.135+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:47:41.135+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:47:46.281+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:47:46.277+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:47:46.283+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:47:46.296+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.171 seconds
[2024-10-02T21:48:16.426+0000] {processor.py:186} INFO - Started process (PID=181956) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:48:16.438+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:48:16.440+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:48:16.439+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:48:21.409+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:48:21.405+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:48:21.410+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:48:21.433+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.015 seconds
[2024-10-02T21:48:52.175+0000] {processor.py:186} INFO - Started process (PID=182307) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:48:52.176+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:48:52.178+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:48:52.177+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:48:57.020+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:48:57.017+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:48:57.022+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:48:57.044+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.878 seconds
[2024-10-02T21:49:27.349+0000] {processor.py:186} INFO - Started process (PID=182657) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:49:27.351+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:49:27.354+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:49:27.353+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:49:32.322+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:49:32.318+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:49:32.324+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:49:32.337+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.996 seconds
[2024-10-02T21:50:02.398+0000] {processor.py:186} INFO - Started process (PID=183015) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:50:02.399+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:50:02.400+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:50:02.400+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:50:07.168+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:50:07.164+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:50:07.170+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:50:07.185+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.794 seconds
[2024-10-02T21:50:37.580+0000] {processor.py:186} INFO - Started process (PID=183363) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:50:37.581+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:50:37.583+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:50:37.582+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:50:43.229+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:50:43.225+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:50:43.230+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:50:43.255+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.683 seconds
[2024-10-02T21:51:13.759+0000] {processor.py:186} INFO - Started process (PID=183731) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:51:13.761+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:51:13.763+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:51:13.762+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:51:19.099+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:51:19.095+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:51:19.101+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:51:19.124+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.372 seconds
[2024-10-02T21:51:49.295+0000] {processor.py:186} INFO - Started process (PID=184094) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:51:49.296+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:51:49.298+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:51:49.298+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:51:54.548+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:51:54.545+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:51:54.549+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:51:54.572+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.283 seconds
[2024-10-02T21:52:24.834+0000] {processor.py:186} INFO - Started process (PID=184444) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:52:24.835+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:52:24.837+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:52:24.836+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:52:30.307+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:52:30.303+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:52:30.309+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:52:30.322+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.496 seconds
[2024-10-02T21:53:01.141+0000] {processor.py:186} INFO - Started process (PID=184794) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:53:01.143+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:53:01.144+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:53:01.144+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:53:06.140+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:53:06.137+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:53:06.142+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:53:06.166+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.031 seconds
[2024-10-02T21:53:36.211+0000] {processor.py:186} INFO - Started process (PID=185151) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:53:36.213+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:53:36.214+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:53:36.214+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:53:41.239+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:53:41.234+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:53:41.241+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:53:41.258+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.054 seconds
[2024-10-02T21:54:12.183+0000] {processor.py:186} INFO - Started process (PID=185501) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:54:12.195+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:54:12.197+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:54:12.196+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:54:17.449+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:54:17.445+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:54:17.450+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:54:17.464+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.291 seconds
[2024-10-02T21:54:47.860+0000] {processor.py:186} INFO - Started process (PID=185862) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:54:47.862+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:54:47.864+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:54:47.864+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:54:52.833+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:54:52.830+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:54:52.835+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:54:52.854+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.002 seconds
[2024-10-02T21:55:23.153+0000] {processor.py:186} INFO - Started process (PID=186215) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:55:23.156+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:55:23.158+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:55:23.157+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:55:28.288+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:55:28.284+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:55:28.290+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:55:28.314+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.167 seconds
[2024-10-02T21:55:58.409+0000] {processor.py:186} INFO - Started process (PID=186574) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:55:58.410+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:55:58.413+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:55:58.412+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:56:03.383+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:56:03.380+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:56:03.386+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:56:03.412+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.011 seconds
[2024-10-02T21:56:33.716+0000] {processor.py:186} INFO - Started process (PID=186924) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:56:33.729+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:56:33.730+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:56:33.730+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:56:38.924+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:56:38.918+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:56:38.927+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:56:38.946+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.239 seconds
[2024-10-02T21:57:09.093+0000] {processor.py:186} INFO - Started process (PID=187276) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:57:09.099+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:57:09.100+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:57:09.100+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:57:13.988+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:57:13.984+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:57:13.989+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:57:14.014+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.928 seconds
[2024-10-02T21:57:44.501+0000] {processor.py:186} INFO - Started process (PID=187636) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:57:44.513+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:57:44.515+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:57:44.514+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:57:49.402+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:57:49.398+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:57:49.404+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:57:49.427+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.933 seconds
[2024-10-02T21:58:19.712+0000] {processor.py:186} INFO - Started process (PID=187989) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:58:19.724+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:58:19.726+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:58:19.725+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:58:24.822+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:58:24.818+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:58:24.824+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:58:24.838+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.134 seconds
[2024-10-02T21:58:55.257+0000] {processor.py:186} INFO - Started process (PID=188348) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:58:55.259+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:58:55.260+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:58:55.260+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:59:00.667+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:59:00.664+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:59:00.669+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:59:00.698+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.448 seconds
[2024-10-02T21:59:31.096+0000] {processor.py:186} INFO - Started process (PID=188711) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:59:31.109+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T21:59:31.110+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:59:31.110+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:59:36.418+0000] {logging_mixin.py:190} INFO - [2024-10-02T21:59:36.414+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T21:59:36.419+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T21:59:36.444+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.355 seconds
[2024-10-02T22:00:06.980+0000] {processor.py:186} INFO - Started process (PID=189066) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:00:06.982+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:00:06.983+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:00:06.983+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:00:12.030+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:00:12.026+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:00:12.032+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:00:12.057+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.084 seconds
[2024-10-02T22:00:42.495+0000] {processor.py:186} INFO - Started process (PID=189424) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:00:42.497+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:00:42.499+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:00:42.498+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:00:47.539+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:00:47.534+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:00:47.540+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:00:47.554+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.068 seconds
[2024-10-02T22:01:18.087+0000] {processor.py:186} INFO - Started process (PID=189784) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:01:18.100+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:01:18.101+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:01:18.101+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:01:22.828+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:01:22.825+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:01:22.830+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:01:22.854+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.774 seconds
[2024-10-02T22:01:53.293+0000] {processor.py:186} INFO - Started process (PID=190135) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:01:53.294+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:01:53.296+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:01:53.296+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:01:58.198+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:01:58.194+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:01:58.199+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:01:58.223+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.936 seconds
[2024-10-02T22:02:28.716+0000] {processor.py:186} INFO - Started process (PID=190484) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:02:28.718+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:02:28.719+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:02:28.719+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:02:33.892+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:02:33.888+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:02:33.894+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:02:33.907+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.200 seconds
[2024-10-02T22:03:04.557+0000] {processor.py:186} INFO - Started process (PID=190850) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:03:04.569+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:03:04.571+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:03:04.571+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:03:09.375+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:03:09.371+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:03:09.377+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:03:09.391+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.840 seconds
[2024-10-02T22:03:39.595+0000] {processor.py:186} INFO - Started process (PID=191197) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:03:39.607+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:03:39.609+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:03:39.608+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:03:44.641+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:03:44.636+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:03:44.644+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:03:44.659+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.071 seconds
[2024-10-02T22:04:14.922+0000] {processor.py:186} INFO - Started process (PID=191556) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:04:14.926+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:04:14.927+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:04:14.927+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:04:19.643+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:04:19.639+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:04:19.645+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:04:19.669+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.753 seconds
[2024-10-02T22:04:50.302+0000] {processor.py:186} INFO - Started process (PID=191910) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:04:50.315+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:04:50.316+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:04:50.316+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:04:55.057+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:04:55.052+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:04:55.058+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:04:55.083+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.790 seconds
[2024-10-02T22:05:25.758+0000] {processor.py:186} INFO - Started process (PID=192265) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:05:25.760+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:05:25.762+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:05:25.761+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:05:30.663+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:05:30.658+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:05:30.666+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:05:30.689+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.938 seconds
[2024-10-02T22:06:01.059+0000] {processor.py:186} INFO - Started process (PID=192615) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:06:01.061+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:06:01.062+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:06:01.062+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:06:06.146+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:06:06.142+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:06:06.148+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:06:06.171+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.120 seconds
[2024-10-02T22:06:36.854+0000] {processor.py:186} INFO - Started process (PID=192977) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:06:36.856+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:06:36.857+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:06:36.857+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:06:41.824+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:06:41.819+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:06:41.825+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:06:41.850+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.003 seconds
[2024-10-02T22:07:12.399+0000] {processor.py:186} INFO - Started process (PID=193333) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:07:12.411+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:07:12.413+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:07:12.412+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:07:17.240+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:07:17.237+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:07:17.242+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:07:17.267+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.875 seconds
[2024-10-02T22:07:47.415+0000] {processor.py:186} INFO - Started process (PID=193686) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:07:47.427+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:07:47.429+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:07:47.428+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:07:52.145+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:07:52.142+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:07:52.147+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:07:52.170+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.762 seconds
[2024-10-02T22:08:22.824+0000] {processor.py:186} INFO - Started process (PID=194040) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:08:22.836+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:08:22.838+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:08:22.837+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:08:27.789+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:08:27.785+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:08:27.790+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:08:27.805+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.992 seconds
[2024-10-02T22:08:58.050+0000] {processor.py:186} INFO - Started process (PID=194397) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:08:58.063+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:08:58.064+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:08:58.064+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:09:02.892+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:09:02.888+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:09:02.894+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:09:02.918+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.876 seconds
[2024-10-02T22:09:33.247+0000] {processor.py:186} INFO - Started process (PID=194744) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:09:33.259+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:09:33.260+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:09:33.260+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:09:38.344+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:09:38.340+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:09:38.345+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:09:38.359+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.120 seconds
[2024-10-02T22:10:08.456+0000] {processor.py:186} INFO - Started process (PID=195098) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:10:08.457+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:10:08.459+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:10:08.458+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:10:13.309+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:10:13.305+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:10:13.311+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:10:13.335+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.886 seconds
[2024-10-02T22:10:43.444+0000] {processor.py:186} INFO - Started process (PID=195452) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:10:43.456+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:10:43.457+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:10:43.457+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:10:48.805+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:10:48.801+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:10:48.807+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:10:48.822+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.385 seconds
[2024-10-02T22:11:18.884+0000] {processor.py:186} INFO - Started process (PID=195809) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:11:18.889+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:11:18.891+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:11:18.890+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:11:23.537+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:11:23.533+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:11:23.539+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:11:23.563+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.687 seconds
[2024-10-02T22:11:54.401+0000] {processor.py:186} INFO - Started process (PID=196167) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:11:54.402+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:11:54.404+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:11:54.404+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:11:59.341+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:11:59.336+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:11:59.342+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:11:59.368+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.973 seconds
[2024-10-02T22:12:29.812+0000] {processor.py:186} INFO - Started process (PID=196523) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:12:29.814+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:12:29.816+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:12:29.816+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:12:35.019+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:12:35.015+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:12:35.022+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:12:35.037+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.233 seconds
[2024-10-02T22:13:05.221+0000] {processor.py:186} INFO - Started process (PID=196880) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:13:05.223+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:13:05.224+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:13:05.224+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:13:09.868+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:13:09.865+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:13:09.870+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:13:09.896+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.682 seconds
[2024-10-02T22:13:40.362+0000] {processor.py:186} INFO - Started process (PID=197229) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:13:40.373+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:13:40.375+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:13:40.375+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:13:45.529+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:13:45.525+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:13:45.531+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:13:45.555+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.200 seconds
[2024-10-02T22:14:16.114+0000] {processor.py:186} INFO - Started process (PID=197585) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:14:16.134+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:14:16.136+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:14:16.135+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:14:21.113+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:14:21.109+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:14:21.114+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:14:21.218+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.111 seconds
[2024-10-02T22:14:51.519+0000] {processor.py:186} INFO - Started process (PID=197937) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:14:51.522+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:14:51.523+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:14:51.523+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:14:56.449+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:14:56.445+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:14:56.450+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:14:56.465+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.953 seconds
[2024-10-02T22:15:27.100+0000] {processor.py:186} INFO - Started process (PID=198303) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:15:27.102+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:15:27.103+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:15:27.103+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:15:32.082+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:15:32.078+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:15:32.084+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:15:32.109+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.015 seconds
[2024-10-02T22:16:02.587+0000] {processor.py:186} INFO - Started process (PID=198658) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:16:02.590+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:16:02.591+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:16:02.591+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:16:07.325+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:16:07.321+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:16:07.326+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:16:07.343+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.762 seconds
[2024-10-02T22:16:38.205+0000] {processor.py:186} INFO - Started process (PID=199007) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:16:38.206+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:16:38.207+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:16:38.207+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:16:43.550+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:16:43.546+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:16:43.552+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:16:43.567+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.370 seconds
[2024-10-02T22:17:14.608+0000] {processor.py:186} INFO - Started process (PID=199365) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:17:14.610+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:17:14.612+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:17:14.611+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:17:19.597+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:17:19.593+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:17:19.598+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:17:19.623+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.023 seconds
[2024-10-02T22:17:50.444+0000] {processor.py:186} INFO - Started process (PID=199720) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:17:50.456+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:17:50.458+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:17:50.457+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:17:55.510+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:17:55.506+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:17:55.512+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:17:55.526+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.089 seconds
[2024-10-02T22:18:25.866+0000] {processor.py:186} INFO - Started process (PID=200078) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:18:25.868+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:18:25.869+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:18:25.869+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:18:30.131+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:18:30.128+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:18:30.133+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:18:30.148+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.288 seconds
[2024-10-02T22:19:00.369+0000] {processor.py:186} INFO - Started process (PID=200432) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:19:00.381+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:19:00.383+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:19:00.382+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:19:05.128+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:19:05.124+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:19:05.129+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:19:05.150+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.789 seconds
[2024-10-02T22:19:35.418+0000] {processor.py:186} INFO - Started process (PID=200789) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:19:35.420+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:19:35.421+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:19:35.421+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:19:39.826+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:19:39.822+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:19:39.827+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:19:39.852+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.440 seconds
[2024-10-02T22:20:09.994+0000] {processor.py:186} INFO - Started process (PID=201136) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:20:09.996+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:20:09.998+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:20:09.997+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:20:14.214+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:20:14.210+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:20:14.216+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:20:14.229+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.242 seconds
[2024-10-02T22:20:44.405+0000] {processor.py:186} INFO - Started process (PID=201485) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:20:44.417+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:20:44.419+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:20:44.419+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:20:48.937+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:20:48.934+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:20:48.939+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:20:48.953+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.556 seconds
[2024-10-02T22:21:19.552+0000] {processor.py:186} INFO - Started process (PID=201842) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:21:19.554+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:21:19.555+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:21:19.555+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:21:24.110+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:21:24.107+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:21:24.112+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:21:24.135+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.591 seconds
[2024-10-02T22:21:54.759+0000] {processor.py:186} INFO - Started process (PID=202195) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:21:54.771+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:21:54.772+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:21:54.772+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:21:59.247+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:21:59.243+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:21:59.249+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:21:59.263+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.512 seconds
[2024-10-02T22:22:29.307+0000] {processor.py:186} INFO - Started process (PID=202553) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:22:29.319+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:22:29.322+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:22:29.321+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:22:33.993+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:22:33.990+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:22:33.995+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:22:34.009+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.707 seconds
[2024-10-02T22:23:04.920+0000] {processor.py:186} INFO - Started process (PID=202905) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:23:04.922+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:23:04.923+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:23:04.923+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:23:09.197+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:23:09.194+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:23:09.199+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:23:09.211+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.297 seconds
[2024-10-02T22:23:39.861+0000] {processor.py:186} INFO - Started process (PID=203257) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:23:39.874+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:23:39.875+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:23:39.875+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:23:44.243+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:23:44.239+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:23:44.245+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:23:44.267+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.414 seconds
[2024-10-02T22:24:14.639+0000] {processor.py:186} INFO - Started process (PID=203611) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:24:14.640+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:24:14.642+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:24:14.642+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:24:19.096+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:24:19.093+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:24:19.097+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:24:19.119+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.487 seconds
[2024-10-02T22:24:49.254+0000] {processor.py:186} INFO - Started process (PID=203959) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:24:49.257+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:24:49.258+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:24:49.258+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:24:53.700+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:24:53.697+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:24:53.702+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:24:53.726+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.478 seconds
[2024-10-02T22:25:23.812+0000] {processor.py:186} INFO - Started process (PID=204307) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:25:23.824+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:25:23.825+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:25:23.825+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:25:28.378+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:25:28.375+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:25:28.380+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:25:28.394+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.590 seconds
[2024-10-02T22:25:59.360+0000] {processor.py:186} INFO - Started process (PID=204668) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:25:59.361+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:25:59.363+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:25:59.362+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:26:04.017+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:26:04.013+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:26:04.018+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:26:04.222+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.869 seconds
[2024-10-02T22:26:34.509+0000] {processor.py:186} INFO - Started process (PID=205029) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:26:34.521+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:26:34.522+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:26:34.522+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:26:39.003+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:26:38.999+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:26:39.005+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:26:39.018+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.516 seconds
[2024-10-02T22:27:09.154+0000] {processor.py:186} INFO - Started process (PID=205381) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:27:09.156+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:27:09.157+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:27:09.157+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:27:13.411+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:27:13.408+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:27:13.413+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:27:13.426+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.279 seconds
[2024-10-02T22:27:43.772+0000] {processor.py:186} INFO - Started process (PID=205734) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:27:43.784+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:27:43.786+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:27:43.785+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:27:48.235+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:27:48.232+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:27:48.236+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:27:48.258+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.493 seconds
[2024-10-02T22:28:18.610+0000] {processor.py:186} INFO - Started process (PID=206082) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:28:18.611+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:28:18.612+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:28:18.612+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:28:23.580+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:28:23.577+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:28:23.581+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:28:23.605+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.002 seconds
[2024-10-02T22:28:54.071+0000] {processor.py:186} INFO - Started process (PID=206440) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:28:54.083+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:28:54.084+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:28:54.084+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:28:58.253+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:28:58.249+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:28:58.255+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:28:58.270+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.206 seconds
[2024-10-02T22:29:29.244+0000] {processor.py:186} INFO - Started process (PID=206789) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:29:29.246+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:29:29.247+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:29:29.247+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:29:33.816+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:29:33.813+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:29:33.817+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:29:33.829+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.591 seconds
[2024-10-02T22:30:04.594+0000] {processor.py:186} INFO - Started process (PID=207148) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:30:04.595+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:30:04.597+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:30:04.597+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:30:08.890+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:30:08.886+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:30:08.891+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:30:08.906+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.319 seconds
[2024-10-02T22:30:39.045+0000] {processor.py:186} INFO - Started process (PID=207503) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:30:39.057+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:30:39.058+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:30:39.058+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:30:43.311+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:30:43.308+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:30:43.313+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:30:43.336+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.298 seconds
[2024-10-02T22:31:13.992+0000] {processor.py:186} INFO - Started process (PID=207860) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:31:13.994+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:31:13.995+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:31:13.995+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:31:18.738+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:31:18.734+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:31:18.739+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:31:18.761+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.776 seconds
[2024-10-02T22:31:49.354+0000] {processor.py:186} INFO - Started process (PID=208213) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:31:49.356+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:31:49.358+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:31:49.357+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:31:54.154+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:31:54.150+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:31:54.155+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:31:54.167+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.819 seconds
[2024-10-02T22:32:25.159+0000] {processor.py:186} INFO - Started process (PID=208562) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:32:25.171+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:32:25.172+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:32:25.172+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:32:29.522+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:32:29.518+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:32:29.524+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:32:29.536+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.384 seconds
[2024-10-02T22:32:59.894+0000] {processor.py:186} INFO - Started process (PID=208915) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:32:59.896+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:32:59.898+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:32:59.897+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:33:04.459+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:33:04.456+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:33:04.460+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:33:04.471+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.584 seconds
[2024-10-02T22:33:35.142+0000] {processor.py:186} INFO - Started process (PID=209263) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:33:35.154+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:33:35.156+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:33:35.156+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:33:39.360+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:33:39.357+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:33:39.361+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:33:39.383+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.248 seconds
[2024-10-02T22:34:09.424+0000] {processor.py:186} INFO - Started process (PID=209617) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:34:09.426+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:34:09.428+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:34:09.427+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:34:13.732+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:34:13.729+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:34:13.733+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:34:13.745+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.328 seconds
[2024-10-02T22:34:43.954+0000] {processor.py:186} INFO - Started process (PID=209977) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:34:43.956+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:34:43.957+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:34:43.957+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:34:48.379+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:34:48.375+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:34:48.380+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:34:48.597+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.651 seconds
[2024-10-02T22:35:18.687+0000] {processor.py:186} INFO - Started process (PID=210340) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:35:18.700+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:35:18.701+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:35:18.701+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:35:23.050+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:35:23.046+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:35:23.051+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:35:23.063+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.382 seconds
[2024-10-02T22:35:53.114+0000] {processor.py:186} INFO - Started process (PID=210688) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:35:53.115+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:35:53.116+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:35:53.116+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:35:57.470+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:35:57.467+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:35:57.472+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:35:57.483+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.376 seconds
[2024-10-02T22:36:27.784+0000] {processor.py:186} INFO - Started process (PID=211036) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:36:27.785+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:36:27.787+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:36:27.787+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:36:32.338+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:36:32.333+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:36:32.341+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:36:32.356+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.579 seconds
[2024-10-02T22:37:03.057+0000] {processor.py:186} INFO - Started process (PID=211384) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:37:03.059+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:37:03.060+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:37:03.059+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:37:07.423+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:37:07.420+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:37:07.424+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:37:07.434+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.384 seconds
[2024-10-02T22:37:37.561+0000] {processor.py:186} INFO - Started process (PID=211741) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:37:37.573+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:37:37.575+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:37:37.574+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:37:42.263+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:37:42.258+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:37:42.265+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:37:42.286+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.733 seconds
[2024-10-02T22:38:12.527+0000] {processor.py:186} INFO - Started process (PID=212090) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:38:12.538+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:38:12.540+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:38:12.540+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:38:16.938+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:38:16.935+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:38:16.940+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:38:16.951+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.431 seconds
[2024-10-02T22:38:47.073+0000] {processor.py:186} INFO - Started process (PID=212450) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:38:47.075+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:38:47.077+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:38:47.076+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:38:52.567+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:38:52.563+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:38:52.568+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:38:52.581+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.514 seconds
[2024-10-02T22:39:22.872+0000] {processor.py:186} INFO - Started process (PID=212810) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:39:22.883+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:39:22.884+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:39:22.884+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:39:27.272+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:39:27.269+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:39:27.274+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:39:27.296+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.432 seconds
[2024-10-02T22:39:57.491+0000] {processor.py:186} INFO - Started process (PID=213169) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:39:57.504+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:39:57.505+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:39:57.505+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:40:01.770+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:40:01.766+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:40:01.771+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:40:01.793+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.308 seconds
[2024-10-02T22:40:32.332+0000] {processor.py:186} INFO - Started process (PID=213520) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:40:32.334+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:40:32.336+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:40:32.335+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:40:36.795+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:40:36.791+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:40:36.797+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:40:36.819+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.493 seconds
[2024-10-02T22:41:07.626+0000] {processor.py:186} INFO - Started process (PID=213870) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:41:07.628+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:41:07.629+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:41:07.629+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:41:11.948+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:41:11.944+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:41:11.950+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:41:11.971+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.352 seconds
[2024-10-02T22:41:42.116+0000] {processor.py:186} INFO - Started process (PID=214218) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:41:42.118+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:41:42.119+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:41:42.119+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:41:46.922+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:41:46.918+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:41:46.923+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:41:46.935+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.825 seconds
[2024-10-02T22:42:17.385+0000] {processor.py:186} INFO - Started process (PID=214573) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:42:17.387+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:42:17.388+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:42:17.388+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:42:21.803+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:42:21.801+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:42:21.805+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:42:21.824+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.446 seconds
[2024-10-02T22:42:51.917+0000] {processor.py:186} INFO - Started process (PID=214932) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:42:51.929+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:42:51.930+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:42:51.930+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:42:56.236+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:42:56.233+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:42:56.237+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:42:56.261+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.351 seconds
[2024-10-02T22:43:26.342+0000] {processor.py:186} INFO - Started process (PID=215290) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:43:26.345+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:43:26.347+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:43:26.346+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:43:30.758+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:43:30.755+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:43:30.760+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:43:30.773+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.437 seconds
[2024-10-02T22:44:00.898+0000] {processor.py:186} INFO - Started process (PID=215646) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:44:00.900+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:44:00.901+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:44:00.901+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:44:05.339+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:44:05.335+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:44:05.340+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:44:05.354+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.462 seconds
[2024-10-02T22:44:35.904+0000] {processor.py:186} INFO - Started process (PID=216000) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:44:35.916+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:44:35.918+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:44:35.918+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:44:40.226+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:44:40.223+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:44:40.228+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:44:40.240+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.343 seconds
[2024-10-02T22:45:10.345+0000] {processor.py:186} INFO - Started process (PID=216349) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:45:10.357+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:45:10.359+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:45:10.358+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:45:14.677+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:45:14.674+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:45:14.679+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:45:14.691+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.353 seconds
[2024-10-02T22:45:44.874+0000] {processor.py:186} INFO - Started process (PID=216697) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:45:44.887+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:45:44.889+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:45:44.888+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:45:49.295+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:45:49.291+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:45:49.297+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:45:49.308+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.440 seconds
[2024-10-02T22:46:19.953+0000] {processor.py:186} INFO - Started process (PID=217045) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:46:19.965+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:46:19.967+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:46:19.967+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:46:24.328+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:46:24.324+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:46:24.329+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:46:24.342+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.396 seconds
[2024-10-02T22:46:54.784+0000] {processor.py:186} INFO - Started process (PID=217395) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:46:54.796+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:46:54.798+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:46:54.797+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:46:59.233+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:46:59.229+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:46:59.234+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:46:59.246+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.469 seconds
[2024-10-02T22:47:29.554+0000] {processor.py:186} INFO - Started process (PID=217764) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:47:29.556+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:47:29.557+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:47:29.557+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:47:33.808+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:47:33.804+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:47:33.809+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:47:33.832+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.285 seconds
[2024-10-02T22:48:03.929+0000] {processor.py:186} INFO - Started process (PID=218119) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:48:03.941+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:48:03.943+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:48:03.942+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:48:08.224+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:48:08.221+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:48:08.225+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:48:08.247+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.325 seconds
[2024-10-02T22:48:38.528+0000] {processor.py:186} INFO - Started process (PID=218473) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:48:38.540+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:48:38.542+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:48:38.541+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:48:43.019+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:48:43.016+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:48:43.021+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:48:43.045+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.524 seconds
[2024-10-02T22:49:13.323+0000] {processor.py:186} INFO - Started process (PID=218829) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:49:13.324+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:49:13.326+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:49:13.325+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:49:17.670+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:49:17.667+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:49:17.671+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:49:17.694+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.377 seconds
[2024-10-02T22:49:47.877+0000] {processor.py:186} INFO - Started process (PID=219176) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:49:47.889+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:49:47.890+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:49:47.890+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:49:52.247+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:49:52.244+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:49:52.249+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:49:52.262+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.393 seconds
[2024-10-02T22:50:22.399+0000] {processor.py:186} INFO - Started process (PID=219524) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:50:22.411+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:50:22.413+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:50:22.412+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:50:26.765+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:50:26.761+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:50:26.766+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:50:26.787+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.394 seconds
[2024-10-02T22:50:57.466+0000] {processor.py:186} INFO - Started process (PID=219872) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:50:57.478+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:50:57.479+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:50:57.479+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:51:01.947+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:51:01.943+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:51:01.948+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:51:01.960+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.501 seconds
[2024-10-02T22:51:32.085+0000] {processor.py:186} INFO - Started process (PID=220231) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:51:32.097+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:51:32.099+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:51:32.099+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:51:36.896+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:51:36.890+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:51:36.898+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:51:36.920+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.842 seconds
[2024-10-02T22:52:07.388+0000] {processor.py:186} INFO - Started process (PID=220597) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:52:07.390+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:52:07.392+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:52:07.391+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:52:12.019+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:52:12.016+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:52:12.021+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:52:12.032+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.651 seconds
[2024-10-02T22:52:42.642+0000] {processor.py:186} INFO - Started process (PID=220951) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:52:42.643+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:52:42.645+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:52:42.644+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:52:47.142+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:52:47.138+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:52:47.143+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:52:47.166+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.531 seconds
[2024-10-02T22:53:17.213+0000] {processor.py:186} INFO - Started process (PID=221299) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:53:17.225+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:53:17.227+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:53:17.227+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:53:21.756+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:53:21.753+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:53:21.758+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:53:21.779+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.573 seconds
[2024-10-02T22:53:52.020+0000] {processor.py:186} INFO - Started process (PID=221653) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:53:52.026+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:53:52.028+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:53:52.028+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:53:56.462+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:53:56.459+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:53:56.464+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:53:56.486+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.474 seconds
[2024-10-02T22:54:26.670+0000] {processor.py:186} INFO - Started process (PID=222001) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:54:26.682+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:54:26.684+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:54:26.683+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:54:31.113+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:54:31.109+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:54:31.114+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:54:31.139+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.475 seconds
[2024-10-02T22:55:01.482+0000] {processor.py:186} INFO - Started process (PID=222352) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:55:01.494+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:55:01.496+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:55:01.495+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:55:06.248+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:55:06.243+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:55:06.250+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:55:06.273+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.797 seconds
[2024-10-02T22:55:36.831+0000] {processor.py:186} INFO - Started process (PID=222713) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:55:36.843+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:55:36.844+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:55:36.844+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:55:41.350+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:55:41.347+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:55:41.351+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:55:41.364+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.540 seconds
[2024-10-02T22:56:12.141+0000] {processor.py:186} INFO - Started process (PID=223071) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:56:12.153+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:56:12.154+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:56:12.154+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:56:16.907+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:56:16.903+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:56:16.908+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:56:16.930+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.796 seconds
[2024-10-02T22:56:47.575+0000] {processor.py:186} INFO - Started process (PID=223431) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:56:47.588+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:56:47.589+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:56:47.589+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:56:51.966+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:56:51.962+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:56:51.967+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:56:51.979+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.412 seconds
[2024-10-02T22:57:22.212+0000] {processor.py:186} INFO - Started process (PID=223782) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:57:22.215+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:57:22.216+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:57:22.216+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:57:26.570+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:57:26.567+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:57:26.572+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:57:26.594+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.388 seconds
[2024-10-02T22:57:56.663+0000] {processor.py:186} INFO - Started process (PID=224131) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:57:56.675+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:57:56.677+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:57:56.677+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:58:01.340+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:58:01.337+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:58:01.343+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:58:01.357+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.701 seconds
[2024-10-02T22:58:31.481+0000] {processor.py:186} INFO - Started process (PID=224483) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:58:31.493+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:58:31.494+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:58:31.494+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:58:36.030+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:58:36.026+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:58:36.031+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:58:36.046+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.572 seconds
[2024-10-02T22:59:06.303+0000] {processor.py:186} INFO - Started process (PID=224837) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:59:06.308+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:59:06.310+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:59:06.310+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:59:10.860+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:59:10.857+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:59:10.862+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:59:10.876+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.580 seconds
[2024-10-02T22:59:41.708+0000] {processor.py:186} INFO - Started process (PID=225202) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:59:41.720+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T22:59:41.722+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:59:41.721+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:59:46.372+0000] {logging_mixin.py:190} INFO - [2024-10-02T22:59:46.369+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T22:59:46.374+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T22:59:46.386+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.684 seconds
[2024-10-02T23:00:16.958+0000] {processor.py:186} INFO - Started process (PID=225548) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:00:16.970+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:00:16.972+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:00:16.971+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:00:21.410+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:00:21.407+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:00:21.412+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:00:21.438+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.488 seconds
[2024-10-02T23:00:52.292+0000] {processor.py:186} INFO - Started process (PID=225895) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:00:52.305+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:00:52.306+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:00:52.306+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:00:56.828+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:00:56.825+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:00:56.829+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:00:56.852+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.567 seconds
[2024-10-02T23:01:27.138+0000] {processor.py:186} INFO - Started process (PID=226255) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:01:27.150+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:01:27.152+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:01:27.152+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:01:31.688+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:01:31.684+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:01:31.690+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:01:31.713+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.581 seconds
[2024-10-02T23:02:01.857+0000] {processor.py:186} INFO - Started process (PID=226603) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:02:01.859+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:02:01.860+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:02:01.860+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:02:06.963+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:02:06.959+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:02:06.964+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:02:06.977+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.126 seconds
[2024-10-02T23:02:37.499+0000] {processor.py:186} INFO - Started process (PID=226952) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:02:37.512+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:02:37.514+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:02:37.513+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:02:42.075+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:02:42.071+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:02:42.076+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:02:42.090+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.598 seconds
[2024-10-02T23:03:12.859+0000] {processor.py:186} INFO - Started process (PID=227316) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:03:12.861+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:03:12.863+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:03:12.863+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:03:17.340+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:03:17.337+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:03:17.342+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:03:17.354+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.501 seconds
[2024-10-02T23:03:47.465+0000] {processor.py:186} INFO - Started process (PID=227675) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:03:47.478+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:03:47.480+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:03:47.479+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:03:52.972+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:03:52.967+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:03:52.974+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:03:52.999+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.540 seconds
[2024-10-02T23:04:23.280+0000] {processor.py:186} INFO - Started process (PID=228023) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:04:23.292+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:04:23.293+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:04:23.293+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:04:28.391+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:04:28.385+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:04:28.393+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:04:28.409+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.136 seconds
[2024-10-02T23:04:59.108+0000] {processor.py:186} INFO - Started process (PID=228374) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:04:59.120+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:04:59.122+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:04:59.122+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:05:04.106+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:05:04.102+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:05:04.108+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:05:04.120+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.020 seconds
[2024-10-02T23:05:34.195+0000] {processor.py:186} INFO - Started process (PID=228734) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:05:34.196+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:05:34.198+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:05:34.197+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:05:39.477+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:05:39.473+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:05:39.478+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:05:39.502+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.315 seconds
[2024-10-02T23:06:09.837+0000] {processor.py:186} INFO - Started process (PID=229083) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:06:09.850+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:06:09.852+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:06:09.852+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:06:15.112+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:06:15.109+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:06:15.114+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:06:15.126+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.297 seconds
[2024-10-02T23:06:45.714+0000] {processor.py:186} INFO - Started process (PID=229443) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:06:45.717+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:06:45.718+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:06:45.718+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:06:51.096+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:06:51.092+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:06:51.097+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:06:51.111+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.405 seconds
[2024-10-02T23:07:21.553+0000] {processor.py:186} INFO - Started process (PID=229802) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:07:21.555+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:07:21.558+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:07:21.557+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:07:27.038+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:07:27.034+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:07:27.040+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:07:27.053+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.514 seconds
[2024-10-02T23:07:57.528+0000] {processor.py:186} INFO - Started process (PID=230157) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:07:57.530+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:07:57.532+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:07:57.531+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:08:02.549+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:08:02.546+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:08:02.551+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:08:02.574+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.054 seconds
[2024-10-02T23:08:32.744+0000] {processor.py:186} INFO - Started process (PID=230507) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:08:32.746+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:08:32.748+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:08:32.748+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:08:38.222+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:08:38.219+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:08:38.223+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:08:38.236+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.499 seconds
[2024-10-02T23:09:08.549+0000] {processor.py:186} INFO - Started process (PID=230864) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:09:08.561+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:09:08.563+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:09:08.563+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:09:13.481+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:09:13.478+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:09:13.483+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:09:13.507+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.964 seconds
[2024-10-02T23:09:43.683+0000] {processor.py:186} INFO - Started process (PID=231220) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:09:43.684+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:09:43.685+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:09:43.685+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:09:48.934+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:09:48.930+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:09:48.936+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:09:48.949+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.273 seconds
[2024-10-02T23:10:19.617+0000] {processor.py:186} INFO - Started process (PID=231579) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:10:19.619+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:10:19.621+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:10:19.620+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:10:24.562+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:10:24.558+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:10:24.563+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:10:24.586+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.977 seconds
[2024-10-02T23:10:54.677+0000] {processor.py:186} INFO - Started process (PID=231939) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:10:54.678+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:10:54.680+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:10:54.679+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:10:59.314+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:10:59.308+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:10:59.316+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:10:59.341+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.672 seconds
[2024-10-02T23:11:29.419+0000] {processor.py:186} INFO - Started process (PID=232287) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:11:29.431+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:11:29.433+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:11:29.433+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:11:34.542+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:11:34.539+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:11:34.544+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:11:34.566+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.154 seconds
[2024-10-02T23:12:04.755+0000] {processor.py:186} INFO - Started process (PID=232643) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:12:04.768+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:12:04.770+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:12:04.769+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:12:09.786+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:12:09.781+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:12:09.789+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:12:09.813+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.065 seconds
[2024-10-02T23:12:40.176+0000] {processor.py:186} INFO - Started process (PID=232991) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:12:40.188+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:12:40.190+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:12:40.190+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:12:45.413+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:12:45.409+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:12:45.415+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:12:45.439+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.271 seconds
[2024-10-02T23:13:15.613+0000] {processor.py:186} INFO - Started process (PID=233346) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:13:15.625+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:13:15.626+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:13:15.626+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:13:20.539+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:13:20.535+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:13:20.541+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:13:20.566+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.960 seconds
[2024-10-02T23:13:51.442+0000] {processor.py:186} INFO - Started process (PID=233697) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:13:51.454+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:13:51.456+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:13:51.456+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:13:56.821+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:13:56.818+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:13:56.823+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:13:56.837+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.402 seconds
[2024-10-02T23:14:27.040+0000] {processor.py:186} INFO - Started process (PID=234069) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:14:27.042+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:14:27.043+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:14:27.043+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:14:32.077+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:14:32.073+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:14:32.079+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:14:32.094+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.061 seconds
[2024-10-02T23:15:02.355+0000] {processor.py:186} INFO - Started process (PID=234417) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:15:02.367+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:15:02.369+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:15:02.368+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:15:07.792+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:15:07.788+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:15:07.793+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:15:07.817+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.469 seconds
[2024-10-02T23:15:37.899+0000] {processor.py:186} INFO - Started process (PID=234770) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:15:37.911+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:15:37.912+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:15:37.912+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:15:42.987+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:15:42.983+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:15:42.988+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:15:43.013+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.122 seconds
[2024-10-02T23:16:13.155+0000] {processor.py:186} INFO - Started process (PID=235127) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:16:13.168+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:16:13.169+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:16:13.169+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:16:18.155+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:16:18.151+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:16:18.158+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:16:18.185+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.037 seconds
[2024-10-02T23:16:48.640+0000] {processor.py:186} INFO - Started process (PID=235483) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:16:48.652+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:16:48.654+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:16:48.653+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:16:53.646+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:16:53.643+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:16:53.648+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:16:53.671+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.038 seconds
[2024-10-02T23:17:24.127+0000] {processor.py:186} INFO - Started process (PID=235839) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:17:24.139+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:17:24.141+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:17:24.140+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:17:28.968+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:17:28.965+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:17:28.970+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:17:28.993+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.873 seconds
[2024-10-02T23:17:59.740+0000] {processor.py:186} INFO - Started process (PID=236193) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:17:59.741+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:17:59.743+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:17:59.743+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:18:05.136+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:18:05.132+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:18:05.137+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:18:05.160+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.427 seconds
[2024-10-02T23:18:35.601+0000] {processor.py:186} INFO - Started process (PID=236559) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:18:35.606+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:18:35.608+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:18:35.608+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:18:40.789+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:18:40.786+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:18:40.791+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:18:40.805+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.210 seconds
[2024-10-02T23:19:11.004+0000] {processor.py:186} INFO - Started process (PID=236908) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:19:11.016+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:19:11.018+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:19:11.018+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:19:15.907+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:19:15.903+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:19:15.909+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:19:15.922+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.925 seconds
[2024-10-02T23:19:46.365+0000] {processor.py:186} INFO - Started process (PID=237261) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:19:46.367+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:19:46.369+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:19:46.369+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:19:53.051+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:19:53.047+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:19:53.054+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:19:53.071+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.732 seconds
[2024-10-02T23:20:23.227+0000] {processor.py:186} INFO - Started process (PID=237625) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:20:23.229+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:20:23.230+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:20:23.230+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:20:28.257+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:20:28.254+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:20:28.259+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:20:28.273+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.056 seconds
[2024-10-02T23:20:58.902+0000] {processor.py:186} INFO - Started process (PID=237986) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:20:58.914+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:20:58.916+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:20:58.916+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:21:03.832+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:21:03.828+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:21:03.834+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:21:03.858+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.963 seconds
[2024-10-02T23:21:34.093+0000] {processor.py:186} INFO - Started process (PID=238336) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:21:34.105+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:21:34.107+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:21:34.106+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:21:39.243+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:21:39.239+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:21:39.244+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:21:39.269+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.184 seconds
[2024-10-02T23:22:09.425+0000] {processor.py:186} INFO - Started process (PID=238697) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:22:09.427+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:22:09.429+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:22:09.429+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:22:14.755+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:22:14.751+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:22:14.757+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:22:14.771+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.353 seconds
[2024-10-02T23:22:44.940+0000] {processor.py:186} INFO - Started process (PID=239054) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:22:44.951+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:22:44.953+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:22:44.953+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:22:49.810+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:22:49.806+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:22:49.812+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:22:49.825+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.893 seconds
[2024-10-02T23:23:20.279+0000] {processor.py:186} INFO - Started process (PID=239408) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:23:20.282+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:23:20.283+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:23:20.283+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:23:25.601+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:23:25.597+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:23:25.602+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:23:25.625+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.352 seconds
[2024-10-02T23:23:56.054+0000] {processor.py:186} INFO - Started process (PID=239761) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:23:56.056+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:23:56.058+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:23:56.057+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:24:01.096+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:24:01.092+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:24:01.097+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:24:01.114+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.068 seconds
[2024-10-02T23:24:31.508+0000] {processor.py:186} INFO - Started process (PID=240127) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:24:31.520+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:24:31.522+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:24:31.521+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:24:36.633+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:24:36.629+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:24:36.635+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:24:36.649+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.149 seconds
[2024-10-02T23:25:07.095+0000] {processor.py:186} INFO - Started process (PID=240485) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:25:07.098+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:25:07.099+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:25:07.099+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:25:12.598+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:25:12.594+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:25:12.600+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:25:12.625+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.537 seconds
[2024-10-02T23:25:42.903+0000] {processor.py:186} INFO - Started process (PID=240843) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:25:42.915+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:25:42.917+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:25:42.917+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:25:47.937+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:25:47.933+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:25:47.938+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:25:47.953+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.056 seconds
[2024-10-02T23:26:18.657+0000] {processor.py:186} INFO - Started process (PID=241191) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:26:18.669+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:26:18.671+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:26:18.670+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:26:23.907+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:26:23.903+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:26:23.909+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:26:23.922+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.271 seconds
[2024-10-02T23:26:54.548+0000] {processor.py:186} INFO - Started process (PID=241547) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:26:54.560+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:26:54.562+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:26:54.561+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:26:59.511+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:26:59.507+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:26:59.513+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:26:59.537+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.997 seconds
[2024-10-02T23:27:29.707+0000] {processor.py:186} INFO - Started process (PID=241896) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:27:29.709+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:27:29.710+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:27:29.710+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:27:34.918+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:27:34.915+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:27:34.920+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:27:34.936+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.238 seconds
[2024-10-02T23:28:05.227+0000] {processor.py:186} INFO - Started process (PID=242259) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:28:05.229+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:28:05.231+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:28:05.230+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:28:10.112+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:28:10.109+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:28:10.114+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:28:10.136+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.917 seconds
[2024-10-02T23:28:40.462+0000] {processor.py:186} INFO - Started process (PID=242609) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:28:40.464+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:28:40.465+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:28:40.465+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:28:45.584+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:28:45.580+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:28:45.585+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:28:45.599+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.143 seconds
[2024-10-02T23:29:16.117+0000] {processor.py:186} INFO - Started process (PID=242969) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:29:16.130+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:29:16.132+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:29:16.131+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:29:21.272+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:29:21.268+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:29:21.274+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:29:21.297+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.187 seconds
[2024-10-02T23:29:51.592+0000] {processor.py:186} INFO - Started process (PID=243328) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:29:51.595+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:29:51.596+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:29:51.596+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:29:56.465+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:29:56.461+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:29:56.467+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:29:56.491+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.905 seconds
[2024-10-02T23:30:26.666+0000] {processor.py:186} INFO - Started process (PID=243678) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:30:26.678+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:30:26.679+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:30:26.679+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:30:31.815+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:30:31.811+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:30:31.817+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:30:31.829+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.170 seconds
[2024-10-02T23:31:01.917+0000] {processor.py:186} INFO - Started process (PID=244033) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:31:01.918+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:31:01.920+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:31:01.919+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:31:07.270+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:31:07.266+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:31:07.272+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:31:07.294+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.385 seconds
[2024-10-02T23:31:37.741+0000] {processor.py:186} INFO - Started process (PID=244389) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:31:37.742+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:31:37.744+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:31:37.744+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:31:43.067+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:31:43.063+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:31:43.069+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:31:43.092+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.360 seconds
[2024-10-02T23:32:13.513+0000] {processor.py:186} INFO - Started process (PID=244751) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:32:13.525+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:32:13.527+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:32:13.527+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:32:18.579+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:32:18.574+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:32:18.581+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:32:18.605+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.101 seconds
[2024-10-02T23:32:49.531+0000] {processor.py:186} INFO - Started process (PID=245109) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:32:49.543+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:32:49.545+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:32:49.544+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:32:54.204+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:32:54.201+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:32:54.206+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:32:54.231+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.706 seconds
[2024-10-02T23:33:24.884+0000] {processor.py:186} INFO - Started process (PID=245459) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:33:24.896+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:33:24.897+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:33:24.897+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:33:30.096+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:33:30.092+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:33:30.097+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:33:30.110+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.233 seconds
[2024-10-02T23:34:00.266+0000] {processor.py:186} INFO - Started process (PID=245815) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:34:00.278+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:34:00.280+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:34:00.280+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:34:05.028+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:34:05.023+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:34:05.030+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:34:05.044+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.786 seconds
[2024-10-02T23:34:35.587+0000] {processor.py:186} INFO - Started process (PID=246163) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:34:35.599+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:34:35.601+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:34:35.600+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:34:41.100+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:34:41.096+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:34:41.101+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:34:41.125+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.545 seconds
[2024-10-02T23:35:11.278+0000] {processor.py:186} INFO - Started process (PID=246530) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:35:11.290+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:35:11.291+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:35:11.291+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:35:16.127+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:35:16.123+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:35:16.128+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:35:16.152+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.882 seconds
[2024-10-02T23:35:46.543+0000] {processor.py:186} INFO - Started process (PID=246877) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:35:46.555+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:35:46.557+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:35:46.556+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:35:51.608+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:35:51.604+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:35:51.610+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:35:51.633+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.097 seconds
[2024-10-02T23:36:22.100+0000] {processor.py:186} INFO - Started process (PID=247236) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:36:22.112+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:36:22.114+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:36:22.114+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:36:27.257+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:36:27.251+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:36:27.261+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:36:27.279+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.187 seconds
[2024-10-02T23:36:58.009+0000] {processor.py:186} INFO - Started process (PID=247592) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:36:58.021+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:36:58.024+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:36:58.022+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:37:03.660+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:37:03.656+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:37:03.661+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:37:03.675+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.674 seconds
[2024-10-02T23:37:34.326+0000] {processor.py:186} INFO - Started process (PID=247941) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:37:34.338+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:37:34.340+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:37:34.339+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:37:39.296+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:37:39.293+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:37:39.298+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:37:39.320+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.001 seconds
[2024-10-02T23:38:09.588+0000] {processor.py:186} INFO - Started process (PID=248298) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:38:09.600+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:38:09.602+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:38:09.602+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:38:14.399+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:38:14.396+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:38:14.401+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:38:14.414+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.833 seconds
[2024-10-02T23:38:45.409+0000] {processor.py:186} INFO - Started process (PID=248656) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:38:45.410+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:38:45.411+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:38:45.411+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:38:50.578+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:38:50.575+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:38:50.580+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:38:50.595+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.194 seconds
[2024-10-02T23:39:20.991+0000] {processor.py:186} INFO - Started process (PID=249011) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:39:21.002+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:39:21.004+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:39:21.004+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:39:26.031+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:39:26.027+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:39:26.033+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:39:26.047+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.064 seconds
[2024-10-02T23:39:56.231+0000] {processor.py:186} INFO - Started process (PID=249367) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:39:56.233+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:39:56.235+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:39:56.234+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:40:01.379+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:40:01.375+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:40:01.381+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:40:01.394+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.170 seconds
[2024-10-02T23:40:31.642+0000] {processor.py:186} INFO - Started process (PID=249729) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:40:31.644+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:40:31.646+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:40:31.646+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:40:36.723+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:40:36.719+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:40:36.725+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:40:36.739+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.104 seconds
[2024-10-02T23:41:07.453+0000] {processor.py:186} INFO - Started process (PID=250075) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:41:07.466+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:41:07.467+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:41:07.467+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:41:12.209+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:41:12.206+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:41:12.211+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:41:12.235+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.788 seconds
[2024-10-02T23:41:42.496+0000] {processor.py:186} INFO - Started process (PID=250422) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:41:42.508+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:41:42.510+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:41:42.509+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:41:47.746+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:41:47.740+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:41:47.748+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:41:47.768+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.279 seconds
[2024-10-02T23:42:18.442+0000] {processor.py:186} INFO - Started process (PID=250781) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:42:18.454+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:42:18.456+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:42:18.455+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:42:23.171+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:42:23.168+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:42:23.173+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:42:23.197+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.762 seconds
[2024-10-02T23:42:53.661+0000] {processor.py:186} INFO - Started process (PID=251134) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:42:53.673+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:42:53.675+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:42:53.674+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:42:58.448+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:42:58.444+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:42:58.449+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:42:58.462+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.808 seconds
[2024-10-02T23:43:28.509+0000] {processor.py:186} INFO - Started process (PID=251487) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:43:28.511+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:43:28.513+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:43:28.513+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:43:33.751+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:43:33.747+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:43:33.753+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:43:33.777+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.275 seconds
[2024-10-02T23:44:04.044+0000] {processor.py:186} INFO - Started process (PID=251852) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:44:04.055+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:44:04.057+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:44:04.057+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:44:08.835+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:44:08.832+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:44:08.837+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:44:08.851+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.814 seconds
[2024-10-02T23:44:39.264+0000] {processor.py:186} INFO - Started process (PID=252200) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:44:39.265+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:44:39.267+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:44:39.267+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:44:44.155+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:44:44.152+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:44:44.157+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:44:44.170+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.915 seconds
[2024-10-02T23:45:14.343+0000] {processor.py:186} INFO - Started process (PID=252551) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:45:14.344+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:45:14.346+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:45:14.346+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:45:19.247+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:45:19.244+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:45:19.249+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:45:19.274+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.939 seconds
[2024-10-02T23:45:49.607+0000] {processor.py:186} INFO - Started process (PID=252902) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:45:49.609+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:45:49.610+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:45:49.610+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:45:54.469+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:45:54.463+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:45:54.471+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:45:54.495+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.894 seconds
[2024-10-02T23:46:25.467+0000] {processor.py:186} INFO - Started process (PID=253260) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:46:25.478+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:46:25.480+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:46:25.480+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:46:30.777+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:46:30.773+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:46:30.779+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:46:30.792+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.333 seconds
[2024-10-02T23:47:01.515+0000] {processor.py:186} INFO - Started process (PID=253625) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:47:01.527+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:47:01.528+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:47:01.528+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:47:06.670+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:47:06.666+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:47:06.672+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:47:06.692+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.184 seconds
[2024-10-02T23:47:37.180+0000] {processor.py:186} INFO - Started process (PID=253979) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:47:37.182+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:47:37.183+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:47:37.183+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:47:42.418+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:47:42.414+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:47:42.419+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:47:42.433+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.259 seconds
[2024-10-02T23:48:12.809+0000] {processor.py:186} INFO - Started process (PID=254338) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:48:12.821+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:48:12.822+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:48:12.822+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:48:17.623+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:48:17.620+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:48:17.625+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:48:17.638+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.836 seconds
[2024-10-02T23:48:47.839+0000] {processor.py:186} INFO - Started process (PID=254689) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:48:47.841+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:48:47.843+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:48:47.842+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:48:52.758+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:48:52.754+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:48:52.759+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:48:52.771+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.941 seconds
[2024-10-02T23:49:23.551+0000] {processor.py:186} INFO - Started process (PID=255037) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:49:23.563+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:49:23.565+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:49:23.565+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:49:28.427+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:49:28.423+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:49:28.428+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:49:28.444+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.901 seconds
[2024-10-02T23:49:59.077+0000] {processor.py:186} INFO - Started process (PID=255396) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:49:59.089+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:49:59.091+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:49:59.090+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:50:05.188+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:50:05.184+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:50:05.189+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:50:05.203+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.133 seconds
[2024-10-02T23:50:35.436+0000] {processor.py:186} INFO - Started process (PID=255760) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:50:35.437+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:50:35.439+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:50:35.438+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:50:40.444+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:50:40.439+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:50:40.446+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:50:40.470+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.041 seconds
[2024-10-02T23:51:10.788+0000] {processor.py:186} INFO - Started process (PID=256114) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:51:10.790+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:51:10.791+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:51:10.791+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:51:15.666+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:51:15.662+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:51:15.667+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:51:15.691+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.910 seconds
[2024-10-02T23:51:46.437+0000] {processor.py:186} INFO - Started process (PID=256466) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:51:46.449+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:51:46.451+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:51:46.450+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:51:52.005+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:51:52.002+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:51:52.007+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:51:52.033+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.603 seconds
[2024-10-02T23:52:22.497+0000] {processor.py:186} INFO - Started process (PID=256827) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:52:22.499+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:52:22.501+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:52:22.500+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:52:27.465+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:52:27.461+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:52:27.467+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:52:27.491+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.001 seconds
[2024-10-02T23:52:57.639+0000] {processor.py:186} INFO - Started process (PID=257183) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:52:57.644+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:52:57.646+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:52:57.645+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:53:02.588+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:53:02.584+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:53:02.590+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:53:02.607+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.976 seconds
[2024-10-02T23:53:32.959+0000] {processor.py:186} INFO - Started process (PID=257537) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:53:32.962+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:53:32.963+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:53:32.963+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:53:38.356+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:53:38.351+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:53:38.358+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:53:38.384+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.432 seconds
[2024-10-02T23:54:08.439+0000] {processor.py:186} INFO - Started process (PID=257894) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:54:08.451+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:54:08.453+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:54:08.452+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:54:13.260+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:54:13.256+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:54:13.261+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:54:13.285+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.853 seconds
[2024-10-02T23:54:44.106+0000] {processor.py:186} INFO - Started process (PID=258248) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:54:44.118+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:54:44.120+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:54:44.120+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:54:49.130+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:54:49.127+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:54:49.132+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:54:49.158+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.059 seconds
[2024-10-02T23:55:19.392+0000] {processor.py:186} INFO - Started process (PID=258600) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:55:19.404+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:55:19.406+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:55:19.406+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:55:24.486+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:55:24.482+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:55:24.488+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:55:24.500+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.116 seconds
[2024-10-02T23:55:54.781+0000] {processor.py:186} INFO - Started process (PID=258951) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:55:54.783+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:55:54.784+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:55:54.784+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:56:00.771+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:56:00.767+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:56:00.773+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:56:00.787+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 6.014 seconds
[2024-10-02T23:56:31.161+0000] {processor.py:186} INFO - Started process (PID=259317) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:56:31.166+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:56:31.168+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:56:31.167+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:56:36.292+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:56:36.287+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:56:36.294+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:56:36.323+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.170 seconds
[2024-10-02T23:57:06.526+0000] {processor.py:186} INFO - Started process (PID=259673) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:57:06.527+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:57:06.529+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:57:06.529+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:57:12.437+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:57:12.431+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:57:12.439+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:57:12.456+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.939 seconds
[2024-10-02T23:57:42.655+0000] {processor.py:186} INFO - Started process (PID=260027) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:57:42.667+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:57:42.668+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:57:42.668+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:57:47.617+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:57:47.613+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:57:47.619+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:57:47.631+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.984 seconds
[2024-10-02T23:58:18.276+0000] {processor.py:186} INFO - Started process (PID=260382) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:58:18.278+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:58:18.280+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:58:18.279+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:58:23.253+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:58:23.249+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:58:23.255+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:58:23.269+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 5.000 seconds
[2024-10-02T23:58:54.008+0000] {processor.py:186} INFO - Started process (PID=260731) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:58:54.010+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:58:54.012+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:58:54.011+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:58:58.839+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:58:58.833+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:58:58.841+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:58:58.865+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.864 seconds
[2024-10-02T23:59:29.145+0000] {processor.py:186} INFO - Started process (PID=261086) to work on /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:59:29.147+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline/run.py for tasks to queue
[2024-10-02T23:59:29.148+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:59:29.148+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:59:34.033+0000] {logging_mixin.py:190} INFO - [2024-10-02T23:59:34.029+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline/run.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline/run.py", line 27, in <module>
    etl_pipeline()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/etl_pipeline/run.py", line 25, in etl_pipeline
    staging(incremental=incremental_mode) >> warehouse(incremental=incremental_mode)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 269, in warehouse
    step_1() >> step_2() >> step_3()
                ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 181, in step_2
    extract_transform() >> validation() >> load()
    ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 93, in __call__
    return self._create_task_group(TaskGroup, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/task_group.py", line 101, in _create_task_group
    retval = self.function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/etl_pipeline/tasks/warehouse/main.py", line 94, in extract_transform
    ('products_history', ExtractTransform._products_history),
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'ExtractTransform' has no attribute '_products_history'
[2024-10-02T23:59:34.034+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline/run.py
[2024-10-02T23:59:34.048+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline/run.py took 4.909 seconds
